{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "import datasets\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "from utils.reasoning import make_segment, split_cot\n",
    "from torch.nn.utils.rnn import pad_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from modeling_rmt.language_modeling import MemoryCell\n",
    "from modeling_rmt.experimental import RecurrentWrapperNoSegmentationGenerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":)\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda'\n",
    "model_name = \"gpt2\"\n",
    "checkpoint_path = \"/workspace-SR006.nfs2/bulatov/rmt/runs/multiplication_4x4/gpt2/1x1024_mem16_1024_LR1e-03-from_scratch-cot-v2-sv/run1/checkpoint-11000/pytorch_model.bin\"\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "bos = tokenizer.encode('////')\n",
    "think = tokenizer.encode('????')\n",
    "ans = tokenizer.encode('!!!!')\n",
    "eos = [tokenizer.eos_token_id]\n",
    "\n",
    "memory_cell = MemoryCell(\n",
    "    model,\n",
    "    num_mem_tokens=16\n",
    ")\n",
    "rmt = RecurrentWrapperNoSegmentationGenerate(memory_cell, \n",
    "                                             max_n_segments=8, \n",
    "                                             think_token_id=think[0],\n",
    "                                             answer_token_id=ans[0],\n",
    "                                             bos_token_id=bos[0],\n",
    "                                             eos_token_id=eos[0]\n",
    "                                             )\n",
    "\n",
    "rmt.load_state_dict(torch.load(checkpoint_path), strict=False)\n",
    "rmt.to(device)\n",
    "print(':)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Holder:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "args = Holder()\n",
    "# args.use_cot = False\n",
    "args.num_mem_tokens = None\n",
    "# args.task_name = 'gsm8k'\n",
    "args.task_name = 'multiplication'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_pad_value = tokenizer.pad_token_id if tokenizer.pad_token_id is not None else tokenizer.eos_token_id\n",
    "think = tokenizer.encode('????')\n",
    "ans = tokenizer.encode('!!!!')\n",
    "eos = [tokenizer.eos_token_id]\n",
    "if 'gsm8k' in args.task_name:\n",
    "    delim = \">> <<\"\n",
    "elif 'multiplication' in args.task_name:\n",
    "    delim = ' + '\n",
    "else:\n",
    "    raise NotImplementedError(f\"Unknown task name {args.task_name}\")\n",
    "\n",
    "id_pad_value = tokenizer.pad_token_id if tokenizer.pad_token_id is not None else tokenizer.eos_token_id\n",
    "bos = tokenizer.encode('////')\n",
    "think = tokenizer.encode('????')\n",
    "ans = tokenizer.encode('!!!!')\n",
    "eos = [tokenizer.eos_token_id]\n",
    "if 'gsm8k' in args.task_name:\n",
    "    delim = \">> <<\"\n",
    "elif 'multiplication' in args.task_name:\n",
    "    delim = ' + '\n",
    "else:\n",
    "    raise NotImplementedError(f\"Unknown task name {args.task_name}\")\n",
    "\n",
    "def collate_fn(batch):\n",
    "    # first, we segment each sample into task, cot steps and labels\n",
    "    segments_batch = []\n",
    "    for sample in batch:\n",
    "        task, lab, cot = sample['task'], sample['labels'], sample['cot']\n",
    "        task_tokens = tokenizer.encode(task, add_special_tokens=False)\n",
    "        labels_tokens = tokenizer.encode(lab, add_special_tokens=False)\n",
    "        cot_segments = split_cot(cot, by=delim)\n",
    "        cot_segment_tokens = tokenizer.batch_encode_plus(cot_segments, add_special_tokens=False)['input_ids']\n",
    "\n",
    "        segments = []\n",
    "        segments.append(make_segment(bos + task_tokens + think, loss=False))\n",
    "        for segment in cot_segment_tokens[:-1]:\n",
    "            segments.append(make_segment(bos + segment + think, loss=True))\n",
    "        segments.append(make_segment(bos + cot_segment_tokens[-1] + ans, loss=True))\n",
    "\n",
    "        segments.append(make_segment(bos + labels_tokens + eos, loss=True))\n",
    "        segments_batch.append(segments)\n",
    "\n",
    "    # if some samples have less segments than others, we pad them with empty segments\n",
    "    num_segments = max(len(segments) for segments in segments_batch)\n",
    "    for segments in segments_batch:\n",
    "        if len(segments) < num_segments:\n",
    "            segments.extend([make_segment(eos, loss=False)] * (num_segments - len(segments)))\n",
    "\n",
    "    # prepare segments for the whole batch\n",
    "    batch_segments = []\n",
    "    for i in range(num_segments):\n",
    "        input_ids = [s[i]['input_ids'] for s in segments_batch]\n",
    "        attention_mask = [s[i]['attention_mask'] for s in segments_batch]\n",
    "        labels = [s[i]['labels'] for s in segments_batch]\n",
    "        labels_mask = [s[i]['labels_mask'] for s in segments_batch]\n",
    "\n",
    "        input_ids = pad_sequence(input_ids, batch_first=True, padding_value=id_pad_value)\n",
    "        attention_mask = pad_sequence(attention_mask, batch_first=True, padding_value=0)\n",
    "        labels = pad_sequence(labels, batch_first=True, padding_value=-100)\n",
    "        labels_mask = pad_sequence(labels_mask, batch_first=True, padding_value=False)\n",
    "\n",
    "        batch_segment = {'input_ids': input_ids,\n",
    "                            'attention_mask': attention_mask,\n",
    "                            'labels_mask': labels_mask,\n",
    "                            'labels': labels\n",
    "                            }\n",
    "        batch_segments.append(batch_segment)\n",
    "    full_labels = torch.cat([s['labels'] for s in batch_segments], dim=1)\n",
    "    return {\"segments\": batch_segments, 'labels': full_labels}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the dataset since booydar/multiplication_4x4 couldn't be found on the Hugging Face Hub\n",
      "Found the latest cached dataset configuration 'default' at /home/jovyan/.cache/huggingface/datasets/booydar___multiplication_4x4/default/0.0.0/e224243bb9970a0937976173287d24816d683ff9 (last modified on Fri Mar 14 16:54:33 2025).\n",
      "Using the latest cached version of the dataset since booydar/multiplication_4x4 couldn't be found on the Hugging Face Hub\n",
      "Found the latest cached dataset configuration 'default' at /home/jovyan/.cache/huggingface/datasets/booydar___multiplication_4x4/default/0.0.0/e224243bb9970a0937976173287d24816d683ff9 (last modified on Fri Mar 14 16:54:33 2025).\n"
     ]
    }
   ],
   "source": [
    "# dataset = 'booydar/gsm8k'\n",
    "dataset = 'booydar/multiplication_4x4'\n",
    "# dataset = f\"booydar/{args.task_name}\"\n",
    "train_dataset = datasets.load_dataset(dataset, split='train')\n",
    "valid_dataset = datasets.load_dataset(dataset, split='valid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, dataset, device='cpu', bs=16, max_new_tokens=25):\n",
    "    all_preds_cot, all_labels_cot = [], []\n",
    "    all_preds_ans, all_labels_ans = [], []\n",
    "\n",
    "    for start_ind in range(0, len(dataset), bs):\n",
    "        batch = dataset.select(range(start_ind, min(len(dataset), start_ind + bs)))\n",
    "        collated = collate_fn(batch)\n",
    "        task = collated['segments'][0]\n",
    "        task = {k:v.to(device) for k,v in task.items()}\n",
    "\n",
    "        with torch.no_grad():\n",
    "            gen_out = model.generate([task], max_new_tokens=max_new_tokens, pad_token_id=eos[0])\n",
    "        \n",
    "\n",
    "        preds_full = torch.cat(gen_out, dim=1)\n",
    "        labels = collated['labels']\n",
    "\n",
    "        labels_masks = labels > 0\n",
    "        labels_full = [lab[m] for lab, m in zip(labels, labels_masks)]\n",
    "\n",
    "        for lab_tokens, pred_tokens in zip(labels_full, preds_full):\n",
    "            lab_tokens = [t.item() for t in lab_tokens if t != bos[0]]\n",
    "            \n",
    "            ans_start_index = max(i for i, x in enumerate(lab_tokens) if x == ans[0])\n",
    "\n",
    "            pred_cot_tokens = pred_tokens[:ans_start_index].tolist()\n",
    "            lab_cot_tokens = lab_tokens[:ans_start_index]\n",
    "\n",
    "            all_preds_cot.append(pred_cot_tokens)\n",
    "            all_labels_cot.append(lab_cot_tokens)\n",
    "\n",
    "            all_preds_ans.append(pred_tokens[ans_start_index:].tolist())\n",
    "            all_labels_ans.append(lab_tokens[ans_start_index:])\n",
    "    \n",
    "    cot_correct = [p == l for p, l in zip(all_preds_cot, all_labels_cot)]\n",
    "    ans_correct = [p == l for p, l in zip(all_preds_ans, all_labels_ans)]\n",
    "    return {'accuracy_cot': np.mean(cot_correct), 'accuracy_ans': np.mean(ans_correct)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 16\n",
    "res = evaluate(rmt, valid_dataset.select(range(128)), bs=16, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy_cot': 1.0, 'accuracy_ans': 0.9921875}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "Index 1007 out of range for dataset of size 1000.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mIndexError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[23]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# for start_ind in range(0, 64, bs):\u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m start_ind \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m0\u001b[39m, \u001b[38;5;28mlen\u001b[39m(valid_dataset), bs):\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m     batch = \u001b[43mvalid_dataset\u001b[49m\u001b[43m.\u001b[49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mstart_ind\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_ind\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[43mbs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      9\u001b[39m     collated = collate_fn(batch)\n\u001b[32m     10\u001b[39m     task = collated[\u001b[33m'\u001b[39m\u001b[33msegments\u001b[39m\u001b[33m'\u001b[39m][\u001b[32m0\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace-SR006.nfs2/Bulatov_A/env_main/lib/python3.11/site-packages/datasets/arrow_dataset.py:562\u001b[39m, in \u001b[36mtransmit_format.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    555\u001b[39m self_format = {\n\u001b[32m    556\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mtype\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m._format_type,\n\u001b[32m    557\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mformat_kwargs\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m._format_kwargs,\n\u001b[32m    558\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mcolumns\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m._format_columns,\n\u001b[32m    559\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33moutput_all_columns\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m._output_all_columns,\n\u001b[32m    560\u001b[39m }\n\u001b[32m    561\u001b[39m \u001b[38;5;66;03m# apply actual function\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m562\u001b[39m out: Union[\u001b[33m\"\u001b[39m\u001b[33mDataset\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mDatasetDict\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    563\u001b[39m datasets: List[\u001b[33m\"\u001b[39m\u001b[33mDataset\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[38;5;28mlist\u001b[39m(out.values()) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(out, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m [out]\n\u001b[32m    564\u001b[39m \u001b[38;5;66;03m# re-apply format to the output\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace-SR006.nfs2/Bulatov_A/env_main/lib/python3.11/site-packages/datasets/fingerprint.py:442\u001b[39m, in \u001b[36mfingerprint_transform.<locals>._fingerprint.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    438\u001b[39m             validate_fingerprint(kwargs[fingerprint_name])\n\u001b[32m    440\u001b[39m \u001b[38;5;66;03m# Call actual function\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m442\u001b[39m out = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    444\u001b[39m \u001b[38;5;66;03m# Update fingerprint of in-place transforms + update in-place history of transforms\u001b[39;00m\n\u001b[32m    446\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m inplace:  \u001b[38;5;66;03m# update after calling func so that the fingerprint doesn't change if the function fails\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace-SR006.nfs2/Bulatov_A/env_main/lib/python3.11/site-packages/datasets/arrow_dataset.py:3920\u001b[39m, in \u001b[36mDataset.select\u001b[39m\u001b[34m(self, indices, keep_in_memory, indices_cache_file_name, writer_batch_size, new_fingerprint)\u001b[39m\n\u001b[32m   3918\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m _is_range_contiguous(indices) \u001b[38;5;129;01mand\u001b[39;00m indices.start >= \u001b[32m0\u001b[39m:\n\u001b[32m   3919\u001b[39m         start, length = indices.start, indices.stop - indices.start\n\u001b[32m-> \u001b[39m\u001b[32m3920\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_select_contiguous\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstart\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlength\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnew_fingerprint\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnew_fingerprint\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3921\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   3922\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace-SR006.nfs2/Bulatov_A/env_main/lib/python3.11/site-packages/datasets/arrow_dataset.py:562\u001b[39m, in \u001b[36mtransmit_format.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    555\u001b[39m self_format = {\n\u001b[32m    556\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mtype\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m._format_type,\n\u001b[32m    557\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mformat_kwargs\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m._format_kwargs,\n\u001b[32m    558\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mcolumns\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m._format_columns,\n\u001b[32m    559\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33moutput_all_columns\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m._output_all_columns,\n\u001b[32m    560\u001b[39m }\n\u001b[32m    561\u001b[39m \u001b[38;5;66;03m# apply actual function\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m562\u001b[39m out: Union[\u001b[33m\"\u001b[39m\u001b[33mDataset\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mDatasetDict\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    563\u001b[39m datasets: List[\u001b[33m\"\u001b[39m\u001b[33mDataset\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[38;5;28mlist\u001b[39m(out.values()) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(out, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m [out]\n\u001b[32m    564\u001b[39m \u001b[38;5;66;03m# re-apply format to the output\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace-SR006.nfs2/Bulatov_A/env_main/lib/python3.11/site-packages/datasets/fingerprint.py:442\u001b[39m, in \u001b[36mfingerprint_transform.<locals>._fingerprint.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    438\u001b[39m             validate_fingerprint(kwargs[fingerprint_name])\n\u001b[32m    440\u001b[39m \u001b[38;5;66;03m# Call actual function\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m442\u001b[39m out = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    444\u001b[39m \u001b[38;5;66;03m# Update fingerprint of in-place transforms + update in-place history of transforms\u001b[39;00m\n\u001b[32m    446\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m inplace:  \u001b[38;5;66;03m# update after calling func so that the fingerprint doesn't change if the function fails\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace-SR006.nfs2/Bulatov_A/env_main/lib/python3.11/site-packages/datasets/arrow_dataset.py:3981\u001b[39m, in \u001b[36mDataset._select_contiguous\u001b[39m\u001b[34m(self, start, length, new_fingerprint)\u001b[39m\n\u001b[32m   3978\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n\u001b[32m   3980\u001b[39m _check_valid_indices_value(start, \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m))\n\u001b[32m-> \u001b[39m\u001b[32m3981\u001b[39m \u001b[43m_check_valid_indices_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstart\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[43mlength\u001b[49m\u001b[43m \u001b[49m\u001b[43m-\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3982\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._indices \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m length == \u001b[32m0\u001b[39m:\n\u001b[32m   3983\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m Dataset(\n\u001b[32m   3984\u001b[39m         \u001b[38;5;28mself\u001b[39m.data.slice(start, length),\n\u001b[32m   3985\u001b[39m         info=\u001b[38;5;28mself\u001b[39m.info.copy(),\n\u001b[32m   3986\u001b[39m         split=\u001b[38;5;28mself\u001b[39m.split,\n\u001b[32m   3987\u001b[39m         fingerprint=new_fingerprint,\n\u001b[32m   3988\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace-SR006.nfs2/Bulatov_A/env_main/lib/python3.11/site-packages/datasets/arrow_dataset.py:624\u001b[39m, in \u001b[36m_check_valid_indices_value\u001b[39m\u001b[34m(index, size)\u001b[39m\n\u001b[32m    622\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_check_valid_indices_value\u001b[39m(index, size):\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m (index < \u001b[32m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m index + size < \u001b[32m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (index >= size):\n\u001b[32m--> \u001b[39m\u001b[32m624\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mIndex \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mindex\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m out of range for dataset of size \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msize\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mIndexError\u001b[39m: Index 1007 out of range for dataset of size 1000."
     ]
    }
   ],
   "source": [
    "\n",
    "bs = 16\n",
    "dataset = valid_dataset\n",
    "\n",
    "all_preds_cot, all_labels_cot = [], []\n",
    "all_preds_ans, all_labels_ans = [], []\n",
    "\n",
    "# for start_ind in range(0, 64, bs):\n",
    "for start_ind in range(0, len(dataset), bs):\n",
    "    batch = dataset.select(range(start_ind, min(len(dataset), start_ind + bs)))\n",
    "    collated = collate_fn(batch)\n",
    "    task = collated['segments'][0]\n",
    "    task = {k:v.to(device) for k,v in task.items()}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        gen_out = rmt.generate([task], max_new_tokens=25, pad_token_id=eos[0])\n",
    "    \n",
    "\n",
    "    preds_full = torch.cat(gen_out, dim=1)\n",
    "    labels = collated['labels']\n",
    "\n",
    "    labels_masks = labels > 0\n",
    "    labels_full = [lab[m] for lab, m in zip(labels, labels_masks)]\n",
    "\n",
    "    special_tokens = {ans[0], bos[0]}\n",
    "    acc_cot, acc_ans = [], []\n",
    "    for lab_tokens, pred_tokens in zip(labels_full, preds_full):\n",
    "        lab_tokens = [t.item() for t in lab_tokens if t != bos[0]]\n",
    "        \n",
    "        ans_start_index = max(i for i, x in enumerate(lab_tokens) if x == ans[0])\n",
    "\n",
    "        pred_cot_tokens = pred_tokens[:ans_start_index].tolist()\n",
    "        lab_cot_tokens = lab_tokens[:ans_start_index]\n",
    "\n",
    "        all_preds_cot.append(pred_cot_tokens)\n",
    "        all_labels_cot.append(lab_cot_tokens)\n",
    "\n",
    "        all_preds_ans.append(pred_tokens[ans_start_index:].tolist())\n",
    "        all_labels_ans.append(lab_tokens[ans_start_index:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy_cot': 1.0, 'accuracy_ans': 0.998991935483871}\n"
     ]
    }
   ],
   "source": [
    "cot_correct = [p == l for p, l in zip(all_preds_cot, all_labels_cot)]\n",
    "ans_correct = [p == l for p, l in zip(all_preds_ans, all_labels_ans)]\n",
    "print( {'accuracy_cot': np.mean(cot_correct), 'accuracy_ans': np.mean(ans_correct)})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy_cot': 1.0, 'accuracy_ans': 1.0}\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_preds_cot[0] == all_labels_cot[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_labels_cot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_cot.append(all(cot_correct))\n",
    "\n",
    "pred_ans_tokens = pred_tokens[ans_start_index:].tolist()\n",
    "lab_ans_tokens = lab_tokens[ans_start_index:]\n",
    "\n",
    "ans_correct = [p == l for p, l in zip(pred_ans_tokens, lab_ans_tokens) if l not in special_tokens]\n",
    "acc_ans.append(all(ans_correct))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 56])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat(gen_out, dim=1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ -100,  -100,  -100,  ...,   657,   352, 50256],\n",
       "        [ -100,  -100,  -100,  ...,   807,   513, 50256],\n",
       "        [ -100,  -100,  -100,  ...,   767,   718, 50256],\n",
       "        ...,\n",
       "        [ -100,  -100,  -100,  ...,   807,   657, 50256],\n",
       "        [ -100,  -100,  -100,  ...,   642,   352, 50256],\n",
       "        [ -100,  -100,  -100,  ...,   604,   807, 50256]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collated['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy_cot': 1.0, 'accuracy_ans': 1.0}\n"
     ]
    }
   ],
   "source": [
    "preds_full = torch.cat(gen_out, dim=1)#[:, 1:]\n",
    "labels = collated['labels']#[:, 1:]\n",
    "\n",
    "labels_masks = labels > 0\n",
    "# preds_full = [p[m] for p, m in zip(preds, labels_masks)]\n",
    "labels_full = [lab[m] for lab, m in zip(labels, labels_masks)]\n",
    "\n",
    "special_tokens = {ans[0], bos[0]}\n",
    "acc_cot, acc_ans = [], []\n",
    "for lab_tokens, pred_tokens in zip(labels_full, preds_full):\n",
    "    lab_tokens = [t for t in lab_tokens if t != bos[0]]\n",
    "    \n",
    "    ans_start_index = max(i for i, x in enumerate(lab_tokens) if x == ans[0])\n",
    "\n",
    "    pred_cot_tokens = pred_tokens[:ans_start_index].tolist()\n",
    "    lab_cot_tokens = lab_tokens[:ans_start_index]\n",
    "\n",
    "    cot_correct = [p == l for p, l in zip(pred_cot_tokens, lab_cot_tokens) if l not in special_tokens]\n",
    "    acc_cot.append(all(cot_correct))\n",
    "\n",
    "    pred_ans_tokens = pred_tokens[ans_start_index:].tolist()\n",
    "    lab_ans_tokens = lab_tokens[ans_start_index:]\n",
    "\n",
    "    ans_correct = [p == l for p, l in zip(pred_ans_tokens, lab_ans_tokens) if l not in special_tokens]\n",
    "    acc_ans.append(all(ans_correct))\n",
    "\n",
    "print( {'accuracy_cot': np.mean(acc_cot), 'accuracy_ans': np.mean(acc_ans)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'6 1 2 8 1????0 8 4 6 4 5 ( 6 9 6 4 6 5 )????0 0 6 1 2 8 1 ( 6 9 2 6 8 3 2 )????0 0 0 2 7 9 1 8'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(pred_cot_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'6 1 2 8 1????0 8 4 6 4 5 ( 6 9 6 4 6 5 )????0 0 6 1 2 8 1 ( 6 9 2 6 8 3 2 )????0 0 0 2 7 9 1 8'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(lab_cot_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['6',\n",
       " ' 1',\n",
       " ' 2',\n",
       " ' 8',\n",
       " ' 1',\n",
       " '????',\n",
       " '0',\n",
       " ' 8',\n",
       " ' 4',\n",
       " ' 6',\n",
       " ' 4',\n",
       " ' 5',\n",
       " ' (',\n",
       " ' 6',\n",
       " ' 9',\n",
       " ' 6',\n",
       " ' 4',\n",
       " ' 6',\n",
       " ' 5',\n",
       " ' )',\n",
       " '????',\n",
       " '0',\n",
       " ' 0',\n",
       " ' 6',\n",
       " ' 1',\n",
       " ' 2',\n",
       " ' 8',\n",
       " ' 1',\n",
       " ' (',\n",
       " ' 6',\n",
       " ' 9',\n",
       " ' 2',\n",
       " ' 6',\n",
       " ' 8',\n",
       " ' 3',\n",
       " ' 2',\n",
       " ' )',\n",
       " '????',\n",
       " '0',\n",
       " ' 0',\n",
       " ' 0',\n",
       " ' 2',\n",
       " ' 7',\n",
       " ' 9',\n",
       " ' 1',\n",
       " ' 8',\n",
       " '!!!!',\n",
       " '6',\n",
       " ' 9',\n",
       " ' 2']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.batch_decode(preds_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['////5 5 5 6 1????////0 0 6 4 9 0 ( 5 5 1 1 1 1 )????////0 0 5 9 0 7 0 ( 5 5 6 0 2 8 0 )????////0 0 0 0 6 4 9 0!!!!////5 5 6 0 8 2 0 1<|endoftext|>',\n",
       " '////6 7 1 1 3????////0 4 8 7 0 2 ( 6 1 0 9 3 2 )????////0 0 4 8 7 0 2 ( 6 1 4 7 1 3 2 )????////0 0 0 2 7 3 6 3!!!!////6 1 4 9 8 6 8 3<|endoftext|>',\n",
       " '////8 0 0 5 7????////0 4 8 3 4 8 ( 8 4 8 8 1 9 )????////0 0 6 7 3 9 0 ( 8 4 4 6 5 8 1 )????////0 0 0 2 3 6 5 6!!!!////8 4 4 8 8 4 7 6<|endoftext|>',\n",
       " '////9 0 9 2 1????////0 2 1 2 7 1 ( 9 2 0 5 8 1 )????////0 0 8 1 8 5 2 ( 9 2 8 6 6 7 2 )????////0 0 0 5 1 5 1 2!!!!////9 2 8 1 8 2 4 2<|endoftext|>',\n",
       " '////0 4 6 8 5????////0 0 5 6 6 3 ( 0 4 1 5 2 4 )????////0 0 0 8 9 3 4 ( 0 4 1 3 2 8 4 )????////0 0 0 0 5 6 6 3!!!!////0 4 1 3 7 4 1 4<|endoftext|>',\n",
       " '////2 5 2 4 2????////0 9 8 1 8 1 ( 2 4 1 6 0 2 )????////0 0 4 0 5 8 4 ( 2 4 5 6 5 0 5 )????////0 0 0 1 4 4 2 4!!!!////2 4 5 7 9 4 7 4<|endoftext|>',\n",
       " '////8 4 7 9 0????////0 6 6 8 3 4 ( 8 0 4 8 4 4 )????////0 0 4 7 8 4 0 ( 8 0 8 5 3 9 0 )????////0 0 0 4 4 2 9 2!!!!////8 0 8 9 7 1 0 3<|endoftext|>',\n",
       " '////0 0 0 0 0????////0 0 6 4 8 0 ( 0 0 6 4 8 0 )????////0 0 2 9 6 1 0 ( 0 0 8 3 5 2 0 )????////0 0 0 8 2 2 5 1!!!!////0 0 8 1 8 4 5 1<|endoftext|>',\n",
       " '////5 5 5 2 2????////0 6 6 0 7 2 ( 5 1 2 3 9 2 )????////0 0 0 0 0 0 0 ( 5 1 2 3 9 2 0 )????////0 0 0 5 5 5 2 2!!!!////5 1 2 8 4 8 2 2<|endoftext|>',\n",
       " '////0 0 0 0 0????////0 7 3 9 5 3 ( 0 7 3 9 5 3 )????////0 0 9 7 9 1 1 ( 0 7 2 7 5 5 1 )????////0 0 0 9 7 9 1 1!!!!////0 7 2 6 3 5 3 1<|endoftext|>',\n",
       " '////5 6 8 3 0????////0 0 6 4 5 1 ( 5 6 4 8 5 1 )????////0 0 5 8 7 4 3 ( 5 6 9 6 3 6 3 )????////0 0 0 5 5 0 7 2!!!!////5 6 9 1 9 6 0 3<|endoftext|>',\n",
       " '////4 8 1 4 5????////0 5 6 8 3 3 ( 4 3 8 2 9 3 )????////0 0 5 6 8 3 3 ( 4 3 3 9 7 7 3 )????////0 0 0 6 4 5 3 1!!!!////4 3 3 5 2 3 7 1<|endoftext|>',\n",
       " '////4 4 8 9 0????////0 9 4 1 2 2 ( 4 3 3 1 3 2 )????////0 0 8 8 6 9 1 ( 4 3 1 0 0 2 2 )????////0 0 0 2 2 9 4 0!!!!////4 3 1 2 2 1 7 0<|endoftext|>',\n",
       " '////6 5 6 7 3????////0 2 3 9 3 4 ( 6 7 9 6 7 4 )????////0 0 2 5 5 2 1 ( 6 7 1 2 3 7 1 )????////0 0 0 6 7 2 6 0!!!!////6 7 1 8 0 0 8 0<|endoftext|>',\n",
       " '////0 2 3 1 1????////0 0 0 3 8 2 ( 0 2 3 4 9 2 )????////0 0 0 6 9 3 3 ( 0 2 3 0 9 6 3 )????////0 0 0 0 2 3 1 1!!!!////0 2 3 0 1 0 5 1<|endoftext|>',\n",
       " '////6 1 2 8 1????////0 8 4 6 4 5 ( 6 9 6 4 6 5 )????////0 0 6 1 2 8 1 ( 6 9 2 6 8 3 2 )????////0 0 0 2 7 9 1 8!!!!////6 9 2 8 5 3 4 8<|endoftext|>']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "tokenizer.batch_decode(labels_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def compute_accuracy(eval_pred):\n",
    "    preds = eval_pred.predictions.argmax(axis=-1)[:, :-1]\n",
    "    labels = eval_pred.label_ids[:, 1:]\n",
    "\n",
    "    labels_masks = labels > 0\n",
    "    preds_full = [p[m] for p, m in zip(preds, labels_masks)]\n",
    "    labels_full = [lab[m] for lab, m in zip(labels, labels_masks)]\n",
    "\n",
    "    special_tokens = {ans[0], bos[0]}\n",
    "    acc_cot, acc_ans = [], []\n",
    "    for lab_tokens, pred_tokens in zip(labels_full, preds_full):\n",
    "        ans_start_index = max(i for i, x in enumerate(lab_tokens) if x == ans[0])\n",
    "\n",
    "        pred_cot_tokens = pred_tokens[:ans_start_index].tolist()\n",
    "        lab_cot_tokens = lab_tokens[:ans_start_index].tolist()\n",
    "\n",
    "        cot_correct = [p == l for p, l in zip(pred_cot_tokens, lab_cot_tokens) if l not in special_tokens]\n",
    "        acc_cot.append(all(cot_correct))\n",
    "\n",
    "        pred_ans_tokens = pred_tokens[ans_start_index:].tolist()\n",
    "        lab_ans_tokens = lab_tokens[ans_start_index:].tolist()\n",
    "\n",
    "        ans_correct = [p == l for p, l in zip(pred_ans_tokens, lab_ans_tokens) if l not in special_tokens]\n",
    "        acc_ans.append(all(ans_correct))\n",
    "\n",
    "    return {'accuracy_cot': np.mean(acc_cot), 'accuracy_ans': np.mean(acc_ans)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# collated = collate_fn([sample for sample in valid_dataset.select(range(128))])\n",
    "collated = collate_fn([sample for sample in train_dataset.select(range(16))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "segments = collated['segments']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer.batch_decode(segments[1]['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 11]) torch.Size([16, 11])\n",
      "torch.Size([16, 7]) torch.Size([16, 7])\n",
      "torch.Size([16, 16]) torch.Size([16, 16])\n",
      "torch.Size([16, 18]) torch.Size([16, 18])\n",
      "torch.Size([16, 10]) torch.Size([16, 10])\n",
      "torch.Size([16, 10]) torch.Size([16, 10])\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(segments)):\n",
    "    print(segments[i]['input_ids'].shape, segments[i]['labels'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# out = rmt(**collated)\n",
    "self = rmt\n",
    "segments = collated['segments']\n",
    "\n",
    "memory_state = None\n",
    "\n",
    "cell_outputs = []\n",
    "for seg_num, segment in enumerate(segments):\n",
    "    cell_out, memory_state = self.memory_cell(input_ids=segment['input_ids'],\n",
    "                                                attention_mask=segment['attention_mask'],\n",
    "                                                # labels=segment['input_ids'],\n",
    "\n",
    "                                                memory_state=memory_state, \n",
    "                                                output_hidden_states=True)\n",
    "    cell_outputs.append(cell_out)\n",
    "    self.manage_gradients(memory_state, seg_num)\n",
    "\n",
    "# out = self.process_outputs(cell_outputs, segments,\n",
    "#                             output_attentions=output_attentions,\n",
    "#                             output_hidden_states=output_hidden_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = dict()\n",
    "from torch.nn import CrossEntropyLoss\n",
    "self = rmt\n",
    "kwargs = {}\n",
    "\n",
    "proxy_out = {}\n",
    "for seg_num, segment in enumerate(segments):\n",
    "    cell_out = cell_outputs[seg_num]\n",
    "\n",
    "    full_logits = cell_out.logits\n",
    "\n",
    "    labels = segment.get('labels')\n",
    "    if labels is not None:\n",
    "        shift_labels = labels[..., 1:].contiguous()\n",
    "        shift_logits = full_logits[..., :-1, :].contiguous()\n",
    "        flat_labels = shift_labels.view(-1)\n",
    "        flat_logits = shift_logits.view(-1, shift_logits.size(-1))\n",
    "\n",
    "        loss_fct = CrossEntropyLoss()\n",
    "        labels_mask = segment.get('labels_mask')\n",
    "        if labels_mask is not None:\n",
    "            shift_mask = labels_mask[..., :-1].contiguous()\n",
    "\n",
    "            flat_labels = flat_labels[shift_mask.view(-1)]\n",
    "            flat_logits = flat_logits[shift_mask.view(-1)]\n",
    "\n",
    "            if labels_mask.sum() == 0:\n",
    "                loss_value = 0\n",
    "            else:\n",
    "                loss_value = loss_fct(flat_logits, flat_labels)\n",
    "\n",
    "        proxy_out[f'loss_{seg_num}'] = loss_value\n",
    "    else:\n",
    "        proxy_out[f'loss_{seg_num}'] = 0\n",
    "\n",
    "    segment_keys = ['loss']\n",
    "    if kwargs.get('output_attentions'):\n",
    "        segment_keys.append('attentions')\n",
    "    if kwargs.get('output_hidden_states'):\n",
    "        segment_keys.append('hidden_states')\n",
    "\n",
    "    for key, value in cell_out.items():\n",
    "        if any([sk in key for sk in segment_keys]):\n",
    "            proxy_out[f'{key}_{seg_num}'] = value\n",
    "\n",
    "num_segments = len(segments)\n",
    "out['loss'] = sum([proxy_out[f'loss_{seg_num}'] for seg_num in range(num_segments)]) / num_segments\n",
    "out['logits'] = torch.cat([cell_out.logits for cell_out in cell_outputs], dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_0 0\n",
      "loss_1 9.379081166116521e-05\n",
      "loss_2 0.0001396716688759625\n",
      "loss_3 0.00016610838065389544\n",
      "loss_4 0.0001877214090200141\n",
      "loss_5 0.00045566188055090606\n"
     ]
    }
   ],
   "source": [
    "for k, v in proxy_out.items():\n",
    "    print(k, v.item() if isinstance(v, torch.Tensor) else v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'task': '5 6 3 2 * 7 4 3 4',\n",
       " 'labels': '5 5 6 0 8 2 0 1',\n",
       " 'cot': '5 5 5 6 1 + 0 0 6 4 9 0 ( 5 5 1 1 1 1 ) + 0 0 5 9 0 7 0 ( 5 5 6 0 2 8 0 ) + 0 0 0 0 6 4 9 0'}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def compute_accuracy(eval_pred):\n",
    "    preds = eval_pred.predictions.argmax(axis=-1)[:, :-1]\n",
    "    labels = eval_pred.label_ids[:, 1:]\n",
    "\n",
    "    labels_masks = labels > 0\n",
    "    preds_full = [p[m] for p, m in zip(preds, labels_masks)]\n",
    "    labels_full = [lab[m] for lab, m in zip(labels, labels_masks)]\n",
    "\n",
    "    special_tokens = {ans[0], bos[0]}\n",
    "    acc_cot, acc_ans = [], []\n",
    "    for lab_tokens, pred_tokens in zip(labels_full, preds_full):\n",
    "        ans_start_index = max(i for i, x in enumerate(lab_tokens) if x == ans[0])\n",
    "\n",
    "        pred_cot_tokens = pred_tokens[:ans_start_index].tolist()\n",
    "        lab_cot_tokens = lab_tokens[:ans_start_index].tolist()\n",
    "\n",
    "        cot_correct = [p == l for p, l in zip(pred_cot_tokens, lab_cot_tokens) if l not in special_tokens]\n",
    "        acc_cot.append(all(cot_correct))\n",
    "\n",
    "        pred_ans_tokens = pred_tokens[ans_start_index:].tolist()\n",
    "        lab_ans_tokens = lab_tokens[ans_start_index:].tolist()\n",
    "\n",
    "        ans_correct = [p == l for p, l in zip(pred_ans_tokens, lab_ans_tokens) if l not in special_tokens]\n",
    "        acc_ans.append(all(ans_correct))\n",
    "\n",
    "    return {'accuracy_cot': np.mean(acc_cot), 'accuracy_ans': np.mean(acc_ans)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "special_tokens = {ans[0], bos[0]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pred_ans_tokens' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[40]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m tokenizer.decode([p \u001b[38;5;28;01mfor\u001b[39;00m p, l \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[43mpred_ans_tokens\u001b[49m, lab_ans_tokens) \u001b[38;5;28;01mif\u001b[39;00m l \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m special_tokens])\n",
      "\u001b[31mNameError\u001b[39m: name 'pred_ans_tokens' is not defined"
     ]
    }
   ],
   "source": [
    "tokenizer.decode([p for p, l in zip(pred_ans_tokens, lab_ans_tokens) if l not in special_tokens])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'9 1 0 3 0 8 6 0<|endoftext|>'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode([l for p, l in zip(pred_ans_tokens, lab_ans_tokens) if l not in special_tokens])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!!!!////9 1 0 3 0 8 6 0<|endoftext|>'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode([l for p, l in zip(pred_ans_tokens, lab_ans_tokens)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!!!! 69 1 0 3 2 8 6 0<|endoftext|>'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode([p for p, l in zip(pred_ans_tokens, lab_ans_tokens)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_pred = Holder()\n",
    "\n",
    "eval_pred.predictions = out['logits']\n",
    "eval_pred.label_ids = collated['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy_cot': 1.0, 'accuracy_ans': 1.0}\n"
     ]
    }
   ],
   "source": [
    "acc = compute_accuracy(eval_pred)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = eval_pred.predictions.argmax(axis=-1)[:, :-1]\n",
    "labels = eval_pred.label_ids[:, 1:]\n",
    "\n",
    "labels_masks = labels > 0\n",
    "preds_full = [p[m] for p, m in zip(preds, labels_masks)]\n",
    "labels_full = [lab[m] for lab, m in zip(labels, labels_masks)]\n",
    "\n",
    "acc_cot, acc_ans = [], []\n",
    "correct_samples = []\n",
    "for lab_tokens, pred_tokens in zip(labels_full, preds_full):\n",
    "    ans_start_index = max(i for i, x in enumerate(lab_tokens) if x == ans[0])\n",
    "\n",
    "    pred_cot_tokens = pred_tokens[:ans_start_index].tolist()\n",
    "    lab_cot_tokens = lab_tokens[:ans_start_index].tolist()\n",
    "\n",
    "    cot_correct = [p == l for p, l in zip(pred_cot_tokens, lab_cot_tokens) if l != bos[0]]\n",
    "    acc_cot.append(all(cot_correct))\n",
    "\n",
    "    pred_ans_tokens = pred_tokens[ans_start_index:].tolist()\n",
    "    lab_ans_tokens = lab_tokens[ans_start_index:].tolist()\n",
    "\n",
    "    # ans_correct = [p == l for p, l in zip(pred_ans_tokens, lab_ans_tokens)]\n",
    "    ans_correct = [p == l for p, l in zip(pred_ans_tokens, lab_ans_tokens) if l not in special_tokens]\n",
    "    acc_ans.append(all(ans_correct))\n",
    "    if all(ans_correct):\n",
    "        correct_samples.append(lab_tokens)\n",
    "    # break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['////1 9 7 9 1????////0 0 0 0 0 0 ( 1 9 7 9 1 0 )????////0 0 9 9 1 2 0 ( 1 9 6 9 3 2 0 )????////0 0 0 3 9 3 5 1!!!!////1 9 6 2 3 6 5 1<|endoftext|>',\n",
       " '////4 7 3 4 0????////0 2 2 1 3 1 ( 4 9 5 5 3 1 )????////0 0 8 4 7 8 0 ( 4 9 3 0 1 0 1 )????////0 0 0 8 4 7 8 0!!!!////4 9 3 8 5 7 9 0<|endoftext|>',\n",
       " '////0 0 2 6 2????////0 0 5 5 6 0 ( 0 0 7 1 9 0 )????////0 0 0 0 2 6 2 ( 0 0 7 1 1 7 2 )????////0 0 0 0 0 2 6 2!!!!////0 0 7 1 1 9 8 2<|endoftext|>',\n",
       " '////9 3 1 1 4????////0 2 4 1 9 0 ( 9 5 5 2 3 1 )????////0 0 3 1 7 3 1 ( 9 5 8 3 0 5 1 )????////0 0 0 5 5 8 2 2!!!!////9 5 8 8 5 3 4 2<|endoftext|>',\n",
       " '////5 4 9 7 4????////0 2 1 7 6 7 ( 5 6 0 5 1 8 )????////0 0 6 5 3 8 3 ( 5 6 6 0 5 6 4 )????////0 0 0 2 1 7 6 7!!!!////5 6 6 2 6 3 1 8<|endoftext|>',\n",
       " '////8 4 6 3 5????////0 2 1 4 3 1 ( 8 6 7 7 8 1 )????////0 0 8 1 1 0 2 ( 8 6 5 9 9 1 2 )????////0 0 0 4 5 3 0 6!!!!////8 6 5 3 5 5 2 6<|endoftext|>',\n",
       " '////6 1 2 9 0????////0 0 2 5 1 1 ( 6 1 4 4 2 1 )????////0 0 0 0 0 0 0 ( 6 1 4 4 2 1 0 )????////0 0 0 6 1 2 9 0!!!!////6 1 4 0 4 3 9 0<|endoftext|>',\n",
       " '////0 0 0 0 0????////0 8 1 5 6 0 ( 0 8 1 5 6 0 )????////0 0 2 7 0 6 2 ( 0 8 3 2 7 6 2 )????////0 0 0 7 7 7 9 0!!!!////0 8 3 9 4 4 2 1<|endoftext|>']"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.batch_decode(correct_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['////5 5 5 6 1????////0 0 6 4 9 0 ( 5 5 1 1 1 1 )????////0 0 5 9 0 7 0 ( 5 5 6 0 2 8 0 )????////0 0 0 0 6 4 9 0!!!!////5 5 6 0 8 2 0 1<|endoftext|>',\n",
       " '////6 7 1 1 3????////0 4 8 7 0 2 ( 6 1 0 9 3 2 )????////0 0 4 8 7 0 2 ( 6 1 4 7 1 3 2 )????////0 0 0 2 7 3 6 3!!!!////6 1 4 9 8 6 8 3<|endoftext|>',\n",
       " '////8 0 0 5 7????////0 4 8 3 4 8 ( 8 4 8 8 1 9 )????////0 0 6 7 3 9 0 ( 8 4 4 6 5 8 1 )????////0 0 0 2 3 6 5 6!!!!////8 4 4 8 8 4 7 6<|endoftext|>',\n",
       " '////9 0 9 2 1????////0 2 1 2 7 1 ( 9 2 0 5 8 1 )????////0 0 8 1 8 5 2 ( 9 2 8 6 6 7 2 )????////0 0 0 5 1 5 1 2!!!!////9 2 8 1 8 2 4 2<|endoftext|>',\n",
       " '////0 4 6 8 5????////0 0 5 6 6 3 ( 0 4 1 5 2 4 )????////0 0 0 8 9 3 4 ( 0 4 1 3 2 8 4 )????////0 0 0 0 5 6 6 3!!!!////0 4 1 3 7 4 1 4<|endoftext|>']"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.batch_decode(labels_full[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' ty5 5 5 6 1????????0 0 6 4 9 0 ( 5 5 1 1 1 1 )????????0 0 5 9 0 7 0 ( 5 5 6 0 2 8 0 )????????0 0 0 0 6 4 9 0!!!! 05 5 6 0 1 2 0 1<|endoftext|>',\n",
       " ' deposit6 7 1 1 3????????0 4 8 7 0 2 ( 6 1 0 9 3 2 )????????0 0 4 8 7 0 2 ( 6 1 4 7 1 3 2 )????????0 0 0 2 7 3 6 3!!!! 26 1 4 9 5 6 8 3<|endoftext|>',\n",
       " ' Bild8 0 0 5 7????????0 4 8 3 4 8 ( 8 4 8 8 1 9 )????????0 0 6 7 3 9 0 ( 8 4 4 6 5 8 1 )????????0 0 0 2 3 6 5 6!!!! 28 4 4 8 5 4 7 6<|endoftext|>',\n",
       " ' Hein9 0 9 2 1????????0 2 1 2 7 1 ( 9 2 0 5 8 1 )????????0 0 8 1 8 5 2 ( 9 2 8 6 6 7 2 )????????0 0 0 5 1 5 1 2!!!! 59 2 8 1 3 2 4 2<|endoftext|>',\n",
       " ' fragrance0 4 6 8 5????????0 0 5 6 6 3 ( 0 4 1 5 2 4 )????????0 0 0 8 9 3 4 ( 0 4 1 3 2 8 4 )????????0 0 0 0 5 6 6 3!!!! 00 4 1 3 9 4 1 4<|endoftext|>']"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.batch_decode(preds_full[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'////5 5 5 6 1????////0 0 6 4 9 0 ( 5 5 1 1 1 1 )????////0 0 5 9 0 7 0 ( 5 5 6 0 2 8 0 )????////0 0 0 0 6 4 9 0!!!!////5 5 6 0 8 2 0 1<|endoftext|>'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(labels_full[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'////9 9 0 9 0????////0 2 3 1 2 1 ( 9 1 4 0 3 1 )????////0 0 6 6 0 6 0 ( 9 1 0 7 3 7 0 )????////0 0 0 6 6 0 6 0!!!!////9 1 0 3 0 8 6 0<|endoftext|>'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(lab_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!!!!'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(ans[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans_start_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' ty5 5 5 6 1????????0 0 6 4 9 0 ( 5 5 1 1 1 1 )????????0 0 5 9 0 7 0 ( 5 5 6 0 2 8 0 )????????0 0 0 0 6 4 9 0!!!! 05 5 6 0 1 2 0 1<|endoftext|>',\n",
       " ' deposit6 7 1 1 3????????0 4 8 7 0 2 ( 6 1 0 9 3 2 )????????0 0 4 8 7 0 2 ( 6 1 4 7 1 3 2 )????????0 0 0 2 7 3 6 3!!!! 26 1 4 9 5 6 8 3<|endoftext|>',\n",
       " ' Bild8 0 0 5 7????????0 4 8 3 4 8 ( 8 4 8 8 1 9 )????????0 0 6 7 3 9 0 ( 8 4 4 6 5 8 1 )????????0 0 0 2 3 6 5 6!!!! 28 4 4 8 5 4 7 6<|endoftext|>',\n",
       " ' Hein9 0 9 2 1????????0 2 1 2 7 1 ( 9 2 0 5 8 1 )????????0 0 8 1 8 5 2 ( 9 2 8 6 6 7 2 )????????0 0 0 5 1 5 1 2!!!! 59 2 8 1 3 2 4 2<|endoftext|>',\n",
       " ' fragrance0 4 6 8 5????????0 0 5 6 6 3 ( 0 4 1 5 2 4 )????????0 0 0 8 9 3 4 ( 0 4 1 3 2 8 4 )????????0 0 0 0 5 6 6 3!!!! 00 4 1 3 9 4 1 4<|endoftext|>']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.batch_decode(preds_full[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['////5 5 5 6 1????////0 0 6 4 9 0 ( 5 5 1 1 1 1 )????////0 0 5 9 0 7 0 ( 5 5 6 0 2 8 0 )????////0 0 0 0 6 4 9 0!!!!////5 5 6 0 8 2 0 1<|endoftext|>',\n",
       " '////6 7 1 1 3????////0 4 8 7 0 2 ( 6 1 0 9 3 2 )????////0 0 4 8 7 0 2 ( 6 1 4 7 1 3 2 )????////0 0 0 2 7 3 6 3!!!!////6 1 4 9 8 6 8 3<|endoftext|>',\n",
       " '////8 0 0 5 7????////0 4 8 3 4 8 ( 8 4 8 8 1 9 )????////0 0 6 7 3 9 0 ( 8 4 4 6 5 8 1 )????////0 0 0 2 3 6 5 6!!!!////8 4 4 8 8 4 7 6<|endoftext|>',\n",
       " '////9 0 9 2 1????////0 2 1 2 7 1 ( 9 2 0 5 8 1 )????////0 0 8 1 8 5 2 ( 9 2 8 6 6 7 2 )????////0 0 0 5 1 5 1 2!!!!////9 2 8 1 8 2 4 2<|endoftext|>',\n",
       " '////0 4 6 8 5????////0 0 5 6 6 3 ( 0 4 1 5 2 4 )????////0 0 0 8 9 3 4 ( 0 4 1 3 2 8 4 )????////0 0 0 0 5 6 6 3!!!!////0 4 1 3 7 4 1 4<|endoftext|>']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.batch_decode(labels_full[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['5 5 6 0 1 2 0 1<|endoftext|>',\n",
       " '6 1 4 9 5 6 8 3<|endoftext|>',\n",
       " '8 4 4 8 5 4 7 6<|endoftext|>',\n",
       " '9 2 8 1 3 2 4 2<|endoftext|>',\n",
       " '0 4 1 3 9 4 1 4<|endoftext|>']"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.batch_decode([s[-9:] for s in preds_full[:5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['5 5 6 0 8 2 0 1<|endoftext|>',\n",
       " '6 1 4 9 8 6 8 3<|endoftext|>',\n",
       " '8 4 4 8 8 4 7 6<|endoftext|>',\n",
       " '9 2 8 1 8 2 4 2<|endoftext|>',\n",
       " '0 4 1 3 7 4 1 4<|endoftext|>']"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.batch_decode([s[-9:] for s in labels_full[:5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'9 9 0 9 0????0 2 3 1 2 1 ( 9 1 4 0 3 1 )????0 0 6 6 0 6 0 ( 9 1 0 7 3 7 0 )????0 0 0 6 6 0 6 0'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode([p for p, l in zip(pred_cot_tokens, lab_cot_tokens) if l != bos[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'9 9 0 9 0????0 2 3 1 2 1 ( 9 1 4 0 3 1 )????0 0 6 6 0 6 0 ( 9 1 0 7 3 7 0 )????0 0 0 6 6 0 6 0'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode([l for p, l in zip(pred_cot_tokens, lab_cot_tokens) if l != bos[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True]"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cot_correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.mean([value.item() if isinstance(value, torch.Tensor) else value  for value in proxy_out.values()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['logits', 'hidden_states'])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cell_outputs[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "si = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "////6 9 1 5 * 6 4 4 7????\n",
      "////6 7 1 1 3????\n",
      "////0 4 8 7 0 2 ( 6 1 0 9 3 2 )????\n",
      "////0 0 4 8 7 0 2 ( 6 1 4 7 1 3 2 )????\n",
      "////0 0 0 2 7 3 6 3!!!!\n",
      "////6 1 4 9 8 6 8 3<|endoftext|>\n"
     ]
    }
   ],
   "source": [
    "# inputs\n",
    "for seg in segments[:]:\n",
    "    print(tokenizer.decode(seg['input_ids'][si]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['robees buttons 2 4 5- 2 dunk wellnesspard',\n",
       " '6 7 1 1 3????????',\n",
       " '0 4 8 7 0 2 ( 6 1 0 9 3 2 )???? 9',\n",
       " '0 0 4 8 7 0 2 ( 6 1 4 7 1 3 2 )???? 7',\n",
       " '0 0 0 2 7 3 6 3!!!!!!!!',\n",
       " '6 1 4 9 1 6 8 3<|endoftext|><|endoftext|>']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predictions\n",
    "[tokenizer.decode(o.logits.argmax(dim=-1)[si]) for o in cell_outputs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy(eval_pred):\n",
    "    preds = eval_pred.predictions.argmax(axis=-1)[:, :-1]\n",
    "    labels = eval_pred.label_ids[:, 1:]\n",
    "\n",
    "    labels_masks = labels > 0\n",
    "    preds_full = [p[m] for p, m in zip(preds, labels_masks)]\n",
    "    labels_full = [lab[m] for lab, m in zip(labels, labels_masks)]\n",
    "\n",
    "    special_tokens = {ans[0], bos[0]}\n",
    "    acc_cot, acc_ans = [], []\n",
    "    for lab_tokens, pred_tokens in zip(labels_full, preds_full):\n",
    "        ans_start_index = max(i for i, x in enumerate(lab_tokens) if x == ans[0])\n",
    "\n",
    "        pred_cot_tokens = pred_tokens[:ans_start_index].tolist()\n",
    "        lab_cot_tokens = lab_tokens[:ans_start_index].tolist()\n",
    "\n",
    "        cot_correct = [p == l for p, l in zip(pred_cot_tokens, lab_cot_tokens) if l not in special_tokens]\n",
    "        acc_cot.append(all(cot_correct))\n",
    "\n",
    "        pred_ans_tokens = pred_tokens[ans_start_index:].tolist()\n",
    "        lab_ans_tokens = lab_tokens[ans_start_index:].tolist()\n",
    "\n",
    "        ans_correct = [p == l for p, l in zip(pred_ans_tokens, lab_ans_tokens)]\n",
    "        acc_ans.append(all(ans_correct))\n",
    "\n",
    "    return {'accuracy_cot': np.mean(acc_cot), 'accuracy_ans': np.mean(acc_ans)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ -100,  -100,  -100,  ...,   657,   352, 50256],\n",
       "        [ -100,  -100,  -100,  ...,   807,   513, 50256],\n",
       "        [ -100,  -100,  -100,  ...,   767,   718, 50256],\n",
       "        ...,\n",
       "        [ -100,  -100,  -100,  ...,   807,   657, 50256],\n",
       "        [ -100,  -100,  -100,  ...,   642,   352, 50256],\n",
       "        [ -100,  -100,  -100,  ...,   604,   807, 50256]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = out['logits'].argmax(axis=-1)[:, :-1]\n",
    "labels = collated['labels'][:, 1:]\n",
    "labels_masks = labels > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16 16\n"
     ]
    }
   ],
   "source": [
    "preds_full = [p[m] for p, m in zip(preds, labels_masks)]\n",
    "labels_full = [lab[m] for lab, m in zip(labels, labels_masks)]\n",
    "\n",
    "print(len(preds_full), len(labels_full))\n",
    "\n",
    "preds_full_text = tokenizer.batch_decode(preds_full, add_special_tokens=True)\n",
    "labels_full_text = tokenizer.batch_decode(labels_full, add_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[9805]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "think"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Tensor' object has no attribute 'find'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[75]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mpreds_full\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfind\u001b[49m()\n",
      "\u001b[31mAttributeError\u001b[39m: 'Tensor' object has no attribute 'find'"
     ]
    }
   ],
   "source": [
    "preds_full[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ans(tensor):\n",
    "    tokens = tensor.tolist()\n",
    "    \n",
    "    try:\n",
    "        start_index = max(i for i, x in enumerate(tokens) if x == ans[0])\n",
    "    except ValueError:\n",
    "        return []\n",
    "    \n",
    "    tokens = tokens[start_index + 1:]\n",
    "    \n",
    "    if tokens and tokens[0] == bos[0]:\n",
    "        tokens = tokens[1:]\n",
    "    \n",
    "    return torch.tensor(tokens)\n",
    "\n",
    "def get_cot(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = labels_full[0].tolist()\n",
    "\n",
    "ans_start_index = max(i for i, x in enumerate(tokens) if x == ans[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "lab_tokens = labels_full[0]\n",
    "pred_tokens = preds_full[0]\n",
    "\n",
    "special_tokens = {ans[0], bos[0]}\n",
    "pred_cot_tokens = pred_tokens[:ans_start_index].tolist()\n",
    "lab_cot_tokens = lab_tokens[:ans_start_index].tolist()\n",
    "\n",
    "cot_correct = [p == l for p, l in zip(pred_cot_tokens, lab_cot_tokens) if l not in special_tokens]\n",
    "\n",
    "pred_ans_tokens = pred_tokens[ans_start_index:].tolist()\n",
    "lab_ans_tokens = lab_tokens[ans_start_index:].tolist()\n",
    "\n",
    "ans_correct = [p == l for p, l in zip(pred_ans_tokens, lab_ans_tokens)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(cot_correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8181818181818182"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(ans_correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' 45 5 5 6 1????????0 0 6 4 9 0 ( 5 5 1 1 1 1 )????????0 0 5 9 0 7 0 ( 5 5 6 0 2 8 0 )???? 00 0 0 0 6 4 9 0!!!!!!!!5 5 6 0 7 2 0 1<|endoftext|>'"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(pred_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'5 5 5 6 1????0 0 6 4 9 0 ( 5 5 1 1 1 1 )????0 0 5 9 0 7 0 ( 5 5 6 0 2 8 0 )????0 0 0 0 6 4 9 0'"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# preds\n",
    "tokenizer.decode([p for p, l in zip(pred_cot_tokens, lab_cot_tokens) if l not in special_tokens])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'5 5 5 6 1????0 0 6 4 9 0 ( 5 5 1 1 1 1 )????0 0 5 9 0 7 0 ( 5 5 6 0 2 8 0 )????0 0 0 0 6 4 9 0'"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# labels\n",
    "tokenizer.decode([l for p, l in zip(pred_cot_tokens, lab_cot_tokens) if l not in special_tokens])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[9805, 9805, 9805]"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[l for l in lab_cot_tokens if l not in special_tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9805"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "think[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[132]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mpred_cot_tokens\u001b[49m\u001b[43m.\u001b[49m\u001b[43mshape\u001b[49m\n",
      "\u001b[31mAttributeError\u001b[39m: 'list' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "pred_cot_tokens.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cot_correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9, 9)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(get_ans(preds_full[0])), len(get_ans(labels_full[0])), "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'5 5 6 0 7 2 0 1<|endoftext|>'"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(get_ans(preds_full[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'5 5 6 0 8 2 0 1<|endoftext|>'"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(get_ans(labels_full[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ans(text):\n",
    "    splits = text.split(ans_text)\n",
    "    splits = list(filter(len, splits))\n",
    "    ans = splits[-1].strip()\n",
    "    if ans.startswith(ans_text):\n",
    "        ans = ans[len(ans_text):]\n",
    "    if ans.startswith(bos_text):\n",
    "        ans = ans[len(bos_text):]\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('5 5 6 0 7 2 0 1<|endoftext|>', '5 5 6 0 8 2 0 1<|endoftext|>')"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_ans(preds_full_text[0]), get_ans(labels_full_text[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' 45 5 5 6 1????????0 0 6 4 9 0 ( 5 5 1 1 1 1 )????????0 0 5 9 0 7 0 ( 5 5 6 0 2 8 0 )???? 00 0 0 0 6 4 9 0',\n",
       " '',\n",
       " '5 5 6 0 7 2 0 1<|endoftext|>']"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_full_text[0].split(ans_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['////5 5 5 6 1????////0 0 6 4 9 0 ( 5 5 1 1 1 1 )????////0 0 5 9 0 7 0 ( 5 5 6 0 2 8 0 )????////0 0 0 0 6 4 9 0',\n",
       " '////5 5 6 0 8 2 0 1<|endoftext|>']"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_full_text[0].split(ans_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' 45 5 5 6 1????????0 0 6 4 9 0 ( 5 5 1 1 1 1 )????????0 0 5 9 0 7 0 ( 5 5 6 0 2 8 0 )???? 00 0 0 0 6 4 9 0!!!!!!!!5 5 6 0 7 2 0 1<|endoftext|>',\n",
       " 'pard6 7 1 1 3????????0 4 8 7 0 2 ( 6 1 0 9 3 2 )???? 90 0 4 8 7 0 2 ( 6 1 4 7 1 3 2 )???? 70 0 0 2 7 3 6 3!!!!!!!!6 1 4 9 1 6 8 3<|endoftext|>',\n",
       " ' Doe8 0 0 5 7????????0 4 8 3 4 8 ( 8 4 8 8 1 9 )????????0 0 6 7 3 9 0 ( 8 4 4 6 5 8 1 )???? 60 0 0 2 3 6 5 6!!!!!!!!8 4 4 8 1 4 7 6<|endoftext|>',\n",
       " ' Gentleman9 0 9 2 1????????0 2 1 2 7 1 ( 9 2 0 5 8 1 )???? 50 0 8 1 8 5 2 ( 9 2 8 6 6 7 2 )???? 60 0 0 5 1 5 1 2!!!!!!!!9 2 8 1 0 2 4 2<|endoftext|>',\n",
       " ' drum0 4 6 8 5????????0 0 5 6 6 3 ( 0 4 1 5 2 4 )???? 50 0 0 8 9 3 4 ( 0 4 1 3 2 8 4 )???? 30 0 0 0 5 6 6 3!!!!!!!!0 4 1 3 9 4 1 4<|endoftext|>',\n",
       " ' 42 5 2 4 2????????0 9 8 1 8 1 ( 2 4 1 6 0 2 )???? 60 0 4 0 5 8 4 ( 2 4 5 6 5 0 5 )???? 60 0 0 1 4 4 2 4!!!!!!!!2 4 5 7 1 4 7 4<|endoftext|>',\n",
       " 'hovah8 4 7 9 0????????0 6 6 8 3 4 ( 8 0 4 8 4 4 )???? 80 0 4 7 8 4 0 ( 8 0 8 5 3 9 0 )???? 50 0 0 4 4 2 9 2!!!!!!!!8 0 8 9 9 1 0 3<|endoftext|>',\n",
       " ' ass0 0 0 0 0????????0 0 6 4 8 0 ( 0 0 6 4 8 0 )????????0 0 2 9 6 1 0 ( 0 0 8 3 5 2 0 )???? 30 0 0 8 2 2 5 1!!!!!!!!0 0 8 1 0 4 5 1<|endoftext|>',\n",
       " ' grilled5 5 5 2 2????????0 6 6 0 7 2 ( 5 1 2 3 9 2 )???? 30 0 0 0 0 0 0 ( 5 1 2 3 9 2 0 )???? 30 0 0 5 5 5 2 2!!!! 55 1 2 8 3 8 2 2<|endoftext|>',\n",
       " ' tam0 0 0 0 0????????0 7 3 9 5 3 ( 0 7 3 9 5 3 )????90 0 9 7 9 1 1 ( 0 7 2 7 5 5 1 )???? 70 0 0 9 7 9 1 1!!!!!!!!0 7 2 6 3 5 3 1<|endoftext|>',\n",
       " ' 35 6 8 3 0????????0 0 6 4 5 1 ( 5 6 4 8 5 1 )???? 80 0 5 8 7 4 3 ( 5 6 9 6 3 6 3 )???? 60 0 0 5 5 0 7 2!!!!!!!!5 6 9 1 0 6 0 3<|endoftext|>',\n",
       " ' 84 8 1 4 5????????0 5 6 8 3 3 ( 4 3 8 2 9 3 )???? 20 0 5 6 8 3 3 ( 4 3 3 9 7 7 3 )???? 90 0 0 6 4 5 3 1!!!!!!!!4 3 3 5 0 3 7 1<|endoftext|>',\n",
       " 'eal4 4 8 9 0????????0 9 4 1 2 2 ( 4 3 3 1 3 2 )???? 10 0 8 8 6 9 1 ( 4 3 1 0 0 2 2 )???? 00 0 0 2 2 9 4 0!!!!!!!!4 3 1 2 1 1 7 0<|endoftext|>',\n",
       " ' 66 5 6 7 3????????0 2 3 9 3 4 ( 6 7 9 6 7 4 )????????0 0 2 5 5 2 1 ( 6 7 1 2 3 7 1 )???? 20 0 0 6 7 2 6 0!!!!!!!!6 7 1 8 1 0 8 0<|endoftext|>',\n",
       " ' Grammy0 2 3 1 1????????0 0 0 3 8 2 ( 0 2 3 4 9 2 )???? 40 0 0 6 9 3 3 ( 0 2 3 0 9 6 3 )???? 00 0 0 0 2 3 1 1!!!!!!!!0 2 3 0 0 0 5 1<|endoftext|>',\n",
       " 'kid6 1 2 8 1????????0 8 4 6 4 5 ( 6 9 6 4 6 5 )????40 0 6 1 2 8 1 ( 6 9 2 6 8 3 2 )???? 60 0 0 2 7 9 1 8!!!!!!!!6 9 2 8 2 3 4 8<|endoftext|>']"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_full_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['////5 5 5 6 1????////0 0 6 4 9 0 ( 5 5 1 1 1 1 )????////0 0 5 9 0 7 0 ( 5 5 6 0 2 8 0 )????////0 0 0 0 6 4 9 0!!!!////5 5 6 0 8 2 0 1<|endoftext|>',\n",
       " '////6 7 1 1 3????////0 4 8 7 0 2 ( 6 1 0 9 3 2 )????////0 0 4 8 7 0 2 ( 6 1 4 7 1 3 2 )????////0 0 0 2 7 3 6 3!!!!////6 1 4 9 8 6 8 3<|endoftext|>',\n",
       " '////8 0 0 5 7????////0 4 8 3 4 8 ( 8 4 8 8 1 9 )????////0 0 6 7 3 9 0 ( 8 4 4 6 5 8 1 )????////0 0 0 2 3 6 5 6!!!!////8 4 4 8 8 4 7 6<|endoftext|>',\n",
       " '////9 0 9 2 1????////0 2 1 2 7 1 ( 9 2 0 5 8 1 )????////0 0 8 1 8 5 2 ( 9 2 8 6 6 7 2 )????////0 0 0 5 1 5 1 2!!!!////9 2 8 1 8 2 4 2<|endoftext|>',\n",
       " '////0 4 6 8 5????////0 0 5 6 6 3 ( 0 4 1 5 2 4 )????////0 0 0 8 9 3 4 ( 0 4 1 3 2 8 4 )????////0 0 0 0 5 6 6 3!!!!////0 4 1 3 7 4 1 4<|endoftext|>',\n",
       " '////2 5 2 4 2????////0 9 8 1 8 1 ( 2 4 1 6 0 2 )????////0 0 4 0 5 8 4 ( 2 4 5 6 5 0 5 )????////0 0 0 1 4 4 2 4!!!!////2 4 5 7 9 4 7 4<|endoftext|>',\n",
       " '////8 4 7 9 0????////0 6 6 8 3 4 ( 8 0 4 8 4 4 )????////0 0 4 7 8 4 0 ( 8 0 8 5 3 9 0 )????////0 0 0 4 4 2 9 2!!!!////8 0 8 9 7 1 0 3<|endoftext|>',\n",
       " '////0 0 0 0 0????////0 0 6 4 8 0 ( 0 0 6 4 8 0 )????////0 0 2 9 6 1 0 ( 0 0 8 3 5 2 0 )????////0 0 0 8 2 2 5 1!!!!////0 0 8 1 8 4 5 1<|endoftext|>',\n",
       " '////5 5 5 2 2????////0 6 6 0 7 2 ( 5 1 2 3 9 2 )????////0 0 0 0 0 0 0 ( 5 1 2 3 9 2 0 )????////0 0 0 5 5 5 2 2!!!!////5 1 2 8 4 8 2 2<|endoftext|>',\n",
       " '////0 0 0 0 0????////0 7 3 9 5 3 ( 0 7 3 9 5 3 )????////0 0 9 7 9 1 1 ( 0 7 2 7 5 5 1 )????////0 0 0 9 7 9 1 1!!!!////0 7 2 6 3 5 3 1<|endoftext|>',\n",
       " '////5 6 8 3 0????////0 0 6 4 5 1 ( 5 6 4 8 5 1 )????////0 0 5 8 7 4 3 ( 5 6 9 6 3 6 3 )????////0 0 0 5 5 0 7 2!!!!////5 6 9 1 9 6 0 3<|endoftext|>',\n",
       " '////4 8 1 4 5????////0 5 6 8 3 3 ( 4 3 8 2 9 3 )????////0 0 5 6 8 3 3 ( 4 3 3 9 7 7 3 )????////0 0 0 6 4 5 3 1!!!!////4 3 3 5 2 3 7 1<|endoftext|>',\n",
       " '////4 4 8 9 0????////0 9 4 1 2 2 ( 4 3 3 1 3 2 )????////0 0 8 8 6 9 1 ( 4 3 1 0 0 2 2 )????////0 0 0 2 2 9 4 0!!!!////4 3 1 2 2 1 7 0<|endoftext|>',\n",
       " '////6 5 6 7 3????////0 2 3 9 3 4 ( 6 7 9 6 7 4 )????////0 0 2 5 5 2 1 ( 6 7 1 2 3 7 1 )????////0 0 0 6 7 2 6 0!!!!////6 7 1 8 0 0 8 0<|endoftext|>',\n",
       " '////0 2 3 1 1????////0 0 0 3 8 2 ( 0 2 3 4 9 2 )????////0 0 0 6 9 3 3 ( 0 2 3 0 9 6 3 )????////0 0 0 0 2 3 1 1!!!!////0 2 3 0 1 0 5 1<|endoftext|>',\n",
       " '////6 1 2 8 1????////0 8 4 6 4 5 ( 6 9 6 4 6 5 )????////0 0 6 1 2 8 1 ( 6 9 2 6 8 3 2 )????////0 0 0 2 7 9 1 8!!!!////6 9 2 8 5 3 4 8<|endoftext|>']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_full_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "preds_cot = [extract_cot(p) for p in preds_full_text]\n",
    "preds_ans = [extract_answer(p) for p in preds_full_text]\n",
    "\n",
    "labels_cot = [extract_cot(lab) for lab in labels_full_text]\n",
    "labels_ans = [extract_answer(lab) for lab in labels_full_text]\n",
    "\n",
    "acc_cot = np.mean([c == p for c, p in zip(preds_cot, labels_cot)])\n",
    "acc_ans = np.mean([c == lab for c, lab in zip(preds_ans, labels_ans)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([16, 72]), torch.Size([1, 72]))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.shape, labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[25481,  1666, 13129,  ...,   352, 50256, 50256],\n",
       "        [25481,   274, 12163,  ...,   513, 50256, 50256],\n",
       "        [25481,   274,   513,  ...,   718, 50256, 50256],\n",
       "        ...,\n",
       "        [25481,   274,   513,  ...,   657, 50256, 50256],\n",
       "        [25481,   657,   513,  ...,   352, 50256, 50256],\n",
       "        [25481,    67,   352,  ...,   807, 50256, 50256]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer.decode([segment['labels'][0][0] for segment in segments[1:]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# res_df = pd.DataFrame(columns=['cpt_path', 'cot', 'acc_cot', 'acc_ans'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None, None, None, None, None, None]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[o.loss for o in cell_outputs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model.generation_config.pad_token_id = tokenizer.pad_token_id\n",
    "gen_outputs = [model.generate(inp.reshape(1, -1).to(device), \n",
    "                            pad_token_id=tokenizer.eos_token_id,\n",
    "                            attention_mask=torch.ones_like(inp.reshape(1, -1)).to(device),\n",
    "                            max_new_tokens=50)[0] for inp in collated['input_ids_generate']]\n",
    "\n",
    "if args.use_cot:\n",
    "    gen_outputs = [model.generate(inp.reshape(1, -1).to(device), \n",
    "                                    pad_token_id=tokenizer.eos_token_id,\n",
    "                                    attention_mask=torch.ones_like(inp.reshape(1, -1)).to(device))[0].cpu() for inp in gen_outputs]\n",
    "\n",
    "labels = collated['labels']\n",
    "labels_masks = labels > 0\n",
    "\n",
    "preds_full = [out[len(inp):] for inp, out in zip(collated['input_ids_generate'], gen_outputs)]\n",
    "# preds_full = [out[len(inp):] for inp, out in zip(collated['input_ids_generate'], gen_outputs_m2)]\n",
    "labels_full = [lab[m][1:] for lab, m in zip(labels, labels_masks)]\n",
    "\n",
    "print(len(preds_full), len(labels_full))\n",
    "\n",
    "preds_full_text = tokenizer.batch_decode(preds_full, add_special_tokens=True)\n",
    "labels_full_text = tokenizer.batch_decode(labels_full, add_special_tokens=True)\n",
    "\n",
    "preds_cot = [extract_cot(p) for p in preds_full_text]\n",
    "preds_ans = [extract_answer(p) for p in preds_full_text]\n",
    "\n",
    "labels_cot = [extract_cot(lab) for lab in labels_full_text]\n",
    "labels_ans = [extract_answer(lab) for lab in labels_full_text]\n",
    "\n",
    "acc_cot = np.mean([c == p for c, p in zip(preds_cot, labels_cot)])\n",
    "acc_ans = np.mean([c == lab for c, lab in zip(preds_ans, labels_ans)])\n",
    "\n",
    "data = {\"inputs\": collated['input_ids_generate'],\n",
    "        \"preds_full_text\": preds_full_text, \"labels_full_text\": labels_full_text,\n",
    "        \"preds_cot\": preds_cot, \"labels_cot\": labels_cot,\n",
    "        \"preds_ans\": preds_ans, \"labels_ans\": labels_ans}\n",
    "\n",
    "print(f\"Accuracy COT: {acc_cot}\")\n",
    "print(f\"Accuracy Answer: {acc_ans}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace-SR006.nfs2/Bulatov_A/rmt/runs/gsm8k/gpt2/SEGM_1x1024_1024_LR3e-04/checkpoint-16500/pytorch_model.bin\n",
      "500 500\n",
      "Accuracy COT: 0.172\n",
      "Accuracy Answer: 1.0\n",
      "/workspace-SR006.nfs2/Bulatov_A/rmt/runs/gsm8k/gpt2/SEGM_1x1024_1024_LR1e-03/checkpoint-24500/pytorch_model.bin\n",
      "500 500\n",
      "Accuracy COT: 0.148\n",
      "Accuracy Answer: 1.0\n"
     ]
    }
   ],
   "source": [
    "args.use_cot = False\n",
    "\n",
    "checkpoints = [\n",
    "    \"/workspace-SR006.nfs2/Bulatov_A/rmt/runs/gsm8k/gpt2/SEGM_1x1024_1024_LR3e-04/checkpoint-16500/pytorch_model.bin\",\n",
    "    \"/workspace-SR006.nfs2/Bulatov_A/rmt/runs/gsm8k/gpt2/SEGM_1x1024_1024_LR1e-03/checkpoint-24500/pytorch_model.bin\",\n",
    "]\n",
    "\n",
    "for cpt_path in checkpoints:\n",
    "    print(cpt_path)\n",
    "    acc_cot, acc_ans = evaluate_model_on_dataset(cpt_path, valid_dataset)\n",
    "    res_df.loc[len(res_df)] = [cpt_path.split('/')[-3], args.use_cot, 0, acc_cot]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cpt_path</th>\n",
       "      <th>cot</th>\n",
       "      <th>acc_cot</th>\n",
       "      <th>acc_ans</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SEGM_1x1024_1024_LR1e-03-cot</td>\n",
       "      <td>True</td>\n",
       "      <td>0.172</td>\n",
       "      <td>0.450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SEGM_1x1024_1024_LR3e-04-cot</td>\n",
       "      <td>True</td>\n",
       "      <td>0.156</td>\n",
       "      <td>0.392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SEGM_1x1024_1024_LR3e-04</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SEGM_1x1024_1024_LR1e-03</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.148</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       cpt_path    cot  acc_cot  acc_ans\n",
       "0  SEGM_1x1024_1024_LR1e-03-cot   True    0.172    0.450\n",
       "1  SEGM_1x1024_1024_LR3e-04-cot   True    0.156    0.392\n",
       "2      SEGM_1x1024_1024_LR3e-04  False    0.000    0.172\n",
       "3      SEGM_1x1024_1024_LR1e-03  False    0.000    0.148"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500 500\n",
      "Accuracy COT: 0.148\n",
      "Accuracy Answer: 1.0\n"
     ]
    }
   ],
   "source": [
    "# model.load_state_dict(torch.load(checkpoint_path), strict=False)\n",
    "model.generation_config.pad_token_id = tokenizer.pad_token_id\n",
    "model.to(device)\n",
    "    \n",
    "collated = collate_fn([sample for sample in valid_dataset])\n",
    "model.generation_config.pad_token_id = tokenizer.pad_token_id\n",
    "gen_outputs = [model.generate(inp.reshape(1, -1).to(device), \n",
    "                            pad_token_id=tokenizer.eos_token_id,\n",
    "                            attention_mask=torch.ones_like(inp.reshape(1, -1)).to(device),\n",
    "                            max_new_tokens=50)[0] for inp in collated['input_ids_generate']]\n",
    "\n",
    "gen_outputs_m2 = [model.generate(inp.reshape(1, -1).to(device), \n",
    "                                    pad_token_id=tokenizer.eos_token_id,\n",
    "                                    attention_mask=torch.ones_like(inp.reshape(1, -1)).to(device))[0].cpu() for inp in gen_outputs]\n",
    "\n",
    "labels = collated['labels']\n",
    "labels_masks = labels > 0\n",
    "\n",
    "preds_full = [out[len(inp):] for inp, out in zip(collated['input_ids_generate'], gen_outputs_m2)]\n",
    "labels_full = [lab[m][1:] for lab, m in zip(labels, labels_masks)]\n",
    "\n",
    "print(len(preds_full), len(labels_full))\n",
    "\n",
    "preds_full_text = tokenizer.batch_decode(preds_full, add_special_tokens=True)\n",
    "labels_full_text = tokenizer.batch_decode(labels_full, add_special_tokens=True)\n",
    "\n",
    "preds_cot = [extract_cot(p) for p in preds_full_text]\n",
    "preds_ans = [extract_answer(p) for p in preds_full_text]\n",
    "\n",
    "labels_cot = [extract_cot(lab) for lab in labels_full_text]\n",
    "labels_ans = [extract_answer(lab) for lab in labels_full_text]\n",
    "\n",
    "acc_cot = np.mean([c == p for c, p in zip(preds_cot, labels_cot)])\n",
    "acc_ans = np.mean([c == lab for c, lab in zip(preds_ans, labels_ans)])\n",
    "\n",
    "print(f\"Accuracy COT: {acc_cot}\")\n",
    "print(f\"Accuracy Answer: {acc_ans}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_cot(text):\n",
    "        try:\n",
    "                return text[:text.index(ans_text)]\n",
    "        except ValueError:\n",
    "                return ''\n",
    "\n",
    "def extract_answer(text):\n",
    "        try:\n",
    "                return text.split(ans_text)[1]\n",
    "        except IndexError:\n",
    "                return ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['600<|endoftext|><|endoftext|>',\n",
       " '7.5<|endoftext|><|endoftext|>',\n",
       " '1400<|endoftext|><|endoftext|>',\n",
       " '15<|endoftext|><|endoftext|>',\n",
       " '240<|endoftext|><|endoftext|>',\n",
       " '20<|endoftext|><|endoftext|>',\n",
       " '160<|endoftext|><|endoftext|>',\n",
       " '1.5<|endoftext|><|endoftext|>',\n",
       " '21.75<|endoftext|><|endoftext|>',\n",
       " '21.5<|endoftext|><|endoftext|>',\n",
       " '14<|endoftext|><|endoftext|>',\n",
       " '88<|endoftext|><|endoftext|>',\n",
       " '20<|endoftext|><|endoftext|>',\n",
       " '130<|endoftext|><|endoftext|>',\n",
       " '16.67<|endoftext|><|endoftext|>',\n",
       " '33.33<|endoftext|><|endoftext|>',\n",
       " '25<|endoftext|><|endoftext|>',\n",
       " '-4<|endoftext|><|endoftext|>',\n",
       " '90<|endoftext|><|endoftext|>',\n",
       " '46<|endoftext|><|endoftext|>',\n",
       " '715<|endoftext|><|endoftext|>',\n",
       " '5<|endoftext|><|endoftext|>',\n",
       " '10<|endoftext|><|endoftext|>',\n",
       " '1<|endoftext|><|endoftext|>',\n",
       " '12000<|endoftext|><|endoftext|>',\n",
       " '160<|endoftext|><|endoftext|>',\n",
       " '5<|endoftext|><|endoftext|>',\n",
       " '45<|endoftext|><|endoftext|>',\n",
       " '74<|endoftext|><|endoftext|>',\n",
       " '460<|endoftext|><|endoftext|>',\n",
       " '52<|endoftext|><|endoftext|>',\n",
       " '98<|endoftext|><|endoftext|>',\n",
       " '35<|endoftext|><|endoftext|>',\n",
       " '4<|endoftext|><|endoftext|>',\n",
       " '550<|endoftext|><|endoftext|>',\n",
       " '64<|endoftext|><|endoftext|>',\n",
       " '240<|endoftext|><|endoftext|>',\n",
       " '12<|endoftext|><|endoftext|>',\n",
       " '25<|endoftext|><|endoftext|>',\n",
       " '65<|endoftext|><|endoftext|>',\n",
       " '16<|endoftext|><|endoftext|>',\n",
       " '1240<|endoftext|><|endoftext|>',\n",
       " '50<|endoftext|><|endoftext|>',\n",
       " '135<|endoftext|><|endoftext|>',\n",
       " '2<|endoftext|><|endoftext|>',\n",
       " '65<|endoftext|><|endoftext|>',\n",
       " '6<|endoftext|><|endoftext|>',\n",
       " '30<|endoftext|><|endoftext|>',\n",
       " '9<|endoftext|><|endoftext|>',\n",
       " '10<|endoftext|><|endoftext|>',\n",
       " '50<|endoftext|><|endoftext|>',\n",
       " '35<|endoftext|><|endoftext|>',\n",
       " '12000<|endoftext|><|endoftext|>',\n",
       " '2056<|endoftext|><|endoftext|>',\n",
       " '25<|endoftext|><|endoftext|>',\n",
       " '480<|endoftext|><|endoftext|>',\n",
       " '-3000<|endoftext|><|endoftext|>',\n",
       " '6<|endoftext|><|endoftext|>',\n",
       " '135<|endoftext|><|endoftext|>',\n",
       " '55<|endoftext|><|endoftext|>',\n",
       " '19<|endoftext|><|endoftext|>',\n",
       " '12<|endoftext|><|endoftext|>',\n",
       " '3.6<|endoftext|><|endoftext|>',\n",
       " '19<|endoftext|><|endoftext|>',\n",
       " '130<|endoftext|><|endoftext|>',\n",
       " '50<|endoftext|><|endoftext|>',\n",
       " '2120<|endoftext|><|endoftext|>',\n",
       " '6<|endoftext|><|endoftext|>',\n",
       " '10000<|endoftext|><|endoftext|>',\n",
       " '18<|endoftext|><|endoftext|>',\n",
       " '1350<|endoftext|><|endoftext|>',\n",
       " '15<|endoftext|><|endoftext|>',\n",
       " '2<|endoftext|><|endoftext|>',\n",
       " '80<|endoftext|><|endoftext|>',\n",
       " '20<|endoftext|><|endoftext|>',\n",
       " '15<|endoftext|><|endoftext|>',\n",
       " '66<|endoftext|><|endoftext|>',\n",
       " '57<|endoftext|><|endoftext|>',\n",
       " '60<|endoftext|><|endoftext|>',\n",
       " '60<|endoftext|><|endoftext|>',\n",
       " '10<|endoftext|><|endoftext|>',\n",
       " '54<|endoftext|><|endoftext|>',\n",
       " '312<|endoftext|><|endoftext|>',\n",
       " '0.4<|endoftext|><|endoftext|>',\n",
       " '80<|endoftext|><|endoftext|>',\n",
       " '70<|endoftext|><|endoftext|>',\n",
       " '20<|endoftext|><|endoftext|>',\n",
       " '16<|endoftext|><|endoftext|>',\n",
       " '25<|endoftext|><|endoftext|>',\n",
       " '3<|endoftext|><|endoftext|>',\n",
       " '18000<|endoftext|><|endoftext|>',\n",
       " '60<|endoftext|><|endoftext|>',\n",
       " '720<|endoftext|><|endoftext|>',\n",
       " '32<|endoftext|><|endoftext|>',\n",
       " '20<|endoftext|><|endoftext|>',\n",
       " '16<|endoftext|><|endoftext|>',\n",
       " '9<|endoftext|><|endoftext|>',\n",
       " '100<|endoftext|><|endoftext|>',\n",
       " '70<|endoftext|><|endoftext|>',\n",
       " '1040<|endoftext|><|endoftext|>',\n",
       " '5.5<|endoftext|><|endoftext|>',\n",
       " '145<|endoftext|><|endoftext|>',\n",
       " '2<|endoftext|><|endoftext|>',\n",
       " '16<|endoftext|><|endoftext|>',\n",
       " '55<|endoftext|><|endoftext|>',\n",
       " '216<|endoftext|><|endoftext|>',\n",
       " '15<|endoftext|><|endoftext|>',\n",
       " '90<|endoftext|><|endoftext|>',\n",
       " '80<|endoftext|><|endoftext|>',\n",
       " '8<|endoftext|><|endoftext|>',\n",
       " '336<|endoftext|><|endoftext|>',\n",
       " '825<|endoftext|><|endoftext|>',\n",
       " '360<|endoftext|><|endoftext|>',\n",
       " '1500<|endoftext|><|endoftext|>',\n",
       " '120<|endoftext|><|endoftext|>',\n",
       " '22<|endoftext|><|endoftext|>',\n",
       " '4<|endoftext|><|endoftext|>',\n",
       " '1200<|endoftext|><|endoftext|>',\n",
       " '78<|endoftext|><|endoftext|>',\n",
       " '61.2<|endoftext|><|endoftext|>',\n",
       " '0<|endoftext|><|endoftext|>',\n",
       " '6.25<|endoftext|><|endoftext|>',\n",
       " '24<|endoftext|><|endoftext|>',\n",
       " '8<|endoftext|><|endoftext|>',\n",
       " '9<|endoftext|><|endoftext|>',\n",
       " '50<|endoftext|><|endoftext|>',\n",
       " '24<|endoftext|><|endoftext|>',\n",
       " '8<|endoftext|><|endoftext|>',\n",
       " '440<|endoftext|><|endoftext|>',\n",
       " '130<|endoftext|><|endoftext|>',\n",
       " '10<|endoftext|><|endoftext|>',\n",
       " '195<|endoftext|><|endoftext|>',\n",
       " '6<|endoftext|><|endoftext|>',\n",
       " '-500<|endoftext|><|endoftext|>',\n",
       " '1300<|endoftext|><|endoftext|>',\n",
       " '200<|endoftext|><|endoftext|>',\n",
       " '13<|endoftext|><|endoftext|>',\n",
       " '15<|endoftext|><|endoftext|>',\n",
       " '150<|endoftext|><|endoftext|>',\n",
       " '1.5<|endoftext|><|endoftext|>',\n",
       " '17<|endoftext|><|endoftext|>',\n",
       " '46.4<|endoftext|><|endoftext|>',\n",
       " '12<|endoftext|><|endoftext|>',\n",
       " '31<|endoftext|><|endoftext|>',\n",
       " '11<|endoftext|><|endoftext|>',\n",
       " '90<|endoftext|><|endoftext|>',\n",
       " '55<|endoftext|><|endoftext|>',\n",
       " '40<|endoftext|><|endoftext|>',\n",
       " '35<|endoftext|><|endoftext|>',\n",
       " '119.5<|endoftext|><|endoftext|>',\n",
       " '30<|endoftext|><|endoftext|>',\n",
       " '198<|endoftext|><|endoftext|>',\n",
       " '144<|endoftext|><|endoftext|>',\n",
       " '600<|endoftext|><|endoftext|>',\n",
       " '1<|endoftext|><|endoftext|>',\n",
       " '3<|endoftext|><|endoftext|>',\n",
       " '900<|endoftext|><|endoftext|>',\n",
       " '1800<|endoftext|><|endoftext|>',\n",
       " '63<|endoftext|><|endoftext|>',\n",
       " '25<|endoftext|><|endoftext|>',\n",
       " '14<|endoftext|><|endoftext|>',\n",
       " '38<|endoftext|><|endoftext|>',\n",
       " '14<|endoftext|><|endoftext|>',\n",
       " '100<|endoftext|><|endoftext|>',\n",
       " '23<|endoftext|><|endoftext|>',\n",
       " '3<|endoftext|><|endoftext|>',\n",
       " '190<|endoftext|><|endoftext|>',\n",
       " '3360<|endoftext|><|endoftext|>',\n",
       " '15300<|endoftext|><|endoftext|>',\n",
       " '2.1<|endoftext|><|endoftext|>',\n",
       " '20<|endoftext|><|endoftext|>',\n",
       " '1920<|endoftext|><|endoftext|>',\n",
       " '30<|endoftext|><|endoftext|>',\n",
       " '4<|endoftext|><|endoftext|>',\n",
       " '320<|endoftext|><|endoftext|>',\n",
       " '8<|endoftext|><|endoftext|>',\n",
       " '30<|endoftext|><|endoftext|>',\n",
       " '10<|endoftext|><|endoftext|>',\n",
       " '585<|endoftext|><|endoftext|>',\n",
       " '80<|endoftext|><|endoftext|>',\n",
       " '48<|endoftext|><|endoftext|>',\n",
       " '41<|endoftext|><|endoftext|>',\n",
       " '7200<|endoftext|><|endoftext|>',\n",
       " '43<|endoftext|><|endoftext|>',\n",
       " '3<|endoftext|><|endoftext|>',\n",
       " '61.25<|endoftext|><|endoftext|>',\n",
       " '20<|endoftext|><|endoftext|>',\n",
       " '72<|endoftext|><|endoftext|>',\n",
       " '3.33<|endoftext|><|endoftext|>',\n",
       " '34<|endoftext|><|endoftext|>',\n",
       " '5.5<|endoftext|><|endoftext|>',\n",
       " '60<|endoftext|><|endoftext|>',\n",
       " '2000<|endoftext|><|endoftext|>',\n",
       " '780<|endoftext|><|endoftext|>',\n",
       " '8<|endoftext|><|endoftext|>',\n",
       " '150<|endoftext|><|endoftext|>',\n",
       " '50<|endoftext|><|endoftext|>',\n",
       " '54<|endoftext|><|endoftext|>',\n",
       " '10<|endoftext|><|endoftext|>',\n",
       " '10<|endoftext|><|endoftext|>',\n",
       " '20<|endoftext|><|endoftext|>',\n",
       " '1600<|endoftext|><|endoftext|>',\n",
       " '120<|endoftext|><|endoftext|>',\n",
       " '14<|endoftext|><|endoftext|>',\n",
       " '12<|endoftext|><|endoftext|>',\n",
       " '16<|endoftext|><|endoftext|>',\n",
       " '15<|endoftext|><|endoftext|>',\n",
       " '22000<|endoftext|><|endoftext|>',\n",
       " '8<|endoftext|><|endoftext|>',\n",
       " '480<|endoftext|><|endoftext|>',\n",
       " '21<|endoftext|><|endoftext|>',\n",
       " '1<|endoftext|><|endoftext|>',\n",
       " '50<|endoftext|><|endoftext|>',\n",
       " '26.67<|endoftext|><|endoftext|>',\n",
       " '4200<|endoftext|><|endoftext|>',\n",
       " '20<|endoftext|><|endoftext|>',\n",
       " '46.67<|endoftext|><|endoftext|>',\n",
       " '-20<|endoftext|><|endoftext|>',\n",
       " '24<|endoftext|><|endoftext|>',\n",
       " '14<|endoftext|><|endoftext|>',\n",
       " '22<|endoftext|><|endoftext|>',\n",
       " '9<|endoftext|><|endoftext|>',\n",
       " '72<|endoftext|><|endoftext|>',\n",
       " '19<|endoftext|><|endoftext|>',\n",
       " '53<|endoftext|><|endoftext|>',\n",
       " '4<|endoftext|><|endoftext|>',\n",
       " '21<|endoftext|><|endoftext|>',\n",
       " '9<|endoftext|><|endoftext|>',\n",
       " '70<|endoftext|><|endoftext|>',\n",
       " '180<|endoftext|><|endoftext|>',\n",
       " '86<|endoftext|><|endoftext|>',\n",
       " '18<|endoftext|><|endoftext|>',\n",
       " '27<|endoftext|><|endoftext|>',\n",
       " '32<|endoftext|><|endoftext|>',\n",
       " '82<|endoftext|><|endoftext|>',\n",
       " '12.5<|endoftext|><|endoftext|>',\n",
       " '12<|endoftext|><|endoftext|>',\n",
       " '1260<|endoftext|><|endoftext|>',\n",
       " '30<|endoftext|><|endoftext|>',\n",
       " '144<|endoftext|><|endoftext|>',\n",
       " '13<|endoftext|><|endoftext|>',\n",
       " '58<|endoftext|><|endoftext|>',\n",
       " '-80<|endoftext|><|endoftext|>',\n",
       " '-1<|endoftext|><|endoftext|>',\n",
       " '50<|endoftext|><|endoftext|>',\n",
       " '21<|endoftext|><|endoftext|>',\n",
       " '46<|endoftext|><|endoftext|>',\n",
       " '1895<|endoftext|><|endoftext|>',\n",
       " '135<|endoftext|><|endoftext|>',\n",
       " '32<|endoftext|><|endoftext|>',\n",
       " '5<|endoftext|><|endoftext|>',\n",
       " '1350<|endoftext|><|endoftext|>',\n",
       " '200<|endoftext|><|endoftext|>',\n",
       " '8<|endoftext|><|endoftext|>',\n",
       " '22<|endoftext|><|endoftext|>',\n",
       " '180<|endoftext|><|endoftext|>',\n",
       " '29<|endoftext|><|endoftext|>',\n",
       " '4500<|endoftext|><|endoftext|>',\n",
       " '120<|endoftext|><|endoftext|>',\n",
       " '3<|endoftext|><|endoftext|>',\n",
       " '10.5<|endoftext|><|endoftext|>',\n",
       " '11<|endoftext|><|endoftext|>',\n",
       " '21<|endoftext|><|endoftext|>',\n",
       " '2600<|endoftext|><|endoftext|>',\n",
       " '20<|endoftext|><|endoftext|>',\n",
       " '3<|endoftext|><|endoftext|>',\n",
       " '385<|endoftext|><|endoftext|>',\n",
       " '18<|endoftext|><|endoftext|>',\n",
       " '80<|endoftext|><|endoftext|>',\n",
       " '1.33<|endoftext|><|endoftext|>',\n",
       " '28<|endoftext|><|endoftext|>',\n",
       " '21<|endoftext|><|endoftext|>',\n",
       " '78<|endoftext|><|endoftext|>',\n",
       " '6<|endoftext|><|endoftext|>',\n",
       " '46.4<|endoftext|><|endoftext|>',\n",
       " '80<|endoftext|><|endoftext|>',\n",
       " '14000<|endoftext|><|endoftext|>',\n",
       " '3<|endoftext|><|endoftext|>',\n",
       " '7<|endoftext|><|endoftext|>',\n",
       " '260<|endoftext|><|endoftext|>',\n",
       " '30<|endoftext|><|endoftext|>',\n",
       " '34<|endoftext|><|endoftext|>',\n",
       " '84<|endoftext|><|endoftext|>',\n",
       " '750<|endoftext|><|endoftext|>',\n",
       " '16<|endoftext|><|endoftext|>',\n",
       " '225<|endoftext|><|endoftext|>',\n",
       " '260<|endoftext|><|endoftext|>',\n",
       " '54<|endoftext|><|endoftext|>',\n",
       " '20<|endoftext|><|endoftext|>',\n",
       " '49<|endoftext|><|endoftext|>',\n",
       " '15<|endoftext|><|endoftext|>',\n",
       " '60<|endoftext|><|endoftext|>',\n",
       " '30<|endoftext|><|endoftext|>',\n",
       " '30<|endoftext|><|endoftext|>',\n",
       " '3240<|endoftext|><|endoftext|>',\n",
       " '54<|endoftext|><|endoftext|>',\n",
       " '5<|endoftext|><|endoftext|>',\n",
       " '62.5<|endoftext|><|endoftext|>',\n",
       " '1000<|endoftext|><|endoftext|>',\n",
       " '6<|endoftext|><|endoftext|>',\n",
       " '18<|endoftext|><|endoftext|>',\n",
       " '32<|endoftext|><|endoftext|>',\n",
       " '9<|endoftext|><|endoftext|>',\n",
       " '14<|endoftext|><|endoftext|>',\n",
       " '66.67<|endoftext|><|endoftext|>',\n",
       " '30<|endoftext|><|endoftext|>',\n",
       " '-7<|endoftext|><|endoftext|>',\n",
       " '171<|endoftext|><|endoftext|>',\n",
       " '93<|endoftext|><|endoftext|>',\n",
       " '3000<|endoftext|><|endoftext|>',\n",
       " '306<|endoftext|><|endoftext|>',\n",
       " '4000<|endoftext|><|endoftext|>',\n",
       " '1450<|endoftext|><|endoftext|>',\n",
       " '80<|endoftext|><|endoftext|>',\n",
       " '142.86<|endoftext|><|endoftext|>',\n",
       " '326<|endoftext|><|endoftext|>',\n",
       " '400<|endoftext|><|endoftext|>',\n",
       " '17.5<|endoftext|><|endoftext|>',\n",
       " '7.5<|endoftext|><|endoftext|>',\n",
       " '3<|endoftext|><|endoftext|>',\n",
       " '120<|endoftext|><|endoftext|>',\n",
       " '-5<|endoftext|><|endoftext|>',\n",
       " '36<|endoftext|><|endoftext|>',\n",
       " '1200<|endoftext|><|endoftext|>',\n",
       " '2200<|endoftext|><|endoftext|>',\n",
       " '19<|endoftext|><|endoftext|>',\n",
       " '90<|endoftext|><|endoftext|>',\n",
       " '21<|endoftext|><|endoftext|>',\n",
       " '288<|endoftext|><|endoftext|>',\n",
       " '3600<|endoftext|><|endoftext|>',\n",
       " '28<|endoftext|><|endoftext|>',\n",
       " '4<|endoftext|><|endoftext|>',\n",
       " '60<|endoftext|><|endoftext|>',\n",
       " '6<|endoftext|><|endoftext|>',\n",
       " '15<|endoftext|><|endoftext|>',\n",
       " '4<|endoftext|><|endoftext|>',\n",
       " '71<|endoftext|><|endoftext|>',\n",
       " '700<|endoftext|><|endoftext|>',\n",
       " '200<|endoftext|><|endoftext|>',\n",
       " '31250<|endoftext|><|endoftext|>',\n",
       " '125<|endoftext|><|endoftext|>',\n",
       " '18<|endoftext|><|endoftext|>',\n",
       " '44<|endoftext|><|endoftext|>',\n",
       " '3.5<|endoftext|><|endoftext|>',\n",
       " '20<|endoftext|><|endoftext|>',\n",
       " '130<|endoftext|><|endoftext|>',\n",
       " '8<|endoftext|><|endoftext|>',\n",
       " '20<|endoftext|><|endoftext|>',\n",
       " '1456<|endoftext|><|endoftext|>',\n",
       " '2900<|endoftext|><|endoftext|>',\n",
       " '175<|endoftext|><|endoftext|>',\n",
       " '36<|endoftext|><|endoftext|>',\n",
       " '1040<|endoftext|><|endoftext|>',\n",
       " '15<|endoftext|><|endoftext|>',\n",
       " '8<|endoftext|><|endoftext|>',\n",
       " '3<|endoftext|><|endoftext|>',\n",
       " '600<|endoftext|><|endoftext|>',\n",
       " '-4.5<|endoftext|><|endoftext|>',\n",
       " '-4<|endoftext|><|endoftext|>',\n",
       " '15<|endoftext|><|endoftext|>',\n",
       " '4<|endoftext|><|endoftext|>',\n",
       " '4<|endoftext|><|endoftext|>',\n",
       " '30<|endoftext|><|endoftext|>',\n",
       " '1.5<|endoftext|><|endoftext|>',\n",
       " '1268<|endoftext|><|endoftext|>',\n",
       " '125<|endoftext|><|endoftext|>',\n",
       " '42<|endoftext|><|endoftext|>',\n",
       " '83<|endoftext|><|endoftext|>',\n",
       " '44<|endoftext|><|endoftext|>',\n",
       " '600<|endoftext|><|endoftext|>',\n",
       " '3<|endoftext|><|endoftext|>',\n",
       " '49<|endoftext|><|endoftext|>',\n",
       " '2.67<|endoftext|><|endoftext|>',\n",
       " '54<|endoftext|><|endoftext|>',\n",
       " '80<|endoftext|><|endoftext|>',\n",
       " '5.83<|endoftext|><|endoftext|>',\n",
       " '17<|endoftext|><|endoftext|>',\n",
       " '6<|endoftext|><|endoftext|>',\n",
       " '52<|endoftext|><|endoftext|>',\n",
       " '750<|endoftext|><|endoftext|>',\n",
       " '15<|endoftext|><|endoftext|>',\n",
       " '16<|endoftext|><|endoftext|>',\n",
       " '330<|endoftext|><|endoftext|>',\n",
       " '18000<|endoftext|><|endoftext|>',\n",
       " '2000<|endoftext|><|endoftext|>',\n",
       " '-150<|endoftext|><|endoftext|>',\n",
       " '46.67<|endoftext|><|endoftext|>',\n",
       " '10<|endoftext|><|endoftext|>',\n",
       " '20<|endoftext|><|endoftext|>',\n",
       " '82<|endoftext|><|endoftext|>',\n",
       " '-38400<|endoftext|><|endoftext|>',\n",
       " '45<|endoftext|><|endoftext|>',\n",
       " '9<|endoftext|><|endoftext|>',\n",
       " '23<|endoftext|><|endoftext|>',\n",
       " '90<|endoftext|><|endoftext|>',\n",
       " '2<|endoftext|><|endoftext|>',\n",
       " '5<|endoftext|><|endoftext|>',\n",
       " '18<|endoftext|><|endoftext|>',\n",
       " '505<|endoftext|><|endoftext|>',\n",
       " '143<|endoftext|><|endoftext|>',\n",
       " '3<|endoftext|><|endoftext|>',\n",
       " '35<|endoftext|><|endoftext|>',\n",
       " '660<|endoftext|><|endoftext|>',\n",
       " '98<|endoftext|><|endoftext|>',\n",
       " '32<|endoftext|><|endoftext|>',\n",
       " '-200<|endoftext|><|endoftext|>',\n",
       " '50<|endoftext|><|endoftext|>',\n",
       " '13<|endoftext|><|endoftext|>',\n",
       " '2<|endoftext|><|endoftext|>',\n",
       " '22<|endoftext|><|endoftext|>',\n",
       " '25<|endoftext|><|endoftext|>',\n",
       " '27<|endoftext|><|endoftext|>',\n",
       " '4.5<|endoftext|><|endoftext|>',\n",
       " '225<|endoftext|><|endoftext|>',\n",
       " '91<|endoftext|><|endoftext|>',\n",
       " '3.5<|endoftext|><|endoftext|>',\n",
       " '14<|endoftext|><|endoftext|>',\n",
       " '133.34<|endoftext|><|endoftext|>',\n",
       " '94.50<|endoftext|><|endoftext|>',\n",
       " '700<|endoftext|><|endoftext|>',\n",
       " '4<|endoftext|><|endoftext|>',\n",
       " '64<|endoftext|><|endoftext|>',\n",
       " '10<|endoftext|><|endoftext|>',\n",
       " '6<|endoftext|><|endoftext|>',\n",
       " '75<|endoftext|><|endoftext|>',\n",
       " '96<|endoftext|><|endoftext|>',\n",
       " '8<|endoftext|><|endoftext|>',\n",
       " '3<|endoftext|><|endoftext|>',\n",
       " '10<|endoftext|><|endoftext|>',\n",
       " '35<|endoftext|><|endoftext|>',\n",
       " '150<|endoftext|><|endoftext|>',\n",
       " '40<|endoftext|><|endoftext|>',\n",
       " '7<|endoftext|><|endoftext|>',\n",
       " '20<|endoftext|><|endoftext|>',\n",
       " '27<|endoftext|><|endoftext|>',\n",
       " '3<|endoftext|><|endoftext|>',\n",
       " '8<|endoftext|><|endoftext|>',\n",
       " '19<|endoftext|><|endoftext|>',\n",
       " '450<|endoftext|><|endoftext|>',\n",
       " '180<|endoftext|><|endoftext|>',\n",
       " '3<|endoftext|><|endoftext|>',\n",
       " '25<|endoftext|><|endoftext|>',\n",
       " '320<|endoftext|><|endoftext|>',\n",
       " '58<|endoftext|><|endoftext|>',\n",
       " '12<|endoftext|><|endoftext|>',\n",
       " '27<|endoftext|><|endoftext|>',\n",
       " '180<|endoftext|><|endoftext|>',\n",
       " '1440<|endoftext|><|endoftext|>',\n",
       " '300<|endoftext|><|endoftext|>',\n",
       " '6<|endoftext|><|endoftext|>',\n",
       " '20<|endoftext|><|endoftext|>',\n",
       " '30<|endoftext|><|endoftext|>',\n",
       " '90<|endoftext|><|endoftext|>',\n",
       " '2<|endoftext|><|endoftext|>',\n",
       " '35<|endoftext|><|endoftext|>',\n",
       " '5<|endoftext|><|endoftext|>',\n",
       " '19200<|endoftext|><|endoftext|>',\n",
       " '-5<|endoftext|><|endoftext|>',\n",
       " '-18<|endoftext|><|endoftext|>',\n",
       " '203<|endoftext|><|endoftext|>',\n",
       " '6<|endoftext|><|endoftext|>',\n",
       " '440<|endoftext|><|endoftext|>',\n",
       " '18<|endoftext|><|endoftext|>',\n",
       " '96<|endoftext|><|endoftext|>',\n",
       " '500<|endoftext|><|endoftext|>',\n",
       " '8<|endoftext|><|endoftext|>',\n",
       " '21<|endoftext|><|endoftext|>',\n",
       " '56<|endoftext|><|endoftext|>',\n",
       " '2000<|endoftext|><|endoftext|>',\n",
       " '25<|endoftext|><|endoftext|>',\n",
       " '4.33<|endoftext|><|endoftext|>',\n",
       " '-1489<|endoftext|><|endoftext|>',\n",
       " '100<|endoftext|><|endoftext|>',\n",
       " '9<|endoftext|><|endoftext|>',\n",
       " '2<|endoftext|><|endoftext|>',\n",
       " '8<|endoftext|><|endoftext|>',\n",
       " '4<|endoftext|><|endoftext|>',\n",
       " '12<|endoftext|><|endoftext|>',\n",
       " '90<|endoftext|><|endoftext|>',\n",
       " '30<|endoftext|><|endoftext|>',\n",
       " '20<|endoftext|><|endoftext|>',\n",
       " '1260<|endoftext|><|endoftext|>',\n",
       " '5<|endoftext|><|endoftext|>',\n",
       " '48<|endoftext|><|endoftext|>',\n",
       " '36<|endoftext|><|endoftext|>',\n",
       " '2.92<|endoftext|><|endoftext|>',\n",
       " '5.5<|endoftext|><|endoftext|>',\n",
       " '56<|endoftext|><|endoftext|>',\n",
       " '6<|endoftext|><|endoftext|>',\n",
       " '18<|endoftext|><|endoftext|>',\n",
       " '203<|endoftext|><|endoftext|>',\n",
       " '45<|endoftext|><|endoftext|>',\n",
       " '12<|endoftext|><|endoftext|>',\n",
       " '4<|endoftext|><|endoftext|>',\n",
       " '113<|endoftext|><|endoftext|>',\n",
       " '4<|endoftext|><|endoftext|>',\n",
       " '22<|endoftext|><|endoftext|>',\n",
       " '20<|endoftext|><|endoftext|>',\n",
       " '24<|endoftext|><|endoftext|>',\n",
       " '3<|endoftext|><|endoftext|>']"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_full_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['600', '7.5', '1400', '15', '240', '20', '160', '1.5', '21.75', '21.5']"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_cot[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['300', '10', '1400', '15', '240', '20', '10', '2', '25', '25']"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_cot[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['', '', '', '', '', '', '', '', '', '']"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_ans[:10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['', '', '', '', '', '', '', '', '', '']"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_ans[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 5\n",
      "Accuracy COT: 0.6\n",
      "Accuracy Answer: 1.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "labels = collated['labels'][:, 1:]\n",
    "labels_masks = labels > 0\n",
    "\n",
    "preds_full = [out[len(inp):] for inp, out in zip(collated['input_ids_generate'], gen_outputs_m2)]\n",
    "labels_full = [lab[m][1:] for lab, m in zip(labels, labels_masks)]\n",
    "\n",
    "print(len(preds_full), len(labels_full))\n",
    "\n",
    "preds_full_text = tokenizer.batch_decode(preds_full, add_special_tokens=True)\n",
    "labels_full_text = tokenizer.batch_decode(labels_full, add_special_tokens=True)\n",
    "\n",
    "preds_cot = [extract_cot(p) for p in preds_full_text]\n",
    "preds_ans = [extract_answer(p) for p in preds_full_text]\n",
    "\n",
    "labels_cot = [extract_cot(lab) for lab in labels_full_text]\n",
    "labels_ans = [extract_answer(lab) for lab in labels_full_text]\n",
    "\n",
    "acc_cot = np.mean([c == p for c, p in zip(preds_cot, labels_cot)])\n",
    "acc_ans = np.mean([c == lab for c, lab in zip(preds_ans, labels_ans)])\n",
    "\n",
    "print(f\"Accuracy COT: {acc_cot}\")\n",
    "print(f\"Accuracy Answer: {acc_ans}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'booydar/gsm8k'\n",
    "train_dataset = datasets.load_dataset(dataset, split='train')\n",
    "valid_dataset = datasets.load_dataset(dataset, split='valid')\n",
    "\n",
    "# cot\n",
    "args.use_cot = True\n",
    "\n",
    "checkpoints = [\n",
    "    \"/workspace-SR006.nfs2/Bulatov_A/rmt/runs/gsm8k/gpt2/SEGM_1x1024_1024_LR1e-03-cot/checkpoint-23500/pytorch_model.bin\",\n",
    "    \"/workspace-SR006.nfs2/Bulatov_A/rmt/runs/gsm8k/gpt2/SEGM_1x1024_1024_LR1e-05-cot/checkpoint-5000/pytorch_model.bin\",\n",
    "    \"/workspace-SR006.nfs2/Bulatov_A/rmt/runs/gsm8k/gpt2/SEGM_1x1024_1024_LR3e-04-cot/checkpoint-17500/pytorch_model.bin\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cpt_path = \"/workspace-SR006.nfs2/Bulatov_A/rmt/runs/test/4_by_4_mult/Llama-3.2-1B-Instruct/smol:qa1-5-1:9/SEGM_1x1024_1024_64_LR3e-04-lora-mnc-distill__short/checkpoint-5000/pytorch_model.bin\"\n",
    "# cpt_path = \"/workspace-SR006.nfs2/Bulatov_A/rmt/runs/test/4_by_4_mult/gpt2/SEGM_1x1024_1024_LR3e-04/checkpoint-25000/pytorch_model.bin\"\n",
    "# cpt_path = \"/workspace-SR006.nfs2/Bulatov_A/rmt/runs/gsm8k/gpt2/SEGM_1x1024_1024_LR3e-04/checkpoint-16500/pytorch_model.bin\"\n",
    "cpt_path = \"/workspace-SR006.nfs2/Bulatov_A/rmt/runs/gsm8k/gpt2/SEGM_1x1024_1024_LR1e-03-cot/checkpoint-23500/pytorch_model.bin\"\n",
    "model.load_state_dict(torch.load(cpt_path), strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 100%|██████████| 384620/384620 [00:00<00:00, 935478.06 examples/s] \n",
      "Generating valid split: 100%|██████████| 500/500 [00:00<00:00, 110028.96 examples/s]\n",
      "Generating test split: 100%|██████████| 1319/1319 [00:00<00:00, 242176.81 examples/s]\n",
      "Generating train_no_aug split: 100%|██████████| 6973/6973 [00:00<00:00, 436918.42 examples/s]\n"
     ]
    }
   ],
   "source": [
    "# dataset_dir = \"/workspace-SR006.nfs2/Bulatov_A/rmt/data/implicit_chain_of_thought/4_by_4_mult\"\n",
    "\n",
    "# train_path = os.path.join(dataset_dir, \"train\")\n",
    "# valid_path = os.path.join(dataset_dir, \"valid\")\n",
    "# train_dataset = datasets.load_from_disk(train_path)\n",
    "# valid_dataset = datasets.load_from_disk(valid_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Holder:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "args = Holder()\n",
    "# args.use_cot = False\n",
    "args.use_cot = True\n",
    "args.num_mem_tokens = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "id_pad_value = tokenizer.pad_token_id if tokenizer.pad_token_id is not None else tokenizer.eos_token_id\n",
    "think = ans = tokenizer.bos_token_id\n",
    "eos = tokenizer.eos_token_id\n",
    "\n",
    "def collate_fn(batch):\n",
    "    input_ids, input_ids_generate, labels, labels_mask, attention_mask = [], [], [], [], []\n",
    "    for sample in batch:\n",
    "        task, lab, cot = sample['task'], sample['labels'], sample['cot']\n",
    "        task_tokens = tokenizer.encode(task, add_special_tokens=False)\n",
    "        labels_tokens = tokenizer.encode(lab, add_special_tokens=False)\n",
    "        cot_tokens = tokenizer.encode(cot, add_special_tokens=False)\n",
    "\n",
    "        if args.use_cot:\n",
    "            full_input = task_tokens + [think] + cot_tokens + [ans] + labels_tokens + [eos]\n",
    "            gen_input = task_tokens + [think]\n",
    "        else:\n",
    "            full_input = task_tokens + [ans] + labels_tokens + [eos]\n",
    "            gen_input = task_tokens + [ans]\n",
    "        \n",
    "        inp_ids = torch.tensor(full_input)\n",
    "        input_ids.append(inp_ids)\n",
    "        input_ids_generate.append(torch.tensor(gen_input))\n",
    "\n",
    "\n",
    "        lab = torch.tensor(full_input)\n",
    "        lab[:len(task_tokens)] = -100\n",
    "        labels.append(lab)\n",
    "\n",
    "        lab_mask = torch.ones_like(inp_ids)\n",
    "        lab_mask[:len(task_tokens)] = 0\n",
    "        labels_mask.append(lab_mask)\n",
    "        attention_mask.append(torch.ones_like(inp_ids))\n",
    "\n",
    "    input_ids = pad_sequence(input_ids, padding_value=id_pad_value, batch_first=True)\n",
    "    # input_ids_generate = pad_sequence(input_ids_generate, padding_value=id_pad_value, batch_first=True)\n",
    "    attention_mask = pad_sequence(attention_mask, padding_value=0, batch_first=True)\n",
    "    labels = pad_sequence(labels, padding_value=id_pad_value, batch_first=True)\n",
    "    labels_mask = pad_sequence(labels_mask, padding_value=0, batch_first=True)\n",
    "\n",
    "    collated = {'input_ids': input_ids,\n",
    "                'input_ids_generate': input_ids_generate,\n",
    "                'labels': labels,\n",
    "                'attention_mask': attention_mask,\n",
    "                }\n",
    "    if args.num_mem_tokens is not None:\n",
    "        # add labels mask only for RMT, ARMT\n",
    "        collated['labels_mask'] = labels_mask.bool()\n",
    "    return collated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "think_text = tokenizer.decode(think)\n",
    "ans_text = tokenizer.decode(ans)\n",
    "\n",
    "def extract_cot(text):\n",
    "        try:\n",
    "                return text[:text.index(ans_text)]\n",
    "        except ValueError:\n",
    "                return ''\n",
    "\n",
    "def extract_answer(text):\n",
    "        try:\n",
    "                return text.split(ans_text)[1]\n",
    "        except IndexError:\n",
    "                return ''\n",
    "                \n",
    "def compute_accuracy(eval_pred):\n",
    "        preds = eval_pred.predictions.argmax(axis=-1)[:, 1:-1]\n",
    "        labels = eval_pred.label_ids[:, 2:]\n",
    "\n",
    "        labels_masks = labels > 0\n",
    "        preds_full = [p[m] for p, m in zip(preds, labels_masks)]\n",
    "        labels_full = [lab[m] for lab, m in zip(labels, labels_masks)]\n",
    "\n",
    "        print(len(preds_full), len(labels_full))\n",
    "\n",
    "        preds_full_text = tokenizer.batch_decode(preds_full, add_special_tokens=True)\n",
    "        labels_full_text = tokenizer.batch_decode(labels_full, add_special_tokens=True)\n",
    "\n",
    "        preds_cot = [extract_cot(p) for p in preds_full_text]\n",
    "        preds_ans = [extract_answer(p) for p in preds_full_text]\n",
    "\n",
    "        labels_cot = [extract_cot(lab) for lab in labels_full_text]\n",
    "        labels_ans = [extract_answer(lab) for lab in labels_full_text]\n",
    "\n",
    "        acc_cot = np.mean([c == p for c, p in zip(preds_cot, labels_cot)])\n",
    "        acc_ans = np.mean([c == lab for c, lab in zip(preds_ans, labels_ans)])\n",
    "\n",
    "        return {'accuracy_cot': acc_cot, 'accuracy_ans': acc_ans}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "odict_keys(['loss', 'logits', 'past_key_values'])\n"
     ]
    }
   ],
   "source": [
    "batch = [valid_dataset[i] for i in range(10)]\n",
    "collated = collate_fn(batch)\n",
    "\n",
    "out = model(**collated)\n",
    "print(out.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### no teacher forcing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.generation_config.pad_token_id = tokenizer.pad_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.generation_config.pad_token_id = tokenizer.pad_token_id\n",
    "gen_outputs = [model.generate(inp.reshape(1, -1), \n",
    "                              attention_mask=torch.ones_like(inp.reshape(1, -1)),\n",
    "                              max_new_tokens=50)[0] for inp in collated['input_ids_generate']]\n",
    "\n",
    "gen_outputs_m2 = [model.generate(inp.reshape(1, -1), attention_mask=torch.ones_like(inp.reshape(1, -1)))[0] for inp in gen_outputs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gen_outputs_m2 = [out[len(inp):] for inp, out in zip(collated['input_ids_generate'], gen_outputs_m2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<<4-2=2>> <<2/.5=4>> <<12/4=3>> <<100*3=300>><|endoftext|>300<|endoftext|>',\n",
       " '<<1.5*2=3>> <<3+2.5=5.5>> <<1.5+3+5.5=10>><|endoftext|>10<|endoftext|>',\n",
       " '<<2000*30/100=600>> <<2000-600=1400>><|endoftext|>1400<|endoftext|>',\n",
       " '<<21/7=3>> <<5*3=15>><|endoftext|>15<|endoftext|>',\n",
       " '<<200*3=600>> <<600*0.4=240>><|endoftext|>240<|endoftext|>',\n",
       " '<<1/2*100=50>> <<3/5*50=30>> <<50+30=80>> <<100-80=20>><|endoftext|>20<|endoftext|>',\n",
       " '<<40*2=80>> <<80*2=160>><|endoftext|>160<|endoftext|>',\n",
       " '<<12*2=24>> <<4*1=4>> <<4*3=12>> <<24+4+12=40>> <<40/4=10>><|endoftext|>10<|endoftext|>',\n",
       " '<<2*2.25=4.50>> <<4.50+3.50+4+3.50=15.00>> <<2*2.50=5.00>> <<15+5+3.50=23.50>><|endoftext|>',\n",
       " '<<28/4=7>> <<3*7+1=22>><|endoftext|>22<|endoftext|>']"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.batch_decode(gen_outputs_m2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10\n",
      "Accuracy COT: 0.3\n",
      "Accuracy Answer: 0.6\n"
     ]
    }
   ],
   "source": [
    "preds = gen_outputs_m2\n",
    "labels_masks = labels > 0\n",
    "\n",
    "preds_full = gen_outputs_m2 #[out[len(inp):] for inp, out in zip(collated['input_ids_generate'], gen_outputs_m2)]\n",
    "labels_full = [lab[m][1:] for lab, m in zip(labels, labels_masks)]\n",
    "\n",
    "print(len(preds_full), len(labels_full))\n",
    "\n",
    "preds_full_text = tokenizer.batch_decode(preds_full, add_special_tokens=True)\n",
    "labels_full_text = tokenizer.batch_decode(labels_full, add_special_tokens=True)\n",
    "\n",
    "preds_cot = [extract_cot(p) for p in preds_full_text]\n",
    "preds_ans = [extract_answer(p) for p in preds_full_text]\n",
    "\n",
    "labels_cot = [extract_cot(lab) for lab in labels_full_text]\n",
    "labels_ans = [extract_answer(lab) for lab in labels_full_text]\n",
    "\n",
    "acc_cot = np.mean([c == p for c, p in zip(preds_cot, labels_cot)])\n",
    "acc_ans = np.mean([c == lab for c, lab in zip(preds_ans, labels_ans)])\n",
    "\n",
    "print(f\"Accuracy COT: {acc_cot}\")\n",
    "print(f\"Accuracy Answer: {acc_ans}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<<4-2=2>> <<2/.5=4>> <<12/4=3>> <<100*3=300>><|endoftext|>300<|endoftext|>',\n",
       " '<<1.5*2=3>> <<3+2.5=5.5>> <<1.5+3+5.5=10>><|endoftext|>10<|endoftext|>',\n",
       " '<<2000*30/100=600>> <<2000-600=1400>><|endoftext|>1400<|endoftext|>',\n",
       " '<<21/7=3>> <<5*3=15>><|endoftext|>15<|endoftext|>',\n",
       " '<<200*3=600>> <<600*0.4=240>><|endoftext|>240<|endoftext|>',\n",
       " '<<1/2*100=50>> <<3/5*50=30>> <<50+30=80>> <<100-80=20>><|endoftext|>20<|endoftext|>',\n",
       " '<<40*2=80>> <<80*2=160>><|endoftext|>160<|endoftext|>',\n",
       " '<<12*2=24>> <<4*1=4>> <<4*3=12>> <<24+4+12=40>> <<40/4=10>><|endoftext|>10<|endoftext|>',\n",
       " '<<2*2.25=4.50>> <<4.50+3.50+4+3.50=15.00>> <<2*2.50=5.00>> <<15+5+3.50=23.50>><|endoftext|>',\n",
       " '<<28/4=7>> <<3*7+1=22>><|endoftext|>22<|endoftext|>']"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_full_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<<4-2=2>> <<2/.5=4>> <<12/4=3>> <<100*3=300>><|endoftext|>300<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>',\n",
       " '<<1.5*2=3>> <<3+2.5=5.5>> <<1.5+3+5.5=10>><|endoftext|>10<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>',\n",
       " '<<30/100*2000=600>> <<2000-600=1400>><|endoftext|>1400<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>',\n",
       " '<<21/7=3>> <<5*3=15>><|endoftext|>15<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>',\n",
       " '<<200*3=600>> <<600*.4=240>><|endoftext|>240<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>',\n",
       " '<<1/2*100=50>> <<3/5*50=30>> <<50-30=20>><|endoftext|>20<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>',\n",
       " '<<40/2=20>> <<20/2=10>><|endoftext|>10<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>',\n",
       " '<<12*2=24>> <<4*1=4>> <<3*4=12>> <<24+4+12=40>> <<12+4+4=20>> <<40/20=2>><|endoftext|>2<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>',\n",
       " '<<2*2.25=4.50>> <<2*4=8.00>> <<2*2.50=5.00>> <<4.50+8.00+.50+5.00+3.50+3.50=25.00>><|endoftext|>25<|endoftext|>',\n",
       " '<<32=32>> <<8=8>><|endoftext|>25<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>']"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_full_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<<4-2=2>> <<2/.5=4>> <<12/4=3>> <<100*3=300>>',\n",
       " '<<1.5*2=3>> <<3+2.5=5.5>> <<1.5+3+5.5=10>>',\n",
       " '<<2000*30/100=600>> <<2000-600=1400>>',\n",
       " '<<21/7=3>> <<5*3=15>>',\n",
       " '<<200*3=600>> <<600*0.4=240>>',\n",
       " '<<1/2*100=50>> <<3/5*50=30>> <<50+30=80>> <<100-80=20>>',\n",
       " '<<40*2=80>> <<80*2=160>>',\n",
       " '<<12*2=24>> <<4*1=4>> <<4*3=12>> <<24+4+12=40>> <<40/4=10>>',\n",
       " '<<2*2.25=4.50>> <<4.50+3.50+4+3.50=15.00>> <<2*2.50=5.00>> <<15+5+3.50=23.50>>',\n",
       " '<<28/4=7>> <<3*7+1=22>>']"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_cot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<<4-2=2>> <<2/.5=4>> <<12/4=3>> <<100*3=300>>',\n",
       " '<<1.5*2=3>> <<3+2.5=5.5>> <<1.5+3+5.5=10>>',\n",
       " '<<30/100*2000=600>> <<2000-600=1400>>',\n",
       " '<<21/7=3>> <<5*3=15>>',\n",
       " '<<200*3=600>> <<600*.4=240>>',\n",
       " '<<1/2*100=50>> <<3/5*50=30>> <<50-30=20>>',\n",
       " '<<40/2=20>> <<20/2=10>>',\n",
       " '<<12*2=24>> <<4*1=4>> <<3*4=12>> <<24+4+12=40>> <<12+4+4=20>> <<40/20=2>>',\n",
       " '<<2*2.25=4.50>> <<2*4=8.00>> <<2*2.50=5.00>> <<4.50+8.00+.50+5.00+3.50+3.50=25.00>>',\n",
       " '<<32=32>> <<8=8>>']"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_cot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['300', '10', '1400', '15', '240', '20', '160', '10', '', '22']"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['300', '10', '1400', '15', '240', '20', '10', '2', '25', '25']"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_ans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### teacher forcing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([10, 172]), (10, 173))"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_masks.shape, preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10\n",
      "Accuracy COT: 0.3\n",
      "Accuracy Answer: 0.9\n"
     ]
    }
   ],
   "source": [
    "# preds = eval_pred.predictions.argmax(axis=-1)[:, :-1]\n",
    "# labels = eval_pred.label_ids[:, 1:]\n",
    "\n",
    "preds = out.logits.argmax(dim=-1).cpu().numpy()[:, :-1]\n",
    "labels = collated['labels'][:, 1:]\n",
    "\n",
    "labels_masks = labels > 0\n",
    "# labels_masks[:, :1] = False\n",
    "preds_full = [p[m][1:] for p, m in zip(preds, labels_masks)]\n",
    "labels_full = [lab[m][1:] for lab, m in zip(labels, labels_masks)]\n",
    "\n",
    "print(len(preds_full), len(labels_full))\n",
    "\n",
    "preds_full_text = tokenizer.batch_decode(preds_full, add_special_tokens=True)\n",
    "labels_full_text = tokenizer.batch_decode(labels_full, add_special_tokens=True)\n",
    "\n",
    "preds_cot = [extract_cot(p) for p in preds_full_text]\n",
    "preds_ans = [extract_answer(p) for p in preds_full_text]\n",
    "\n",
    "labels_cot = [extract_cot(lab) for lab in labels_full_text]\n",
    "labels_ans = [extract_answer(lab) for lab in labels_full_text]\n",
    "\n",
    "acc_cot = np.mean([c == p for c, p in zip(preds_cot, labels_cot)])\n",
    "acc_ans = np.mean([c == lab for c, lab in zip(preds_ans, labels_ans)])\n",
    "\n",
    "print(f\"Accuracy COT: {acc_cot}\")\n",
    "print(f\"Accuracy Answer: {acc_ans}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<<4-2=2>> <<2/.5=4>> <<12/4=3>> <<100*3=300>><|endoftext|>300<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>',\n",
       " '<<1.5*2=3>> <<3+2.5=5.5>> <<1.5+3+5.5=10>><|endoftext|>10<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>',\n",
       " '<<2000/100*2000=600>> <<2000-600=1400>><|endoftext|>1400<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>',\n",
       " '<<21/7=3>> <<5*3=15>><|endoftext|>15<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>',\n",
       " '<<200*3=600>> <<600*4=240>><|endoftext|>240<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>',\n",
       " '<<1/2*100=50>> <<3/5*50=30>> <<50+30=20>><|endoftext|>20<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>',\n",
       " '<<40*2=20>> <<20/2=10>><|endoftext|>10<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>',\n",
       " '<<12*2=24>> <<4*1=4>> <<4*4=12>> <<24+4+12=40>> <<40+4+12=20>> <<40/20=2>><|endoftext|>2<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>',\n",
       " '<<2*2.25=4.50>> <<4*4=8.00>> <<2*2.50=5.00>> <<4.50+8+00+50+5+00+3.50=2.50=28.00>><|endoftext|>25<|endoftext|>',\n",
       " '<<28/32>> <<(.8>> <<8<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>']"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_full_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<<4-2=2>> <<2/.5=4>> <<12/4=3>> <<100*3=300>><|endoftext|>300<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>',\n",
       " '<<1.5*2=3>> <<3+2.5=5.5>> <<1.5+3+5.5=10>><|endoftext|>10<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>',\n",
       " '<<30/100*2000=600>> <<2000-600=1400>><|endoftext|>1400<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>',\n",
       " '<<21/7=3>> <<5*3=15>><|endoftext|>15<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>',\n",
       " '<<200*3=600>> <<600*.4=240>><|endoftext|>240<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>',\n",
       " '<<1/2*100=50>> <<3/5*50=30>> <<50-30=20>><|endoftext|>20<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>',\n",
       " '<<40/2=20>> <<20/2=10>><|endoftext|>10<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>',\n",
       " '<<12*2=24>> <<4*1=4>> <<3*4=12>> <<24+4+12=40>> <<12+4+4=20>> <<40/20=2>><|endoftext|>2<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>',\n",
       " '<<2*2.25=4.50>> <<2*4=8.00>> <<2*2.50=5.00>> <<4.50+8.00+.50+5.00+3.50+3.50=25.00>><|endoftext|>25<|endoftext|>',\n",
       " '<<32=32>> <<8=8>><|endoftext|>25<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>']"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_full_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<<4-2=2>> <<2/.5=4>> <<12/4=3>> <<100*3=300>>',\n",
       " '<<1.5*2=3>> <<3+2.5=5.5>> <<1.5+3+5.5=10>>',\n",
       " '<<2000/100*2000=600>> <<2000-600=1400>>',\n",
       " '<<21/7=3>> <<5*3=15>>',\n",
       " '<<200*3=600>> <<600*4=240>>',\n",
       " '<<1/2*100=50>> <<3/5*50=30>> <<50+30=20>>',\n",
       " '<<40*2=20>> <<20/2=10>>',\n",
       " '<<12*2=24>> <<4*1=4>> <<4*4=12>> <<24+4+12=40>> <<40+4+12=20>> <<40/20=2>>',\n",
       " '<<2*2.25=4.50>> <<4*4=8.00>> <<2*2.50=5.00>> <<4.50+8+00+50+5+00+3.50=2.50=28.00>>',\n",
       " '<<28/32>> <<(.8>> <<8']"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_cot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<<4-2=2>> <<2/.5=4>> <<12/4=3>> <<100*3=300>>',\n",
       " '<<1.5*2=3>> <<3+2.5=5.5>> <<1.5+3+5.5=10>>',\n",
       " '<<2000/100*2000=600>> <<2000-600=1400>>',\n",
       " '<<21/7=3>> <<5*3=15>>',\n",
       " '<<200*3=600>> <<600*4=240>>',\n",
       " '<<1/2*100=50>> <<3/5*50=30>> <<50+30=20>>',\n",
       " '<<40*2=20>> <<20/2=10>>',\n",
       " '<<12*2=24>> <<4*1=4>> <<4*4=12>> <<24+4+12=40>> <<40+4+12=20>> <<40/20=2>>',\n",
       " '<<2*2.25=4.50>> <<4*4=8.00>> <<2*2.50=5.00>> <<4.50+8+00+50+5+00+3.50=2.50=28.00>>',\n",
       " '<<28/32>> <<(.8>> <<8']"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_cot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['300', '10', '1400', '15', '240', '20', '10', '2', '25', '']"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['300', '10', '1400', '15', '240', '20', '10', '2', '25', '25']"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_ans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Older pretokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torch.nn.utils.rnn import pad_sequence\n",
    "# id_pad_value = tokenizer.pad_token_id if tokenizer.pad_token_id is not None else tokenizer.eos_token_id\n",
    "# if args.use_cot in (False, None):\n",
    "#     inputs_key = 'examples_nocot'\n",
    "#     labels_key = 'labels_nocot'\n",
    "# else:\n",
    "#     inputs_key = 'examples_all'\n",
    "#     labels_key = 'labels_all'\n",
    "    \n",
    "# def collate_fn(batch):\n",
    "#     input_ids = [torch.tensor(b[inputs_key]) for b in batch]\n",
    "#     labels = [torch.tensor(b[labels_key]) for b in batch]\n",
    "#     attention_mask = [torch.ones_like(b, dtype=int) for b in input_ids]\n",
    "#     # labels_mask defines which input_ids participate in loss calculation\n",
    "#     labels_mask = [torch.sign(torch.tensor(b[labels_key])) for b in batch]\n",
    "\n",
    "\n",
    "#     input_ids = pad_sequence(input_ids, padding_value=id_pad_value, batch_first=True)\n",
    "#     labels = pad_sequence(labels, padding_value=id_pad_value, batch_first=True)\n",
    "#     attention_mask = pad_sequence(attention_mask, padding_value=0, batch_first=True)\n",
    "#     labels_mask = pad_sequence(labels_mask, padding_value=0, batch_first=True)\n",
    "\n",
    "#     collated = {'input_ids': input_ids,\n",
    "#                 'labels': labels, \n",
    "#                 'attention_mask': attention_mask,\n",
    "#                 }\n",
    "#     if args.num_mem_tokens is not None:\n",
    "#         # add labels mask only for RMT, ARMT\n",
    "#         collated['labels_mask'] = labels_mask.bool()\n",
    "#     return collated\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def extract_cot(text):\n",
    "#     if '<|endoftext|>' not in text:\n",
    "#         return ''\n",
    "#     else:\n",
    "#         return text.split('<|endoftext|>')[0].strip()\n",
    "\n",
    "# def extract_answer(text):\n",
    "#     if '####' not in text:\n",
    "#         return ''\n",
    "#     else:\n",
    "#         ans = text.split('####')[-1]\n",
    "#         ans = ans.split('<|endoftext|>')[0]\n",
    "#         return ans.strip()\n",
    "        \n",
    "# def compute_accuracy(eval_pred):\n",
    "#     preds = eval_pred.predictions[:, :-1]\n",
    "#     labels = eval_pred.label_ids[:, 1:]\n",
    "#     # inputs = eval_pred.inputs\n",
    "#     # losses = eval_pred.losses\n",
    "\n",
    "#     # labels = collated['labels'][:, 1:]\n",
    "\n",
    "#     labels_masks = labels > 0\n",
    "#     preds_full = [p[m] for p, m in zip(preds, labels_masks)]\n",
    "#     labels_full = [l[m] for l, m in zip(labels, labels_masks)]\n",
    "\n",
    "#     preds_full_text = tokenizer.batch_decode(preds_full, add_special_tokens=True)\n",
    "#     labels_full_text = tokenizer.batch_decode(labels_full, add_special_tokens=True)\n",
    "\n",
    "#     preds_cot = [extract_cot(p) for p in preds_full_text]\n",
    "#     preds_ans = [extract_answer(p) for p in preds_full_text]\n",
    "\n",
    "#     labels_cot = [extract_cot(l) for l in labels_full_text]\n",
    "#     labels_ans = [extract_answer(l) for l in labels_full_text]\n",
    "    \n",
    "#     # Calculate accuracy only on the unignored tokens\n",
    "#     acc_cot = np.mean([c == l for c, l in zip(preds_cot, labels_cot)])\n",
    "#     acc_ans = np.mean([c == l for c, l in zip(preds_ans, labels_ans)])\n",
    "\n",
    "#     return {'accuracy_cot': acc_cot, 'accuracy_ans': acc_ans}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions = eval_pred.predictions\n",
    "# label_ids = eval_pred.label_ids\n",
    "# inputs = eval_pred.inputs\n",
    "# losses = eval_pred.losses\n",
    "# # elements = (self.predictions, self.label_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "odict_keys(['loss', 'logits', 'past_key_values'])\n"
     ]
    }
   ],
   "source": [
    "batch = [valid_dataset[i] for i in range(10)]\n",
    "collated = collate_fn(batch)\n",
    "\n",
    "out = model(**collated)\n",
    "print(out.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0672, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 175)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = out.logits.argmax(dim=-1).cpu().numpy()\n",
    "preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_text = tokenizer.batch_decode(preds, add_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preds_text[0].split('<|endoftext|>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ''.split('<|endoftext|>')[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = collated['labels'][:, 1:]\n",
    "\n",
    "labels_masks = labels > 0\n",
    "preds_full = [p[m] for p, m in zip(preds[:, :-1], labels_masks)]\n",
    "labels_full = [l[m] for l, m in zip(labels, labels_masks)]\n",
    "\n",
    "preds_full_text = tokenizer.batch_decode(preds_full, add_special_tokens=True)\n",
    "labels_full_text = tokenizer.batch_decode(labels_full, add_special_tokens=True)\n",
    "\n",
    "preds_cot = [extract_cot(p) for p in preds_full_text]\n",
    "preds_ans = [extract_answer(p) for p in preds_full_text]\n",
    "\n",
    "labels_cot = [extract_cot(l) for l in labels_full_text]\n",
    "labels_ans = [extract_answer(l) for l in labels_full_text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels = collated['labels'][:, 1:]\n",
    "\n",
    "# labels_masks = labels > 0\n",
    "# preds_full = [p[m] for p, m in zip(preds[:, :-1], labels_masks)]\n",
    "# labels_full = [l[m] for l, m in zip(labels, labels_masks)]\n",
    "\n",
    "# preds_full_text = tokenizer.batch_decode(preds_full, add_special_tokens=True)\n",
    "# labels_full_text = tokenizer.batch_decode(labels_full, add_special_tokens=True)\n",
    "\n",
    "# preds_cot = [p.split('<|endoftext|>')[0].strip() for p in preds_full_text]\n",
    "# labels_cot = [l.split('<|endoftext|>')[0].strip() for l in labels_full_text]\n",
    "\n",
    "# # preds_ans = [p.split('<|endoftext|>')[1].strip()[4:] for p in preds_full_text]\n",
    "# # labels_ans = [l.split('<|endoftext|>')[1].strip()[4:] for l in labels_full_text]\n",
    "\n",
    "# preds_ans = [p.split('####')[1].strip()[4:] for p in preds_full_text]\n",
    "# labels_ans = [l.split('####')[1].split('astrip()[4:] for l in labels_full_text]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['John cuts his grass to 2 inches.  It grows .5 inches per month.  When it gets to 4 inches he cuts it back down to 2 inches.  It cost $100 to get his grass cut.  How much does he pay per year?<|endoftext|><<4-2=2>> <<2/.5=4>> <<12/4=3>> <<100*3=300>><|endoftext|>300<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>',\n",
       " 'Hannah has three dogs. The first dog eats 1.5 cups of dog food a day. The second dog eats twice as much while the third dog eats 2.5 cups more than the second dog. How many cups of dog food should Hannah prepare in a day for her three dogs?<|endoftext|><<1.5*2=3>> <<3+2.5=5.5>> <<1.5+3+5.5=10>><|endoftext|>10<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>',\n",
       " 'Travis wants to fly to Australia. The regular tickets cost about $2000. As Travis is a student, he will get a 30% discount on this price. How much does he need to pay for his ticket?<|endoftext|><<30/100*2000=600>> <<2000-600=1400>><|endoftext|>1400<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>',\n",
       " 'A set of 7 spoons costs $21. If each spoon would be sold separately, how much would 5 spoons cost?<|endoftext|><<21/7=3>> <<5*3=15>><|endoftext|>15<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>',\n",
       " 'Tom bought his games for $200.  They tripled in value and he then sold 40% of them.  How much did he sell the games for?<|endoftext|><<200*3=600>> <<600*.4=240>><|endoftext|>240<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>',\n",
       " \"Maggie went to Lou's aquarium and saw 100 goldfish in the aquarium. She asked if she could take some home to care for, and she was allowed to catch half of them. While using a catching net, she caught 3/5 of the total number of goldfish she was allowed to take home. How many goldfish does Maggie remain with to catch to get the total number she was allowed to take home?<|endoftext|><<1/2*100=50>> <<3/5*50=30>> <<50-30=20>><|endoftext|>20<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>\",\n",
       " 'Kenny played basketball last week. He ran for twice as long as he played basketball, and he practiced on the trumpet for twice as long as he ran. If he practiced on the trumpet for 40 hours, how many hours did Kenny play basketball last week?<|endoftext|><<40/2=20>> <<20/2=10>><|endoftext|>10<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>',\n",
       " 'Marcia wants to buy some fruit. Apples cost $2, bananas cost $1, and oranges cost $3. If Marcia buys 12 apples, 4 bananas and 4 oranges, what is the average cost of each piece of fruit in dollars?<|endoftext|><<12*2=24>> <<4*1=4>> <<3*4=12>> <<24+4+12=40>> <<12+4+4=20>> <<40/20=2>><|endoftext|>2<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>',\n",
       " \"It’s Meghan’s turn to pick up her team's coffee order.  She needs 2 drip coffees that are $2.25 each and one double shot espresso that’s $3.50.  She needs 2 lattes that are $4.00 and needs to add vanilla syrup to one of those for an additional $0.50.  She also needs 2 cold brew coffees that are $2.50 each and 1 cappuccino for $3.50.  How much is the coffee order?<|endoftext|><<2*2.25=4.50>> <<2*4=8.00>> <<2*2.50=5.00>> <<4.50+8.00+.50+5.00+3.50+3.50=25.00>><|endoftext|>25<|endoftext|>\",\n",
       " 'Roman and Remy took separate showers. Remy used 1 more gallon than 3 times the number of gallons that Roman used for his shower. Together the boys used 33 gallons of water.  How many gallons did Remy use?<|endoftext|><<32=32>> <<8=8>><|endoftext|>25<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.batch_decode(collated['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<|endoftext|><<4-2=2>> <<2/.5=4>> <<12/4=3>> <<100*3=300>><|endoftext|>300<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>',\n",
       " '<|endoftext|><<1.5*2=3>> <<3+2.5=5.5>> <<1.5+3+5.5=10>><|endoftext|>10<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>',\n",
       " '<|endoftext|><<30/100*2000=600>> <<2000-600=1400>><|endoftext|>1400<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>',\n",
       " '<|endoftext|><<21/7=3>> <<5*3=15>><|endoftext|>15<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>',\n",
       " '<|endoftext|><<200*3=600>> <<600*.4=240>><|endoftext|>240<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>',\n",
       " '<|endoftext|><<1/2*100=50>> <<3/5*50=30>> <<50-30=20>><|endoftext|>20<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>',\n",
       " '<|endoftext|><<40/2=20>> <<20/2=10>><|endoftext|>10<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>',\n",
       " '<|endoftext|><<12*2=24>> <<4*1=4>> <<3*4=12>> <<24+4+12=40>> <<12+4+4=20>> <<40/20=2>><|endoftext|>2<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>',\n",
       " '<|endoftext|><<2*2.25=4.50>> <<2*4=8.00>> <<2*2.50=5.00>> <<4.50+8.00+.50+5.00+3.50+3.50=25.00>><|endoftext|>25<|endoftext|>',\n",
       " '<|endoftext|><<32=32>> <<8=8>><|endoftext|>25<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_full_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['', '', '', '', '', '', '', '', '', '']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_cot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['', '', '', '', '', '', '', '', '', '']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_cot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['', '', '', '', '', '', '', '', '', '']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['', '', '', '', '', '', '', '', '', '']"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'labels_text' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[27]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mlabels_text\u001b[49m\n\u001b[32m      2\u001b[39m [\u001b[32m0\u001b[39m].split(\u001b[33m'\u001b[39m\u001b[33m<|endoftext|>\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'labels_text' is not defined"
     ]
    }
   ],
   "source": [
    "labels_text\n",
    "[0].split('<|endoftext|>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'labels_mask'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[28]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m p, l, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(preds, collated[\u001b[33m'\u001b[39m\u001b[33mlabels\u001b[39m\u001b[33m'\u001b[39m], \u001b[43mcollated\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mlabels_mask\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m):\n\u001b[32m      2\u001b[39m     \u001b[38;5;28mprint\u001b[39m(p[m], l[m])\n",
      "\u001b[31mKeyError\u001b[39m: 'labels_mask'"
     ]
    }
   ],
   "source": [
    "for p, l, m in zip(preds, collated['labels'], collated['labels_mask']):\n",
    "    print(p[m], l[m])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   11,   860,   860,   604,  1635,   657,   657,   767,   657,\n",
       "         642,   642,   642,   642,   718,   352,  1343,   657,   657,\n",
       "         718,   604,   860,   657,   357,   642,   642,   352,   352,\n",
       "         352,   352,  1267,  1343,   657,   657,   642,   860,   657,\n",
       "         767,   657,   357,   642,   642,   718,   657,   362,   807,\n",
       "         657,  1267,  1343,   657,   657,   657,   657,   718,   604,\n",
       "         860,   657,   220, 50256,  1303, 21017,   642,   642,   718,\n",
       "         657,   807,   362,   657,   352,   220, 50256,  1303])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[', 9 9 4 * 0 0 7 0 5 5 5 5 6 1 + 0 0 6 4 9 0 ( 5 5 1 1 1 1 ) + 0 0 5 9 0 7 0 ( 5 5 6 0 2 8 0 ) + 0 0 0 0 6 4 9 0 <|endoftext|> #### 5 5 6 0 8 2 0 1 <|endoftext|> #', ' the 0 1 6 0 1 0 8 3 6 6 7 1 1 3 + 0 4 8 7 0 2 ( 6 1 0 9 3 2 ) + 0 0 4 8 7 0 2 ( 6 1 4 7 1 3 2 ) + 0 0 0 2 7 3 6 3 <|endoftext|> #### 6 1 4 9 8 6 8 3 <|endoftext|> #', ' the 0 8 4 + 2 8 3 0 8 8 0 0 5 7 + 0 4 8 3 4 8 ( 8 4 8 8 1 9 ) + 0 0 6 7 3 9 0 ( 8 4 4 6 5 8 1 ) + 0 0 0 2 3 6 5 6 <|endoftext|> #### 8 4 4 8 8 4 7 6 <|endoftext|> #', ', 2 3 2\\n 0 0 0 1 9 9 0 9 2 1 + 0 2 1 2 7 1 ( 9 2 0 5 8 1 ) + 0 0 8 1 8 5 2 ( 9 2 8 6 6 7 2 ) + 0 0 0 5 1 5 1 2 <|endoftext|> #### 9 2 8 1 8 2 4 2 <|endoftext|> #', ' the 1 - 0 0 0 1 3 2 0 0 4 6 8 5 + 0 0 5 6 6 3 ( 0 4 1 5 2 4 ) + 0 0 0 8 9 3 4 ( 0 4 1 3 2 8 4 ) + 0 0 0 0 5 6 6 3 <|endoftext|> #### 0 4 1 3 7 4 1 4 <|endoftext|> #', ', 4 5 1 0 8 2 8 1 2 2 5 2 4 2 + 0 9 8 1 8 1 ( 2 4 1 6 0 2 ) + 0 0 4 0 5 8 4 ( 2 4 5 6 5 0 5 ) + 0 0 0 1 4 4 2 4 <|endoftext|> #### 2 4 5 7 9 4 7 4 <|endoftext|> #', ' the 7 0 9\\n 0 8 3 0 0 8 4 7 9 0 + 0 6 6 8 3 4 ( 8 0 4 8 4 4 ) + 0 0 4 7 8 4 0 ( 8 0 8 5 3 9 0 ) + 0 0 0 4 4 2 9 2 <|endoftext|> #### 8 0 8 9 7 1 0 3 <|endoftext|> #', ', 3 9 2 0 0 0 3 0 0 0 0 0 0 0 + 0 0 6 4 8 0 ( 0 0 6 4 8 0 ) + 0 0 2 9 6 1 0 ( 0 0 8 3 5 2 0 ) + 0 0 0 8 2 2 5 1 <|endoftext|> #### 0 0 8 1 8 4 5 1 <|endoftext|> #', ', 7 7 3average 1 0 0 2 5 5 5 5 2 2 + 0 6 6 0 7 2 ( 5 1 2 3 9 2 ) + 0 0 0 0 0 0 0 ( 5 1 2 3 9 2 0 ) + 0 0 0 5 5 5 2 2 <|endoftext|> #### 5 1 2 8 4 8 2 2 <|endoftext|> #', ', 5 9 1ACH 0 3 7 0 0 0 0 0 0 0 + 0 7 3 9 5 3 ( 0 7 3 9 5 3 ) + 0 0 9 7 9 1 1 ( 0 7 2 7 5 5 1 ) + 0 0 0 9 7 9 1 1 <|endoftext|> #### 0 7 2 6 3 5 3 1 <|endoftext|> #']\n"
     ]
    }
   ],
   "source": [
    "pred_texts = tokenizer.batch_decode(preds, skip_special_tokens=False)\n",
    "print(pred_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' 5 6 3 2 * 7 4 3 4 <|endoftext|> 5 5 5 6 1 + 0 0 6 4 9 0 ( 5 5 1 1 1 1 ) + 0 0 5 9 0 7 0 ( 5 5 6 0 2 8 0 ) + 0 0 0 0 6 4 9 0 <|endoftext|> #### 5 5 6 0 8 2 0 1 <|endoftext|>', ' 6 9 1 5 * 6 4 4 7 <|endoftext|> 6 7 1 1 3 + 0 4 8 7 0 2 ( 6 1 0 9 3 2 ) + 0 0 4 8 7 0 2 ( 6 1 4 7 1 3 2 ) + 0 0 0 2 7 3 6 3 <|endoftext|> #### 6 1 4 9 8 6 8 3 <|endoftext|>', ' 6 7 3 9 * 8 9 1 7 <|endoftext|> 8 0 0 5 7 + 0 4 8 3 4 8 ( 8 4 8 8 1 9 ) + 0 0 6 7 3 9 0 ( 8 4 4 6 5 8 1 ) + 0 0 0 2 3 6 5 6 <|endoftext|> #### 8 4 4 8 8 4 7 6 <|endoftext|>', ' 3 0 3 4 * 3 4 6 5 <|endoftext|> 9 0 9 2 1 + 0 2 1 2 7 1 ( 9 2 0 5 8 1 ) + 0 0 8 1 8 5 2 ( 9 2 8 6 6 7 2 ) + 0 0 0 5 1 5 1 2 <|endoftext|> #### 9 2 8 1 8 2 4 2 <|endoftext|>', ' 0 3 3 7 * 8 5 6 5 <|endoftext|> 0 4 6 8 5 + 0 0 5 6 6 3 ( 0 4 1 5 2 4 ) + 0 0 0 8 9 3 4 ( 0 4 1 3 2 8 4 ) + 0 0 0 0 5 6 6 3 <|endoftext|> #### 0 4 1 3 7 4 1 4 <|endoftext|>', ' 3 6 0 6 * 4 3 8 7 <|endoftext|> 2 5 2 4 2 + 0 9 8 1 8 1 ( 2 4 1 6 0 2 ) + 0 0 4 0 5 8 4 ( 2 4 5 6 5 0 5 ) + 0 0 0 1 4 4 2 4 <|endoftext|> #### 2 4 5 7 9 4 7 4 <|endoftext|>', ' 4 7 8 4 * 2 9 1 6 <|endoftext|> 8 4 7 9 0 + 0 6 6 8 3 4 ( 8 0 4 8 4 4 ) + 0 0 4 7 8 4 0 ( 8 0 8 5 3 9 0 ) + 0 0 0 4 4 2 9 2 <|endoftext|> #### 8 0 8 9 7 1 0 3 <|endoftext|>', ' 2 9 6 1 * 0 5 1 9 <|endoftext|> 0 0 0 0 0 + 0 0 6 4 8 0 ( 0 0 6 4 8 0 ) + 0 0 2 9 6 1 0 ( 0 0 8 3 5 2 0 ) + 0 0 0 8 2 2 5 1 <|endoftext|> #### 0 0 8 1 8 4 5 1 <|endoftext|>', ' 1 1 5 4 * 5 6 0 5 <|endoftext|> 5 5 5 2 2 + 0 6 6 0 7 2 ( 5 1 2 3 9 2 ) + 0 0 0 0 0 0 0 ( 5 1 2 3 9 2 0 ) + 0 0 0 5 5 5 2 2 <|endoftext|> #### 5 1 2 8 4 8 2 2 <|endoftext|>', ' 3 9 9 3 * 0 9 3 3 <|endoftext|> 0 0 0 0 0 + 0 7 3 9 5 3 ( 0 7 3 9 5 3 ) + 0 0 9 7 9 1 1 ( 0 7 2 7 5 5 1 ) + 0 0 0 9 7 9 1 1 <|endoftext|> #### 0 7 2 6 3 5 3 1 <|endoftext|>']\n"
     ]
    }
   ],
   "source": [
    "labels_texts = tokenizer.batch_decode(collated['input_ids'], skip_special_tokens=False)\n",
    "print(labels_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 71])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collated['input_ids'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "', 9 9 4 * 0 0 7 0 5 5 5 5 6 1 + 0 0 6 4 9 0 ( 5 5 1 1 1 1 ) + 0 0 5 9 0 7 0 ( 5 5 6 0 2 8 0 ) + 0 0 0 0 6 4 9 0 <|endoftext|> #### 5 5 6 0 8 2 0 1 <|endoftext|> #'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_texts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   11,   860,   860,   604,  1635,   657,   657,   767,   657,\n",
       "         642,   642,   642,   642,   718,   352,  1343,   657,   657,\n",
       "         718,   604,   860,   657,   357,   642,   642,   352,   352,\n",
       "         352,   352,  1267,  1343,   657,   657,   642,   860,   657,\n",
       "         767,   657,   357,   642,   642,   718,   657,   362,   807,\n",
       "         657,  1267,  1343,   657,   657,   657,   657,   718,   604,\n",
       "         860,   657,   220, 50256,  1303, 21017,   642,   642,   718,\n",
       "         657,   807,   362,   657,   352,   220, 50256,  1303])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([71])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collated['input_ids'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ",  6\n",
      " 9  3\n",
      " 9  2\n",
      " 4  *\n",
      " *  7\n",
      " 0  4\n",
      " 0  3\n",
      " 7  4\n",
      " 0  \n",
      " 5 <|endoftext|>\n",
      " 5  5\n",
      " 5  5\n",
      " 5  5\n",
      " 6  6\n",
      " 1  1\n",
      " +  +\n",
      " 0  0\n",
      " 0  0\n",
      " 6  6\n",
      " 4  4\n",
      " 9  9\n",
      " 0  0\n",
      " (  (\n",
      " 5  5\n",
      " 5  5\n",
      " 1  1\n",
      " 1  1\n",
      " 1  1\n",
      " 1  1\n",
      " )  )\n",
      " +  +\n",
      " 0  0\n",
      " 0  0\n",
      " 5  5\n",
      " 9  9\n",
      " 0  0\n",
      " 7  7\n",
      " 0  0\n",
      " (  (\n",
      " 5  5\n",
      " 5  5\n",
      " 6  6\n",
      " 0  0\n",
      " 2  2\n",
      " 8  8\n",
      " 0  0\n",
      " )  )\n",
      " +  +\n",
      " 0  0\n",
      " 0  0\n",
      " 0  0\n",
      " 0  0\n",
      " 6  6\n",
      " 4  4\n",
      " 9  9\n",
      " 0  0\n",
      "   \n",
      "<|endoftext|> <|endoftext|>\n",
      " #  #\n",
      "### ###\n",
      " 5  5\n",
      " 5  5\n",
      " 6  6\n",
      " 0  0\n",
      " 8  8\n",
      " 2  2\n",
      " 0  0\n",
      " 1  1\n",
      "   \n",
      "<|endoftext|> <|endoftext|>\n"
     ]
    }
   ],
   "source": [
    "for p, t in zip(preds[0], collated['input_ids'][0][1:]):\n",
    "    # print(p, tokenizer.decode([p]), t, tokenizer.decode([t]))\n",
    "    print(tokenizer.decode([p]), tokenizer.decode([t]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
