{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "import datasets\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"gpt2\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Holder:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "args = Holder()\n",
    "# args.use_cot = False\n",
    "args.num_mem_tokens = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "id_pad_value = tokenizer.pad_token_id if tokenizer.pad_token_id is not None else tokenizer.eos_token_id\n",
    "think = ans = tokenizer.bos_token_id\n",
    "eos = tokenizer.eos_token_id\n",
    "\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "def collate_fn(batch):\n",
    "    input_ids, input_ids_generate, labels, labels_mask, attention_mask = [], [], [], [], []\n",
    "    for sample in batch:\n",
    "        task, lab, cot = sample['task'], sample['labels'], sample['cot']\n",
    "        task_tokens = tokenizer.encode(task, add_special_tokens=False)\n",
    "        labels_tokens = tokenizer.encode(lab, add_special_tokens=False)\n",
    "        cot_tokens = tokenizer.encode(cot, add_special_tokens=False)\n",
    "\n",
    "        if args.use_cot:\n",
    "            full_input = task_tokens + [think] + cot_tokens + [ans] + labels_tokens + [eos]\n",
    "            gen_input = task_tokens + [think]\n",
    "        else:\n",
    "            full_input = task_tokens + [ans] + labels_tokens + [eos]\n",
    "            gen_input = task_tokens + [ans]\n",
    "        \n",
    "        inp_ids = torch.tensor(full_input)\n",
    "        input_ids.append(inp_ids)\n",
    "        input_ids_generate.append(torch.tensor(gen_input))\n",
    "\n",
    "\n",
    "        lab = torch.tensor(full_input)\n",
    "        lab[:len(task_tokens)] = -100\n",
    "        labels.append(lab)\n",
    "\n",
    "        lab_mask = torch.ones_like(inp_ids)\n",
    "        lab_mask[:len(task_tokens)] = 0\n",
    "        labels_mask.append(lab_mask)\n",
    "        attention_mask.append(torch.ones_like(inp_ids))\n",
    "\n",
    "    input_ids = pad_sequence(input_ids, padding_value=id_pad_value, batch_first=True)\n",
    "    # input_ids_generate = pad_sequence(input_ids_generate, padding_value=id_pad_value, batch_first=True)\n",
    "    attention_mask = pad_sequence(attention_mask, padding_value=0, batch_first=True)\n",
    "    labels = pad_sequence(labels, padding_value=id_pad_value, batch_first=True)\n",
    "    labels_mask = pad_sequence(labels_mask, padding_value=0, batch_first=True)\n",
    "\n",
    "    collated = {'input_ids': input_ids,\n",
    "                'input_ids_generate': input_ids_generate,\n",
    "                'labels': labels,\n",
    "                'attention_mask': attention_mask,\n",
    "                }\n",
    "    if args.num_mem_tokens is not None:\n",
    "        # add labels mask only for RMT, ARMT\n",
    "        collated['labels_mask'] = labels_mask.bool()\n",
    "    return collated\n",
    "    \n",
    "think_text = tokenizer.decode(think)\n",
    "ans_text = tokenizer.decode(ans)\n",
    "\n",
    "def extract_cot(text):\n",
    "        try:\n",
    "                return text[:text.index(ans_text)]\n",
    "        except ValueError:\n",
    "                return ''\n",
    "\n",
    "def extract_answer(text):\n",
    "        try:\n",
    "                return text.split(ans_text)[1]\n",
    "        except IndexError:\n",
    "                return ''\n",
    "                \n",
    "def compute_accuracy(eval_pred):\n",
    "        preds = eval_pred.predictions.argmax(axis=-1)[:, 1:-1]\n",
    "        labels = eval_pred.label_ids[:, 2:]\n",
    "\n",
    "        labels_masks = labels > 0\n",
    "        preds_full = [p[m] for p, m in zip(preds, labels_masks)]\n",
    "        labels_full = [lab[m] for lab, m in zip(labels, labels_masks)]\n",
    "\n",
    "        print(len(preds_full), len(labels_full))\n",
    "\n",
    "        preds_full_text = tokenizer.batch_decode(preds_full, add_special_tokens=True)\n",
    "        labels_full_text = tokenizer.batch_decode(labels_full, add_special_tokens=True)\n",
    "\n",
    "        preds_cot = [extract_cot(p) for p in preds_full_text]\n",
    "        preds_ans = [extract_answer(p) for p in preds_full_text]\n",
    "\n",
    "        labels_cot = [extract_cot(lab) for lab in labels_full_text]\n",
    "        labels_ans = [extract_answer(lab) for lab in labels_full_text]\n",
    "\n",
    "        acc_cot = np.mean([c == p for c, p in zip(preds_cot, labels_cot)])\n",
    "        acc_ans = np.mean([c == lab for c, lab in zip(preds_ans, labels_ans)])\n",
    "\n",
    "        return {'accuracy_cot': acc_cot, 'accuracy_ans': acc_ans}\n",
    "\n",
    "def evaluate_model_on_dataset(checkpoint_path, valid_dataset, device='cuda'):\n",
    "    model.load_state_dict(torch.load(checkpoint_path), strict=False)\n",
    "    model.generation_config.pad_token_id = tokenizer.pad_token_id\n",
    "    model.to(device)\n",
    "        \n",
    "    collated = collate_fn([sample for sample in valid_dataset])\n",
    "    model.generation_config.pad_token_id = tokenizer.pad_token_id\n",
    "    gen_outputs = [model.generate(inp.reshape(1, -1).to(device), \n",
    "                                pad_token_id=tokenizer.eos_token_id,\n",
    "                                attention_mask=torch.ones_like(inp.reshape(1, -1)).to(device),\n",
    "                                max_new_tokens=50)[0] for inp in collated['input_ids_generate']]\n",
    "\n",
    "    gen_outputs_m2 = [model.generate(inp.reshape(1, -1).to(device), \n",
    "                                     pad_token_id=tokenizer.eos_token_id,\n",
    "                                     attention_mask=torch.ones_like(inp.reshape(1, -1)).to(device))[0].cpu() for inp in gen_outputs]\n",
    "\n",
    "    labels = collated['labels']\n",
    "    labels_masks = labels > 0\n",
    "\n",
    "    preds_full = [out[len(inp):] for inp, out in zip(collated['input_ids_generate'], gen_outputs_m2)]\n",
    "    labels_full = [lab[m][1:] for lab, m in zip(labels, labels_masks)]\n",
    "\n",
    "    print(len(preds_full), len(labels_full))\n",
    "\n",
    "    preds_full_text = tokenizer.batch_decode(preds_full, add_special_tokens=True)\n",
    "    labels_full_text = tokenizer.batch_decode(labels_full, add_special_tokens=True)\n",
    "\n",
    "    preds_cot = [extract_cot(p) for p in preds_full_text]\n",
    "    preds_ans = [extract_answer(p) for p in preds_full_text]\n",
    "\n",
    "    labels_cot = [extract_cot(lab) for lab in labels_full_text]\n",
    "    labels_ans = [extract_answer(lab) for lab in labels_full_text]\n",
    "\n",
    "    acc_cot = np.mean([c == p for c, p in zip(preds_cot, labels_cot)])\n",
    "    acc_ans = np.mean([c == lab for c, lab in zip(preds_ans, labels_ans)])\n",
    "\n",
    "    print(f\"Accuracy COT: {acc_cot}\")\n",
    "    print(f\"Accuracy Answer: {acc_ans}\")\n",
    "    return (acc_cot, acc_ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "res_df = pd.DataFrame(columns=['cpt_path', 'cot', 'acc_cot', 'acc_ans'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'booydar/multiplication_4x4'\n",
    "valid_dataset = datasets.load_dataset(dataset, split='valid')\n",
    "\n",
    "# cot\n",
    "args.use_cot = True\n",
    "\n",
    "checkpoints = [\n",
    "    \"/workspace-SR006.nfs2/Bulatov_A/rmt/runs/4_by_4_mult/gpt2/SEGM_1x1024_1024_LR3e-04-cot/checkpoint-4500/pytorch_model.bin\",\n",
    "]\n",
    "\n",
    "for cpt_path in checkpoints:\n",
    "    print()\n",
    "    print(cpt_path)\n",
    "    acc_cot, acc_ans = evaluate_model_on_dataset(cpt_path, valid_dataset)\n",
    "    res_df.loc[len(res_df)] = [cpt_path.split('/')[-3], args.use_cot, acc_cot, acc_ans]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace-SR006.nfs2/Bulatov_A/rmt/runs/4_by_4_mult/gpt2/SEGM_1x1024_1024_LR3e-04/checkpoint-25000/pytorch_model.bin\n",
      "1000 1000\n",
      "Accuracy COT: 0.001\n",
      "Accuracy Answer: 0.0\n",
      "/workspace-SR006.nfs2/Bulatov_A/rmt/runs/4_by_4_mult/gpt2/SEGM_1x1024_1024_LR1e-05/checkpoint-24500/pytorch_model.bin\n",
      "1000 1000\n",
      "Accuracy COT: 0.0\n",
      "Accuracy Answer: 0.0\n"
     ]
    }
   ],
   "source": [
    "args.use_cot = False\n",
    "\n",
    "checkpoints = [\n",
    "    \"/workspace-SR006.nfs2/Bulatov_A/rmt/runs/4_by_4_mult/gpt2/SEGM_1x1024_1024_LR3e-04/checkpoint-25000/pytorch_model.bin\",\n",
    "    \"/workspace-SR006.nfs2/Bulatov_A/rmt/runs/4_by_4_mult/gpt2/SEGM_1x1024_1024_LR1e-05/checkpoint-24500/pytorch_model.bin\",\n",
    "]\n",
    "\n",
    "for cpt_path in checkpoints:\n",
    "    print(cpt_path)\n",
    "    acc_cot, acc_ans = evaluate_model_on_dataset(cpt_path, valid_dataset)\n",
    "    res_df.loc[len(res_df)] = [cpt_path.split('/')[-3], args.use_cot, 0, acc_cot]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cpt_path</th>\n",
       "      <th>cot</th>\n",
       "      <th>acc_cot</th>\n",
       "      <th>acc_ans</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SEGM_1x1024_1024_LR3e-04-cot</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SEGM_1x1024_1024_LR3e-04</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SEGM_1x1024_1024_LR1e-05</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       cpt_path    cot  acc_cot  acc_ans\n",
       "0  SEGM_1x1024_1024_LR3e-04-cot   True      1.0    1.000\n",
       "1      SEGM_1x1024_1024_LR3e-04  False      0.0    0.001\n",
       "2      SEGM_1x1024_1024_LR1e-05  False      0.0    0.000"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cpt_path = \"/workspace-SR006.nfs2/Bulatov_A/rmt/runs/test/4_by_4_mult/Llama-3.2-1B-Instruct/smol:qa1-5-1:9/SEGM_1x1024_1024_64_LR3e-04-lora-mnc-distill__short/checkpoint-5000/pytorch_model.bin\"\n",
    "# cpt_path = \"/workspace-SR006.nfs2/Bulatov_A/rmt/runs/test/4_by_4_mult/gpt2/SEGM_1x1024_1024_LR3e-04/checkpoint-25000/pytorch_model.bin\"\n",
    "# cpt_path = \"/workspace-SR006.nfs2/Bulatov_A/rmt/runs/gsm8k/gpt2/SEGM_1x1024_1024_LR3e-04/checkpoint-16500/pytorch_model.bin\"\n",
    "# cpt_path = \"/workspace-SR006.nfs2/Bulatov_A/rmt/runs/4_by_4_mult/gpt2/SEGM_1x1024_1024_LR3e-04/checkpoint-25000/pytorch_model.bin\"\n",
    "cpt_path = \"/workspace-SR006.nfs2/Bulatov_A/rmt/runs/4_by_4_mult/gpt2/SEGM_1x1024_1024_LR3e-04-cot/checkpoint-4500/pytorch_model.bin\"\n",
    "model.load_state_dict(torch.load(cpt_path), strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_dir = \"/workspace-SR006.nfs2/Bulatov_A/rmt/data/implicit_chain_of_thought/4_by_4_mult\"\n",
    "\n",
    "# train_path = os.path.join(dataset_dir, \"train\")\n",
    "# valid_path = os.path.join(dataset_dir, \"valid\")\n",
    "# train_dataset = datasets.load_from_disk(train_path)\n",
    "# valid_dataset = datasets.load_from_disk(valid_path)\n",
    "\n",
    "dataset = 'booydar/multiplication_4x4'\n",
    "train_dataset = datasets.load_dataset(dataset, split='train')\n",
    "valid_dataset = datasets.load_dataset(dataset, split='valid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Holder:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "args = Holder()\n",
    "# args.use_cot = False\n",
    "args.use_cot = True\n",
    "args.num_mem_tokens = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "id_pad_value = tokenizer.pad_token_id if tokenizer.pad_token_id is not None else tokenizer.eos_token_id\n",
    "think = ans = tokenizer.bos_token_id\n",
    "eos = tokenizer.eos_token_id\n",
    "\n",
    "def collate_fn(batch):\n",
    "    input_ids, labels, labels_mask, attention_mask = [], [], [], []\n",
    "    for sample in batch:\n",
    "        task, lab, cot = sample['task'], sample['labels'], sample['cot']\n",
    "        task_tokens = tokenizer.encode(task, add_special_tokens=False)\n",
    "        labels_tokens = tokenizer.encode(lab, add_special_tokens=False)\n",
    "        cot_tokens = tokenizer.encode(cot, add_special_tokens=False)\n",
    "\n",
    "        if args.use_cot:\n",
    "            full_input = task_tokens + [think] + cot_tokens + [ans] + labels_tokens + [eos]\n",
    "        else:\n",
    "            full_input = task_tokens + [ans] + labels_tokens + [eos]\n",
    "        inp_ids = torch.tensor(full_input)\n",
    "        input_ids.append(inp_ids)\n",
    "\n",
    "        lab = torch.tensor(full_input)\n",
    "        lab[:len(task_tokens)] = -100\n",
    "        labels.append(lab)\n",
    "\n",
    "        lab_mask = torch.ones_like(inp_ids)\n",
    "        lab_mask[:len(task_tokens)] = 0\n",
    "        labels_mask.append(lab_mask)\n",
    "        attention_mask.append(torch.ones_like(inp_ids))\n",
    "\n",
    "    input_ids = pad_sequence(input_ids, padding_value=id_pad_value, batch_first=True)\n",
    "    attention_mask = pad_sequence(attention_mask, padding_value=0, batch_first=True)\n",
    "    labels = pad_sequence(labels, padding_value=id_pad_value, batch_first=True)\n",
    "    labels_mask = pad_sequence(labels_mask, padding_value=0, batch_first=True)\n",
    "\n",
    "    collated = {'input_ids': input_ids,\n",
    "                'labels': labels,\n",
    "                'attention_mask': attention_mask,\n",
    "                }\n",
    "    if args.num_mem_tokens is not None:\n",
    "        # add labels mask only for RMT, ARMT\n",
    "        collated['labels_mask'] = labels_mask.bool()\n",
    "    return collated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "think_text = tokenizer.decode(think)\n",
    "ans_text = tokenizer.decode(ans)\n",
    "\n",
    "def extract_cot(text):\n",
    "        try:\n",
    "                start_index = text.index(think_text)\n",
    "                end_index = text.index(ans_text, start_index + len(think_text))\n",
    "                return text[start_index + len(think_text):end_index]\n",
    "        except ValueError:\n",
    "                return ''\n",
    "\n",
    "def extract_answer(text):\n",
    "        try:\n",
    "                return text.split(ans_text)[2]\n",
    "        except IndexError:\n",
    "                return ''\n",
    "                \n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "def compute_accuracy(eval_pred):\n",
    "        preds = eval_pred.predictions.argmax(axis=-1)[:, :-1]\n",
    "        labels = eval_pred.label_ids[:, 1:]\n",
    "\n",
    "        labels_masks = labels > 0\n",
    "        preds_full = [p[m] for p, m in zip(preds, labels_masks)]\n",
    "        labels_full = [lab[m] for lab, m in zip(labels, labels_masks)]\n",
    "\n",
    "        print(len(preds_full), len(labels_full))\n",
    "\n",
    "        preds_full_text = tokenizer.batch_decode(preds_full, add_special_tokens=True)\n",
    "        labels_full_text = tokenizer.batch_decode(labels_full, add_special_tokens=True)\n",
    "\n",
    "        preds_cot = [extract_cot(p) for p in preds_full_text]\n",
    "        preds_ans = [extract_answer(p) for p in preds_full_text]\n",
    "\n",
    "        labels_cot = [extract_cot(lab) for lab in labels_full_text]\n",
    "        labels_ans = [extract_answer(lab) for lab in labels_full_text]\n",
    "\n",
    "        acc_cot = np.mean([c == p for c, p in zip(preds_cot, labels_cot)])\n",
    "        acc_ans = np.mean([c == lab for c, lab in zip(preds_ans, labels_ans)])\n",
    "\n",
    "        return {'accuracy_cot': acc_cot, 'accuracy_ans': acc_ans}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "odict_keys(['loss', 'logits', 'past_key_values'])\n"
     ]
    }
   ],
   "source": [
    "batch = [train_dataset[i] for i in range(10)]\n",
    "collated = collate_fn(batch)\n",
    "\n",
    "out = model(**collated)\n",
    "print(out.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10\n"
     ]
    }
   ],
   "source": [
    "# preds = eval_pred.predictions.argmax(axis=-1)[:, :-1]\n",
    "# labels = eval_pred.label_ids[:, 1:]\n",
    "\n",
    "preds = out.logits.argmax(dim=-1).cpu().numpy()[:, :-1]\n",
    "labels = collated['labels'][:, 1:]\n",
    "\n",
    "labels_masks = labels > 0\n",
    "preds_full = [p[m] for p, m in zip(preds, labels_masks)]\n",
    "labels_full = [lab[m] for lab, m in zip(labels, labels_masks)]\n",
    "\n",
    "print(len(preds_full), len(labels_full))\n",
    "\n",
    "preds_full_text = tokenizer.batch_decode(preds_full, add_special_tokens=True)\n",
    "labels_full_text = tokenizer.batch_decode(labels_full, add_special_tokens=True)\n",
    "\n",
    "preds_cot = [extract_cot(p) for p in preds_full_text]\n",
    "preds_ans = [extract_answer(p) for p in preds_full_text]\n",
    "\n",
    "labels_cot = [extract_cot(lab) for lab in labels_full_text]\n",
    "labels_ans = [extract_answer(lab) for lab in labels_full_text]\n",
    "\n",
    "acc_cot = np.mean([c == p for c, p in zip(preds_cot, labels_cot)])\n",
    "acc_ans = np.mean([c == lab for c, lab in zip(preds_ans, labels_ans)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<|endoftext|>5 5 6 1 4 + 0 1 3 3 8 0 ( 5 6 9 4 2 1 ) + 0 0 0 0 0 0 0 ( 5 6 9 4 2 1 0 ) + 0 0 0 5 5 6 1 4<|endoftext|>5 6 9 9 7 7 1 4<|endoftext|>',\n",
       " '<|endoftext|>0 0 0 0 0 + 0 4 4 2 5 3 ( 0 4 4 2 5 3 ) + 0 0 7 7 6 1 6 ( 0 4 1 0 2 5 6 ) + 0 0 0 8 8 4 0 7<|endoftext|>0 4 1 8 0 0 7 7<|endoftext|>',\n",
       " '<|endoftext|>6 9 9 3 1 + 0 8 8 9 1 4 ( 6 7 8 3 3 4 ) + 0 0 6 8 9 8 4 ( 6 7 4 2 3 3 5 ) + 0 0 0 6 8 9 8 4<|endoftext|>6 7 4 8 1 3 4 5<|endoftext|>',\n",
       " '<|endoftext|>2 3 4 3 3 + 0 8 4 1 0 5 ( 2 1 9 4 3 5 ) + 0 0 8 8 2 2 2 ( 2 1 7 3 6 7 2 ) + 0 0 0 2 7 5 5 0<|endoftext|>2 1 7 5 3 3 8 0<|endoftext|>',\n",
       " '<|endoftext|>2 1 9 4 2 + 0 0 0 0 0 0 ( 2 1 9 4 2 0 ) + 0 0 0 6 7 0 2 ( 2 1 9 0 0 1 2 ) + 0 0 0 4 0 3 8 0<|endoftext|>2 1 9 4 0 4 0 1<|endoftext|>',\n",
       " '<|endoftext|>0 6 3 0 4 + 0 5 4 0 5 0 ( 0 1 8 0 9 0 ) + 0 0 5 4 0 5 0 ( 0 1 3 5 9 5 0 ) + 0 0 0 5 3 1 5 1<|endoftext|>0 1 3 0 3 7 5 1<|endoftext|>',\n",
       " '<|endoftext|>8 9 8 1 1 + 0 7 4 8 7 1 ( 8 6 3 0 9 1 ) + 0 0 4 6 8 5 1 ( 8 6 7 6 7 7 1 ) + 0 0 0 2 3 9 7 0<|endoftext|>8 6 7 8 0 7 9 0<|endoftext|>',\n",
       " '<|endoftext|>0 0 0 0 0 + 0 2 7 8 3 1 ( 0 2 7 8 3 1 ) + 0 0 8 3 1 2 1 ( 0 2 5 2 5 3 1 ) + 0 0 0 2 7 8 3 1<|endoftext|>0 2 5 4 2 2 5 1<|endoftext|>',\n",
       " '<|endoftext|>0 4 8 2 1 + 0 6 7 9 7 1 ( 0 0 6 2 9 1 ) + 0 0 0 4 8 2 1 ( 0 0 6 6 7 4 1 ) + 0 0 0 6 3 1 5 0<|endoftext|>0 0 6 2 1 6 6 0<|endoftext|>',\n",
       " '<|endoftext|>6 8 0 0 4 + 0 3 4 0 0 2 ( 6 1 5 0 4 2 ) + 0 0 8 4 4 3 5 ( 6 1 3 5 8 5 5 ) + 0 0 0 4 2 7 6 2<|endoftext|>6 1 3 9 0 3 2 3<|endoftext|>']"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_full_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<|endoftext|>5 5 6 1 4 + 0 1 3 3 8 0 ( 5 6 9 4 2 1 ) + 0 0 0 0 0 0 0 ( 5 6 9 4 2 1 0 ) + 0 0 0 5 5 6 1 4<|endoftext|>5 6 9 9 7 7 1 4<|endoftext|>',\n",
       " '<|endoftext|>0 0 0 0 0 + 0 4 4 2 5 3 ( 0 4 4 2 5 3 ) + 0 0 7 7 6 1 6 ( 0 4 1 0 2 5 6 ) + 0 0 0 8 8 4 0 7<|endoftext|>0 4 1 8 0 0 7 7<|endoftext|>',\n",
       " '<|endoftext|>6 9 9 3 1 + 0 8 8 9 1 4 ( 6 7 8 3 3 4 ) + 0 0 6 8 9 8 4 ( 6 7 4 2 3 3 5 ) + 0 0 0 6 8 9 8 4<|endoftext|>6 7 4 8 1 3 4 5<|endoftext|>',\n",
       " '<|endoftext|>2 3 4 3 3 + 0 8 4 1 0 5 ( 2 1 9 4 3 5 ) + 0 0 8 8 2 2 2 ( 2 1 7 3 6 7 2 ) + 0 0 0 2 7 5 5 0<|endoftext|>2 1 7 5 3 3 8 0<|endoftext|>',\n",
       " '<|endoftext|>2 1 9 4 2 + 0 0 0 0 0 0 ( 2 1 9 4 2 0 ) + 0 0 0 6 7 0 2 ( 2 1 9 0 0 1 2 ) + 0 0 0 4 0 3 8 0<|endoftext|>2 1 9 4 0 4 0 1<|endoftext|>',\n",
       " '<|endoftext|>0 6 3 0 4 + 0 5 4 0 5 0 ( 0 1 8 0 9 0 ) + 0 0 5 4 0 5 0 ( 0 1 3 5 9 5 0 ) + 0 0 0 5 3 1 5 1<|endoftext|>0 1 3 0 3 7 5 1<|endoftext|>',\n",
       " '<|endoftext|>8 9 8 1 1 + 0 7 4 8 7 1 ( 8 6 3 0 9 1 ) + 0 0 4 6 8 5 1 ( 8 6 7 6 7 7 1 ) + 0 0 0 2 3 9 7 0<|endoftext|>8 6 7 8 0 7 9 0<|endoftext|>',\n",
       " '<|endoftext|>0 0 0 0 0 + 0 2 7 8 3 1 ( 0 2 7 8 3 1 ) + 0 0 8 3 1 2 1 ( 0 2 5 2 5 3 1 ) + 0 0 0 2 7 8 3 1<|endoftext|>0 2 5 4 2 2 5 1<|endoftext|>',\n",
       " '<|endoftext|>0 4 8 2 1 + 0 6 7 9 7 1 ( 0 0 6 2 9 1 ) + 0 0 0 4 8 2 1 ( 0 0 6 6 7 4 1 ) + 0 0 0 6 3 1 5 0<|endoftext|>0 0 6 2 1 6 6 0<|endoftext|>',\n",
       " '<|endoftext|>6 8 0 0 4 + 0 3 4 0 0 2 ( 6 1 5 0 4 2 ) + 0 0 8 4 4 3 5 ( 6 1 3 5 8 5 5 ) + 0 0 0 4 2 7 6 2<|endoftext|>6 1 3 9 0 3 2 3<|endoftext|>']"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_full_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['5 5 6 1 4 + 0 1 3 3 8 0 ( 5 6 9 4 2 1 ) + 0 0 0 0 0 0 0 ( 5 6 9 4 2 1 0 ) + 0 0 0 5 5 6 1 4',\n",
       " '0 0 0 0 0 + 0 4 4 2 5 3 ( 0 4 4 2 5 3 ) + 0 0 7 7 6 1 6 ( 0 4 1 0 2 5 6 ) + 0 0 0 8 8 4 0 7',\n",
       " '6 9 9 3 1 + 0 8 8 9 1 4 ( 6 7 8 3 3 4 ) + 0 0 6 8 9 8 4 ( 6 7 4 2 3 3 5 ) + 0 0 0 6 8 9 8 4',\n",
       " '2 3 4 3 3 + 0 8 4 1 0 5 ( 2 1 9 4 3 5 ) + 0 0 8 8 2 2 2 ( 2 1 7 3 6 7 2 ) + 0 0 0 2 7 5 5 0',\n",
       " '2 1 9 4 2 + 0 0 0 0 0 0 ( 2 1 9 4 2 0 ) + 0 0 0 6 7 0 2 ( 2 1 9 0 0 1 2 ) + 0 0 0 4 0 3 8 0',\n",
       " '0 6 3 0 4 + 0 5 4 0 5 0 ( 0 1 8 0 9 0 ) + 0 0 5 4 0 5 0 ( 0 1 3 5 9 5 0 ) + 0 0 0 5 3 1 5 1',\n",
       " '8 9 8 1 1 + 0 7 4 8 7 1 ( 8 6 3 0 9 1 ) + 0 0 4 6 8 5 1 ( 8 6 7 6 7 7 1 ) + 0 0 0 2 3 9 7 0',\n",
       " '0 0 0 0 0 + 0 2 7 8 3 1 ( 0 2 7 8 3 1 ) + 0 0 8 3 1 2 1 ( 0 2 5 2 5 3 1 ) + 0 0 0 2 7 8 3 1',\n",
       " '0 4 8 2 1 + 0 6 7 9 7 1 ( 0 0 6 2 9 1 ) + 0 0 0 4 8 2 1 ( 0 0 6 6 7 4 1 ) + 0 0 0 6 3 1 5 0',\n",
       " '6 8 0 0 4 + 0 3 4 0 0 2 ( 6 1 5 0 4 2 ) + 0 0 8 4 4 3 5 ( 6 1 3 5 8 5 5 ) + 0 0 0 4 2 7 6 2']"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_cot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['5 5 6 1 4 + 0 1 3 3 8 0 ( 5 6 9 4 2 1 ) + 0 0 0 0 0 0 0 ( 5 6 9 4 2 1 0 ) + 0 0 0 5 5 6 1 4',\n",
       " '0 0 0 0 0 + 0 4 4 2 5 3 ( 0 4 4 2 5 3 ) + 0 0 7 7 6 1 6 ( 0 4 1 0 2 5 6 ) + 0 0 0 8 8 4 0 7',\n",
       " '6 9 9 3 1 + 0 8 8 9 1 4 ( 6 7 8 3 3 4 ) + 0 0 6 8 9 8 4 ( 6 7 4 2 3 3 5 ) + 0 0 0 6 8 9 8 4',\n",
       " '2 3 4 3 3 + 0 8 4 1 0 5 ( 2 1 9 4 3 5 ) + 0 0 8 8 2 2 2 ( 2 1 7 3 6 7 2 ) + 0 0 0 2 7 5 5 0',\n",
       " '2 1 9 4 2 + 0 0 0 0 0 0 ( 2 1 9 4 2 0 ) + 0 0 0 6 7 0 2 ( 2 1 9 0 0 1 2 ) + 0 0 0 4 0 3 8 0',\n",
       " '0 6 3 0 4 + 0 5 4 0 5 0 ( 0 1 8 0 9 0 ) + 0 0 5 4 0 5 0 ( 0 1 3 5 9 5 0 ) + 0 0 0 5 3 1 5 1',\n",
       " '8 9 8 1 1 + 0 7 4 8 7 1 ( 8 6 3 0 9 1 ) + 0 0 4 6 8 5 1 ( 8 6 7 6 7 7 1 ) + 0 0 0 2 3 9 7 0',\n",
       " '0 0 0 0 0 + 0 2 7 8 3 1 ( 0 2 7 8 3 1 ) + 0 0 8 3 1 2 1 ( 0 2 5 2 5 3 1 ) + 0 0 0 2 7 8 3 1',\n",
       " '0 4 8 2 1 + 0 6 7 9 7 1 ( 0 0 6 2 9 1 ) + 0 0 0 4 8 2 1 ( 0 0 6 6 7 4 1 ) + 0 0 0 6 3 1 5 0',\n",
       " '6 8 0 0 4 + 0 3 4 0 0 2 ( 6 1 5 0 4 2 ) + 0 0 8 4 4 3 5 ( 6 1 3 5 8 5 5 ) + 0 0 0 4 2 7 6 2']"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_cot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['5 6 9 9 7 7 1 4',\n",
       " '0 4 1 8 0 0 7 7',\n",
       " '6 7 4 8 1 3 4 5',\n",
       " '2 1 7 5 3 3 8 0',\n",
       " '2 1 9 4 0 4 0 1',\n",
       " '0 1 3 0 3 7 5 1',\n",
       " '8 6 7 8 0 7 9 0',\n",
       " '0 2 5 4 2 2 5 1',\n",
       " '0 0 6 2 1 6 6 0',\n",
       " '6 1 3 9 0 3 2 3']"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['5 6 9 9 7 7 1 4',\n",
       " '0 4 1 8 0 0 7 7',\n",
       " '6 7 4 8 1 3 4 5',\n",
       " '2 1 7 5 3 3 8 0',\n",
       " '2 1 9 4 0 4 0 1',\n",
       " '0 1 3 0 3 7 5 1',\n",
       " '8 6 7 8 0 7 9 0',\n",
       " '0 2 5 4 2 2 5 1',\n",
       " '0 0 6 2 1 6 6 0',\n",
       " '6 1 3 9 0 3 2 3']"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_ans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Older pretokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torch.nn.utils.rnn import pad_sequence\n",
    "# id_pad_value = tokenizer.pad_token_id if tokenizer.pad_token_id is not None else tokenizer.eos_token_id\n",
    "# if args.use_cot in (False, None):\n",
    "#     inputs_key = 'examples_nocot'\n",
    "#     labels_key = 'labels_nocot'\n",
    "# else:\n",
    "#     inputs_key = 'examples_all'\n",
    "#     labels_key = 'labels_all'\n",
    "    \n",
    "# def collate_fn(batch):\n",
    "#     input_ids = [torch.tensor(b[inputs_key]) for b in batch]\n",
    "#     labels = [torch.tensor(b[labels_key]) for b in batch]\n",
    "#     attention_mask = [torch.ones_like(b, dtype=int) for b in input_ids]\n",
    "#     # labels_mask defines which input_ids participate in loss calculation\n",
    "#     labels_mask = [torch.sign(torch.tensor(b[labels_key])) for b in batch]\n",
    "\n",
    "\n",
    "#     input_ids = pad_sequence(input_ids, padding_value=id_pad_value, batch_first=True)\n",
    "#     labels = pad_sequence(labels, padding_value=id_pad_value, batch_first=True)\n",
    "#     attention_mask = pad_sequence(attention_mask, padding_value=0, batch_first=True)\n",
    "#     labels_mask = pad_sequence(labels_mask, padding_value=0, batch_first=True)\n",
    "\n",
    "#     collated = {'input_ids': input_ids,\n",
    "#                 'labels': labels, \n",
    "#                 'attention_mask': attention_mask,\n",
    "#                 }\n",
    "#     if args.num_mem_tokens is not None:\n",
    "#         # add labels mask only for RMT, ARMT\n",
    "#         collated['labels_mask'] = labels_mask.bool()\n",
    "#     return collated\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def extract_cot(text):\n",
    "#     if '<|endoftext|>' not in text:\n",
    "#         return ''\n",
    "#     else:\n",
    "#         return text.split('<|endoftext|>')[0].strip()\n",
    "\n",
    "# def extract_answer(text):\n",
    "#     if '####' not in text:\n",
    "#         return ''\n",
    "#     else:\n",
    "#         ans = text.split('####')[-1]\n",
    "#         ans = ans.split('<|endoftext|>')[0]\n",
    "#         return ans.strip()\n",
    "        \n",
    "# def compute_accuracy(eval_pred):\n",
    "#     preds = eval_pred.predictions[:, :-1]\n",
    "#     labels = eval_pred.label_ids[:, 1:]\n",
    "#     # inputs = eval_pred.inputs\n",
    "#     # losses = eval_pred.losses\n",
    "\n",
    "#     # labels = collated['labels'][:, 1:]\n",
    "\n",
    "#     labels_masks = labels > 0\n",
    "#     preds_full = [p[m] for p, m in zip(preds, labels_masks)]\n",
    "#     labels_full = [l[m] for l, m in zip(labels, labels_masks)]\n",
    "\n",
    "#     preds_full_text = tokenizer.batch_decode(preds_full, add_special_tokens=True)\n",
    "#     labels_full_text = tokenizer.batch_decode(labels_full, add_special_tokens=True)\n",
    "\n",
    "#     preds_cot = [extract_cot(p) for p in preds_full_text]\n",
    "#     preds_ans = [extract_answer(p) for p in preds_full_text]\n",
    "\n",
    "#     labels_cot = [extract_cot(l) for l in labels_full_text]\n",
    "#     labels_ans = [extract_answer(l) for l in labels_full_text]\n",
    "    \n",
    "#     # Calculate accuracy only on the unignored tokens\n",
    "#     acc_cot = np.mean([c == l for c, l in zip(preds_cot, labels_cot)])\n",
    "#     acc_ans = np.mean([c == l for c, l in zip(preds_ans, labels_ans)])\n",
    "\n",
    "#     return {'accuracy_cot': acc_cot, 'accuracy_ans': acc_ans}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions = eval_pred.predictions\n",
    "# label_ids = eval_pred.label_ids\n",
    "# inputs = eval_pred.inputs\n",
    "# losses = eval_pred.losses\n",
    "# # elements = (self.predictions, self.label_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "odict_keys(['loss', 'logits', 'past_key_values'])\n"
     ]
    }
   ],
   "source": [
    "batch = [valid_dataset[i] for i in range(10)]\n",
    "collated = collate_fn(batch)\n",
    "\n",
    "out = model(**collated)\n",
    "print(out.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0672, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 175)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = out.logits.argmax(dim=-1).cpu().numpy()\n",
    "preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_text = tokenizer.batch_decode(preds, add_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preds_text[0].split('<|endoftext|>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ''.split('<|endoftext|>')[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = collated['labels'][:, 1:]\n",
    "\n",
    "labels_masks = labels > 0\n",
    "preds_full = [p[m] for p, m in zip(preds[:, :-1], labels_masks)]\n",
    "labels_full = [l[m] for l, m in zip(labels, labels_masks)]\n",
    "\n",
    "preds_full_text = tokenizer.batch_decode(preds_full, add_special_tokens=True)\n",
    "labels_full_text = tokenizer.batch_decode(labels_full, add_special_tokens=True)\n",
    "\n",
    "preds_cot = [extract_cot(p) for p in preds_full_text]\n",
    "preds_ans = [extract_answer(p) for p in preds_full_text]\n",
    "\n",
    "labels_cot = [extract_cot(l) for l in labels_full_text]\n",
    "labels_ans = [extract_answer(l) for l in labels_full_text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels = collated['labels'][:, 1:]\n",
    "\n",
    "# labels_masks = labels > 0\n",
    "# preds_full = [p[m] for p, m in zip(preds[:, :-1], labels_masks)]\n",
    "# labels_full = [l[m] for l, m in zip(labels, labels_masks)]\n",
    "\n",
    "# preds_full_text = tokenizer.batch_decode(preds_full, add_special_tokens=True)\n",
    "# labels_full_text = tokenizer.batch_decode(labels_full, add_special_tokens=True)\n",
    "\n",
    "# preds_cot = [p.split('<|endoftext|>')[0].strip() for p in preds_full_text]\n",
    "# labels_cot = [l.split('<|endoftext|>')[0].strip() for l in labels_full_text]\n",
    "\n",
    "# # preds_ans = [p.split('<|endoftext|>')[1].strip()[4:] for p in preds_full_text]\n",
    "# # labels_ans = [l.split('<|endoftext|>')[1].strip()[4:] for l in labels_full_text]\n",
    "\n",
    "# preds_ans = [p.split('####')[1].strip()[4:] for p in preds_full_text]\n",
    "# labels_ans = [l.split('####')[1].split('astrip()[4:] for l in labels_full_text]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['John cuts his grass to 2 inches.  It grows .5 inches per month.  When it gets to 4 inches he cuts it back down to 2 inches.  It cost $100 to get his grass cut.  How much does he pay per year?<|endoftext|><<4-2=2>> <<2/.5=4>> <<12/4=3>> <<100*3=300>><|endoftext|>300<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>',\n",
       " 'Hannah has three dogs. The first dog eats 1.5 cups of dog food a day. The second dog eats twice as much while the third dog eats 2.5 cups more than the second dog. How many cups of dog food should Hannah prepare in a day for her three dogs?<|endoftext|><<1.5*2=3>> <<3+2.5=5.5>> <<1.5+3+5.5=10>><|endoftext|>10<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>',\n",
       " 'Travis wants to fly to Australia. The regular tickets cost about $2000. As Travis is a student, he will get a 30% discount on this price. How much does he need to pay for his ticket?<|endoftext|><<30/100*2000=600>> <<2000-600=1400>><|endoftext|>1400<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>',\n",
       " 'A set of 7 spoons costs $21. If each spoon would be sold separately, how much would 5 spoons cost?<|endoftext|><<21/7=3>> <<5*3=15>><|endoftext|>15<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>',\n",
       " 'Tom bought his games for $200.  They tripled in value and he then sold 40% of them.  How much did he sell the games for?<|endoftext|><<200*3=600>> <<600*.4=240>><|endoftext|>240<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>',\n",
       " \"Maggie went to Lou's aquarium and saw 100 goldfish in the aquarium. She asked if she could take some home to care for, and she was allowed to catch half of them. While using a catching net, she caught 3/5 of the total number of goldfish she was allowed to take home. How many goldfish does Maggie remain with to catch to get the total number she was allowed to take home?<|endoftext|><<1/2*100=50>> <<3/5*50=30>> <<50-30=20>><|endoftext|>20<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>\",\n",
       " 'Kenny played basketball last week. He ran for twice as long as he played basketball, and he practiced on the trumpet for twice as long as he ran. If he practiced on the trumpet for 40 hours, how many hours did Kenny play basketball last week?<|endoftext|><<40/2=20>> <<20/2=10>><|endoftext|>10<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>',\n",
       " 'Marcia wants to buy some fruit. Apples cost $2, bananas cost $1, and oranges cost $3. If Marcia buys 12 apples, 4 bananas and 4 oranges, what is the average cost of each piece of fruit in dollars?<|endoftext|><<12*2=24>> <<4*1=4>> <<3*4=12>> <<24+4+12=40>> <<12+4+4=20>> <<40/20=2>><|endoftext|>2<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>',\n",
       " \"It’s Meghan’s turn to pick up her team's coffee order.  She needs 2 drip coffees that are $2.25 each and one double shot espresso that’s $3.50.  She needs 2 lattes that are $4.00 and needs to add vanilla syrup to one of those for an additional $0.50.  She also needs 2 cold brew coffees that are $2.50 each and 1 cappuccino for $3.50.  How much is the coffee order?<|endoftext|><<2*2.25=4.50>> <<2*4=8.00>> <<2*2.50=5.00>> <<4.50+8.00+.50+5.00+3.50+3.50=25.00>><|endoftext|>25<|endoftext|>\",\n",
       " 'Roman and Remy took separate showers. Remy used 1 more gallon than 3 times the number of gallons that Roman used for his shower. Together the boys used 33 gallons of water.  How many gallons did Remy use?<|endoftext|><<32=32>> <<8=8>><|endoftext|>25<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.batch_decode(collated['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<|endoftext|><<4-2=2>> <<2/.5=4>> <<12/4=3>> <<100*3=300>><|endoftext|>300<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>',\n",
       " '<|endoftext|><<1.5*2=3>> <<3+2.5=5.5>> <<1.5+3+5.5=10>><|endoftext|>10<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>',\n",
       " '<|endoftext|><<30/100*2000=600>> <<2000-600=1400>><|endoftext|>1400<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>',\n",
       " '<|endoftext|><<21/7=3>> <<5*3=15>><|endoftext|>15<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>',\n",
       " '<|endoftext|><<200*3=600>> <<600*.4=240>><|endoftext|>240<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>',\n",
       " '<|endoftext|><<1/2*100=50>> <<3/5*50=30>> <<50-30=20>><|endoftext|>20<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>',\n",
       " '<|endoftext|><<40/2=20>> <<20/2=10>><|endoftext|>10<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>',\n",
       " '<|endoftext|><<12*2=24>> <<4*1=4>> <<3*4=12>> <<24+4+12=40>> <<12+4+4=20>> <<40/20=2>><|endoftext|>2<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>',\n",
       " '<|endoftext|><<2*2.25=4.50>> <<2*4=8.00>> <<2*2.50=5.00>> <<4.50+8.00+.50+5.00+3.50+3.50=25.00>><|endoftext|>25<|endoftext|>',\n",
       " '<|endoftext|><<32=32>> <<8=8>><|endoftext|>25<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_full_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['', '', '', '', '', '', '', '', '', '']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_cot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['', '', '', '', '', '', '', '', '', '']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_cot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['', '', '', '', '', '', '', '', '', '']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['', '', '', '', '', '', '', '', '', '']"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'labels_text' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[27]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mlabels_text\u001b[49m\n\u001b[32m      2\u001b[39m [\u001b[32m0\u001b[39m].split(\u001b[33m'\u001b[39m\u001b[33m<|endoftext|>\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'labels_text' is not defined"
     ]
    }
   ],
   "source": [
    "labels_text\n",
    "[0].split('<|endoftext|>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'labels_mask'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[28]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m p, l, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(preds, collated[\u001b[33m'\u001b[39m\u001b[33mlabels\u001b[39m\u001b[33m'\u001b[39m], \u001b[43mcollated\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mlabels_mask\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m):\n\u001b[32m      2\u001b[39m     \u001b[38;5;28mprint\u001b[39m(p[m], l[m])\n",
      "\u001b[31mKeyError\u001b[39m: 'labels_mask'"
     ]
    }
   ],
   "source": [
    "for p, l, m in zip(preds, collated['labels'], collated['labels_mask']):\n",
    "    print(p[m], l[m])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   11,   860,   860,   604,  1635,   657,   657,   767,   657,\n",
       "         642,   642,   642,   642,   718,   352,  1343,   657,   657,\n",
       "         718,   604,   860,   657,   357,   642,   642,   352,   352,\n",
       "         352,   352,  1267,  1343,   657,   657,   642,   860,   657,\n",
       "         767,   657,   357,   642,   642,   718,   657,   362,   807,\n",
       "         657,  1267,  1343,   657,   657,   657,   657,   718,   604,\n",
       "         860,   657,   220, 50256,  1303, 21017,   642,   642,   718,\n",
       "         657,   807,   362,   657,   352,   220, 50256,  1303])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[', 9 9 4 * 0 0 7 0 5 5 5 5 6 1 + 0 0 6 4 9 0 ( 5 5 1 1 1 1 ) + 0 0 5 9 0 7 0 ( 5 5 6 0 2 8 0 ) + 0 0 0 0 6 4 9 0 <|endoftext|> #### 5 5 6 0 8 2 0 1 <|endoftext|> #', ' the 0 1 6 0 1 0 8 3 6 6 7 1 1 3 + 0 4 8 7 0 2 ( 6 1 0 9 3 2 ) + 0 0 4 8 7 0 2 ( 6 1 4 7 1 3 2 ) + 0 0 0 2 7 3 6 3 <|endoftext|> #### 6 1 4 9 8 6 8 3 <|endoftext|> #', ' the 0 8 4 + 2 8 3 0 8 8 0 0 5 7 + 0 4 8 3 4 8 ( 8 4 8 8 1 9 ) + 0 0 6 7 3 9 0 ( 8 4 4 6 5 8 1 ) + 0 0 0 2 3 6 5 6 <|endoftext|> #### 8 4 4 8 8 4 7 6 <|endoftext|> #', ', 2 3 2\\n 0 0 0 1 9 9 0 9 2 1 + 0 2 1 2 7 1 ( 9 2 0 5 8 1 ) + 0 0 8 1 8 5 2 ( 9 2 8 6 6 7 2 ) + 0 0 0 5 1 5 1 2 <|endoftext|> #### 9 2 8 1 8 2 4 2 <|endoftext|> #', ' the 1 - 0 0 0 1 3 2 0 0 4 6 8 5 + 0 0 5 6 6 3 ( 0 4 1 5 2 4 ) + 0 0 0 8 9 3 4 ( 0 4 1 3 2 8 4 ) + 0 0 0 0 5 6 6 3 <|endoftext|> #### 0 4 1 3 7 4 1 4 <|endoftext|> #', ', 4 5 1 0 8 2 8 1 2 2 5 2 4 2 + 0 9 8 1 8 1 ( 2 4 1 6 0 2 ) + 0 0 4 0 5 8 4 ( 2 4 5 6 5 0 5 ) + 0 0 0 1 4 4 2 4 <|endoftext|> #### 2 4 5 7 9 4 7 4 <|endoftext|> #', ' the 7 0 9\\n 0 8 3 0 0 8 4 7 9 0 + 0 6 6 8 3 4 ( 8 0 4 8 4 4 ) + 0 0 4 7 8 4 0 ( 8 0 8 5 3 9 0 ) + 0 0 0 4 4 2 9 2 <|endoftext|> #### 8 0 8 9 7 1 0 3 <|endoftext|> #', ', 3 9 2 0 0 0 3 0 0 0 0 0 0 0 + 0 0 6 4 8 0 ( 0 0 6 4 8 0 ) + 0 0 2 9 6 1 0 ( 0 0 8 3 5 2 0 ) + 0 0 0 8 2 2 5 1 <|endoftext|> #### 0 0 8 1 8 4 5 1 <|endoftext|> #', ', 7 7 3average 1 0 0 2 5 5 5 5 2 2 + 0 6 6 0 7 2 ( 5 1 2 3 9 2 ) + 0 0 0 0 0 0 0 ( 5 1 2 3 9 2 0 ) + 0 0 0 5 5 5 2 2 <|endoftext|> #### 5 1 2 8 4 8 2 2 <|endoftext|> #', ', 5 9 1ACH 0 3 7 0 0 0 0 0 0 0 + 0 7 3 9 5 3 ( 0 7 3 9 5 3 ) + 0 0 9 7 9 1 1 ( 0 7 2 7 5 5 1 ) + 0 0 0 9 7 9 1 1 <|endoftext|> #### 0 7 2 6 3 5 3 1 <|endoftext|> #']\n"
     ]
    }
   ],
   "source": [
    "pred_texts = tokenizer.batch_decode(preds, skip_special_tokens=False)\n",
    "print(pred_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' 5 6 3 2 * 7 4 3 4 <|endoftext|> 5 5 5 6 1 + 0 0 6 4 9 0 ( 5 5 1 1 1 1 ) + 0 0 5 9 0 7 0 ( 5 5 6 0 2 8 0 ) + 0 0 0 0 6 4 9 0 <|endoftext|> #### 5 5 6 0 8 2 0 1 <|endoftext|>', ' 6 9 1 5 * 6 4 4 7 <|endoftext|> 6 7 1 1 3 + 0 4 8 7 0 2 ( 6 1 0 9 3 2 ) + 0 0 4 8 7 0 2 ( 6 1 4 7 1 3 2 ) + 0 0 0 2 7 3 6 3 <|endoftext|> #### 6 1 4 9 8 6 8 3 <|endoftext|>', ' 6 7 3 9 * 8 9 1 7 <|endoftext|> 8 0 0 5 7 + 0 4 8 3 4 8 ( 8 4 8 8 1 9 ) + 0 0 6 7 3 9 0 ( 8 4 4 6 5 8 1 ) + 0 0 0 2 3 6 5 6 <|endoftext|> #### 8 4 4 8 8 4 7 6 <|endoftext|>', ' 3 0 3 4 * 3 4 6 5 <|endoftext|> 9 0 9 2 1 + 0 2 1 2 7 1 ( 9 2 0 5 8 1 ) + 0 0 8 1 8 5 2 ( 9 2 8 6 6 7 2 ) + 0 0 0 5 1 5 1 2 <|endoftext|> #### 9 2 8 1 8 2 4 2 <|endoftext|>', ' 0 3 3 7 * 8 5 6 5 <|endoftext|> 0 4 6 8 5 + 0 0 5 6 6 3 ( 0 4 1 5 2 4 ) + 0 0 0 8 9 3 4 ( 0 4 1 3 2 8 4 ) + 0 0 0 0 5 6 6 3 <|endoftext|> #### 0 4 1 3 7 4 1 4 <|endoftext|>', ' 3 6 0 6 * 4 3 8 7 <|endoftext|> 2 5 2 4 2 + 0 9 8 1 8 1 ( 2 4 1 6 0 2 ) + 0 0 4 0 5 8 4 ( 2 4 5 6 5 0 5 ) + 0 0 0 1 4 4 2 4 <|endoftext|> #### 2 4 5 7 9 4 7 4 <|endoftext|>', ' 4 7 8 4 * 2 9 1 6 <|endoftext|> 8 4 7 9 0 + 0 6 6 8 3 4 ( 8 0 4 8 4 4 ) + 0 0 4 7 8 4 0 ( 8 0 8 5 3 9 0 ) + 0 0 0 4 4 2 9 2 <|endoftext|> #### 8 0 8 9 7 1 0 3 <|endoftext|>', ' 2 9 6 1 * 0 5 1 9 <|endoftext|> 0 0 0 0 0 + 0 0 6 4 8 0 ( 0 0 6 4 8 0 ) + 0 0 2 9 6 1 0 ( 0 0 8 3 5 2 0 ) + 0 0 0 8 2 2 5 1 <|endoftext|> #### 0 0 8 1 8 4 5 1 <|endoftext|>', ' 1 1 5 4 * 5 6 0 5 <|endoftext|> 5 5 5 2 2 + 0 6 6 0 7 2 ( 5 1 2 3 9 2 ) + 0 0 0 0 0 0 0 ( 5 1 2 3 9 2 0 ) + 0 0 0 5 5 5 2 2 <|endoftext|> #### 5 1 2 8 4 8 2 2 <|endoftext|>', ' 3 9 9 3 * 0 9 3 3 <|endoftext|> 0 0 0 0 0 + 0 7 3 9 5 3 ( 0 7 3 9 5 3 ) + 0 0 9 7 9 1 1 ( 0 7 2 7 5 5 1 ) + 0 0 0 9 7 9 1 1 <|endoftext|> #### 0 7 2 6 3 5 3 1 <|endoftext|>']\n"
     ]
    }
   ],
   "source": [
    "labels_texts = tokenizer.batch_decode(collated['input_ids'], skip_special_tokens=False)\n",
    "print(labels_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 71])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collated['input_ids'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "', 9 9 4 * 0 0 7 0 5 5 5 5 6 1 + 0 0 6 4 9 0 ( 5 5 1 1 1 1 ) + 0 0 5 9 0 7 0 ( 5 5 6 0 2 8 0 ) + 0 0 0 0 6 4 9 0 <|endoftext|> #### 5 5 6 0 8 2 0 1 <|endoftext|> #'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_texts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   11,   860,   860,   604,  1635,   657,   657,   767,   657,\n",
       "         642,   642,   642,   642,   718,   352,  1343,   657,   657,\n",
       "         718,   604,   860,   657,   357,   642,   642,   352,   352,\n",
       "         352,   352,  1267,  1343,   657,   657,   642,   860,   657,\n",
       "         767,   657,   357,   642,   642,   718,   657,   362,   807,\n",
       "         657,  1267,  1343,   657,   657,   657,   657,   718,   604,\n",
       "         860,   657,   220, 50256,  1303, 21017,   642,   642,   718,\n",
       "         657,   807,   362,   657,   352,   220, 50256,  1303])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([71])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collated['input_ids'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ",  6\n",
      " 9  3\n",
      " 9  2\n",
      " 4  *\n",
      " *  7\n",
      " 0  4\n",
      " 0  3\n",
      " 7  4\n",
      " 0  \n",
      " 5 <|endoftext|>\n",
      " 5  5\n",
      " 5  5\n",
      " 5  5\n",
      " 6  6\n",
      " 1  1\n",
      " +  +\n",
      " 0  0\n",
      " 0  0\n",
      " 6  6\n",
      " 4  4\n",
      " 9  9\n",
      " 0  0\n",
      " (  (\n",
      " 5  5\n",
      " 5  5\n",
      " 1  1\n",
      " 1  1\n",
      " 1  1\n",
      " 1  1\n",
      " )  )\n",
      " +  +\n",
      " 0  0\n",
      " 0  0\n",
      " 5  5\n",
      " 9  9\n",
      " 0  0\n",
      " 7  7\n",
      " 0  0\n",
      " (  (\n",
      " 5  5\n",
      " 5  5\n",
      " 6  6\n",
      " 0  0\n",
      " 2  2\n",
      " 8  8\n",
      " 0  0\n",
      " )  )\n",
      " +  +\n",
      " 0  0\n",
      " 0  0\n",
      " 0  0\n",
      " 0  0\n",
      " 6  6\n",
      " 4  4\n",
      " 9  9\n",
      " 0  0\n",
      "   \n",
      "<|endoftext|> <|endoftext|>\n",
      " #  #\n",
      "### ###\n",
      " 5  5\n",
      " 5  5\n",
      " 6  6\n",
      " 0  0\n",
      " 8  8\n",
      " 2  2\n",
      " 0  0\n",
      " 1  1\n",
      "   \n",
      "<|endoftext|> <|endoftext|>\n"
     ]
    }
   ],
   "source": [
    "for p, t in zip(preds[0], collated['input_ids'][0][1:]):\n",
    "    # print(p, tokenizer.decode([p]), t, tokenizer.decode([t]))\n",
    "    print(tokenizer.decode([p]), tokenizer.decode([t]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
