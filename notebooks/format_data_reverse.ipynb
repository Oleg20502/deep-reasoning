{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import datasets\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4x4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the dataset since booydar/multiplication_4x4 couldn't be found on the Hugging Face Hub\n",
      "Found the latest cached dataset configuration 'default' at /home/jovyan/.cache/huggingface/datasets/booydar___multiplication_4x4/default/0.0.0/e224243bb9970a0937976173287d24816d683ff9 (last modified on Fri Mar 14 16:54:33 2025).\n"
     ]
    }
   ],
   "source": [
    "ds_name = \"booydar/multiplication_4x4\"\n",
    "ds = load_dataset(ds_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reverse(sample):\n",
    "    numbers = sample['task'][::-1].split(' * ')\n",
    "\n",
    "    a = int(re.sub(' ', '', numbers[0]))\n",
    "    b = int(re.sub(' ', '', numbers[1]))\n",
    "\n",
    "    task = ' '.join(str(b)) + ' * ' + ' '.join(str(a))\n",
    "    label = ' '.join(str(a * b))\n",
    "\n",
    "    s1 = b * int(str(a)[3])\n",
    "    s2 = b * int(str(a)[2]) * 10\n",
    "    s3 = b * int(str(a)[1]) * 100\n",
    "    s4 = b * int(str(a)[0]) * 1000\n",
    "\n",
    "    cot = ''\n",
    "    cot += ' '.join(str(s1))\n",
    "    cot += ' + '\n",
    "    cot += ' '.join(str(s2))\n",
    "    cot += ' ( ' + ' '.join(str(s1 + s2)) + ' )'\n",
    "    cot += ' + '\n",
    "    cot += ' '.join(str(s3))\n",
    "    cot += ' ( ' + ' '.join(str(s1 + s2 + s3)) + ' )'\n",
    "    cot += ' + '\n",
    "    cot += ' '.join(str(s4))\n",
    "\n",
    "    return {'task': task, 'cot': cot, \"labels\": label}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3ce384f9d7041febf13ea076c10de71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/808000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "reversed = ds.map(reverse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "823d15114d164413a8d5b295b2c540f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51c840c2933a4c54808b0cd048a3a4d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/808 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f986f262aa74dbc8b6a891d6311f4db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a834441f732d45d3bd1e44b76247b007",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/datasets/booydar/multiplication_4x4_reversed/commit/4077af4afd528e18f6339000e77ab963714d288c', commit_message='Upload dataset', commit_description='', oid='4077af4afd528e18f6339000e77ab963714d288c', pr_url=None, repo_url=RepoUrl('https://huggingface.co/datasets/booydar/multiplication_4x4_reversed', endpoint='https://huggingface.co', repo_type='dataset', repo_id='booydar/multiplication_4x4_reversed'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_out_name = \"booydar/multiplication_4x4_reversed\"\n",
    "reversed.push_to_hub(ds_out_name, token='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')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'task': '8 3 3 1 * 5 0 1 5',\n",
       " 'labels': '4 1 7 7 9 9 6 5',\n",
       " 'cot': '4 1 6 5 5 + 8 3 3 1 0 ( 1 2 4 9 6 5 ) + 0 ( 1 2 4 9 6 5 ) + 4 1 6 5 5 0 0 0'}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reversed['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'task': '1 3 3 8 * 5 1 0 5',\n",
       " 'labels': '5 6 9 9 7 7 1 4',\n",
       " 'cot': '5 5 6 1 4 + 0 1 3 3 8 0 ( 5 6 9 4 2 1 ) + 0 0 0 0 0 0 0 ( 5 6 9 4 2 1 0 ) + 0 0 0 5 5 6 1 4'}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'task': '2 3 6 5 + 4 3 4 7',\n",
       " 'cot': '1 6 5 5 5 + 9 4 6 0 0 ( 1 1 1 1 5 5 ) + 7 0 9 5 0 0 ( 8 2 0 6 5 5 ) + 9 4 6 0 0 0 0',\n",
       " 'label': '1 0 2 8 0 6 5 5'}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reverse(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'task': '5 6 3 2 * 7 4 3 4',\n",
       " 'labels': '5 5 6 0 8 2 0 1',\n",
       " 'cot': '5 5 5 6 1 + 0 0 6 4 9 0 ( 5 5 1 1 1 1 ) + 0 0 5 9 0 7 0 ( 5 5 6 0 2 8 0 ) + 0 0 0 0 6 4 9 0'}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1 6 5 5 5 + 9 4 6 0 0 ( 1 1 1 1 5 5 ) + 7 0 9 5 0 0 ( 8 2 0 6 5 5 ) + 9 4 6 0 0 0 0'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cot = []\n",
    "cot.append"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "111155"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s1 + s2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "709500"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b * int(str(a)[1]) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9460000"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b * int(str(a)[0]) * 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4347"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4347"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating parquet from Arrow format: 100%|██████████| 808/808 [00:01<00:00, 654.62ba/s]\n",
      "Uploading the dataset shards: 100%|██████████| 1/1 [00:06<00:00,  6.31s/it]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 567.95ba/s]\n",
      "Uploading the dataset shards: 100%|██████████| 1/1 [00:00<00:00,  1.31it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/datasets/booydar/multiplication_4x4/commit/e224243bb9970a0937976173287d24816d683ff9', commit_message='Upload dataset', commit_description='', oid='e224243bb9970a0937976173287d24816d683ff9', pr_url=None, repo_url=RepoUrl('https://huggingface.co/datasets/booydar/multiplication_4x4', endpoint='https://huggingface.co', repo_type='dataset', repo_id='booydar/multiplication_4x4'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hf_dataset = datasets.DatasetDict(train=ds_train, valid=ds_val)\n",
    "hf_dataset.push_to_hub('booydar/multiplication_4x4', token=\"your_token_here\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5x5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating parquet from Arrow format: 100%|██████████| 808/808 [00:01<00:00, 694.47ba/s]\n",
      "Uploading the dataset shards: 100%|██████████| 1/1 [00:05<00:00,  5.30s/it]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 591.08ba/s]\n",
      "Uploading the dataset shards: 100%|██████████| 1/1 [00:00<00:00,  1.27it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/datasets/booydar/multiplication_5x5/commit/0460ea5f5468419ce40dd642de25a3a7b896daaa', commit_message='Upload dataset', commit_description='', oid='0460ea5f5468419ce40dd642de25a3a7b896daaa', pr_url=None, repo_url=RepoUrl('https://huggingface.co/datasets/booydar/multiplication_5x5', endpoint='https://huggingface.co', repo_type='dataset', repo_id='booydar/multiplication_5x5'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_path = '/workspace-SR006.nfs2/Bulatov_A/rmt/tools/implicit_chain_of_thought/data/5_by_5_mult/train.txt'\n",
    "val_path = '/workspace-SR006.nfs2/Bulatov_A/rmt/tools/implicit_chain_of_thought/data/5_by_5_mult/valid.txt'\n",
    "\n",
    "ds_train = get_hf_dataset(train_path)\n",
    "ds_val = get_hf_dataset(val_path)\n",
    "\n",
    "hf_dataset = datasets.DatasetDict(train=ds_train, valid=ds_val)\n",
    "hf_dataset.push_to_hub('booydar/multiplication_5x5', token=\"your_token_here\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### gsm8k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating parquet from Arrow format: 100%|██████████| 385/385 [00:00<00:00, 415.34ba/s]\n",
      "Uploading the dataset shards: 100%|██████████| 1/1 [00:09<00:00,  9.26s/it]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 623.41ba/s]\n",
      "Uploading the dataset shards: 100%|██████████| 1/1 [00:00<00:00,  1.26it/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 2/2 [00:00<00:00, 643.94ba/s]\n",
      "Uploading the dataset shards: 100%|██████████| 1/1 [00:01<00:00,  1.81s/it]\n",
      "Creating parquet from Arrow format: 100%|██████████| 7/7 [00:00<00:00, 369.91ba/s]\n",
      "Uploading the dataset shards: 100%|██████████| 1/1 [00:01<00:00,  1.51s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/datasets/booydar/gsm8k/commit/71eb04c3261d8da50bae2dccdec5d70dace5d07d', commit_message='Upload dataset', commit_description='', oid='71eb04c3261d8da50bae2dccdec5d70dace5d07d', pr_url=None, repo_url=RepoUrl('https://huggingface.co/datasets/booydar/gsm8k', endpoint='https://huggingface.co', repo_type='dataset', repo_id='booydar/gsm8k'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_path = '/workspace-SR006.nfs2/Bulatov_A/rmt/tools/implicit_chain_of_thought/data/gsm8k/train.txt'\n",
    "val_path = '/workspace-SR006.nfs2/Bulatov_A/rmt/tools/implicit_chain_of_thought/data/gsm8k/valid.txt'\n",
    "test_path = '/workspace-SR006.nfs2/Bulatov_A/rmt/tools/implicit_chain_of_thought/data/gsm8k/test.txt'\n",
    "train_no_aug = '/workspace-SR006.nfs2/Bulatov_A/rmt/tools/implicit_chain_of_thought/data/gsm8k/train_no_aug.txt'\n",
    "\n",
    "ds_train = get_hf_dataset(train_path)\n",
    "ds_val = get_hf_dataset(val_path)\n",
    "ds_test = get_hf_dataset(test_path)\n",
    "ds_train_no_aug = get_hf_dataset(train_no_aug)\n",
    "\n",
    "hf_dataset = datasets.DatasetDict(train=ds_train, valid=ds_val, test=ds_test, train_no_aug=ds_train_no_aug)\n",
    "hf_dataset.push_to_hub('booydar/gsm8k', token=\"your_token_here\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'task': 'Jen shared a pack of chocolates among her friends. She gave 20% to Lucy, 30% to Sarah and the remaining were shared equally among four others. If the pack contained 100 chocolates, how many chocolates were each of the four others getting?',\n",
       " 'labels': '12.5',\n",
       " 'cot': '<<20+30=50>> <<100-50=50>> <<100*50/100=50>> <<50/4=12.5>>'}"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hf_dataset['train'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_dataset = datasets.load_dataset(\"booydar/multiplication_4x4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn.utils.rnn import pad_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Holder:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "args = Holder()\n",
    "args.use_cot = False\n",
    "args.num_mem_tokens = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_pad_value = tokenizer.pad_token_id if tokenizer.pad_token_id is not None else tokenizer.eos_token_id\n",
    "# id_pad_value = -100\n",
    "\n",
    "\n",
    "if args.use_cot in (False, None):\n",
    "    inputs_key = 'examples_nocot'\n",
    "    labels_key = 'labels_nocot'\n",
    "else:\n",
    "    inputs_key = 'examples_all'\n",
    "    labels_key = 'labels_all'\n",
    "    \n",
    "def collate_fn(batch):\n",
    "    input_ids = [torch.tensor(b[inputs_key]) for b in batch]\n",
    "    labels = [torch.tensor(b[labels_key]) for b in batch]\n",
    "    attention_mask = [torch.ones_like(b, dtype=int) for b in input_ids]\n",
    "    # labels_mask defines which input_ids participate in loss calculation\n",
    "    labels_mask = [torch.sign(torch.tensor(b[labels_key])) for b in batch]\n",
    "\n",
    "\n",
    "    input_ids = pad_sequence(input_ids, padding_value=id_pad_value, batch_first=True)\n",
    "    labels = pad_sequence(labels, padding_value=id_pad_value, batch_first=True)\n",
    "    attention_mask = pad_sequence(attention_mask, padding_value=0, batch_first=True)\n",
    "    labels_mask = pad_sequence(labels_mask, padding_value=0, batch_first=True)\n",
    "\n",
    "    collated = {'input_ids': input_ids,\n",
    "                'labels': labels, \n",
    "                'attention_mask': attention_mask,\n",
    "                }\n",
    "    if args.num_mem_tokens is not None:\n",
    "        # add labels mask only for RMT, ARMT\n",
    "        collated['labels_mask'] = labels_mask.bool()\n",
    "    return collated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = hf_dataset['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = [train_dataset[i] for i in range(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'task': '1 3 3 8 * 5 1 0 5',\n",
       " 'labels': '5 6 9 9 7 7 1 4',\n",
       " 'cot': '5 5 6 1 4 + 0 1 3 3 8 0 ( 5 6 9 4 2 1 ) + 0 0 0 0 0 0 0 ( 5 6 9 4 2 1 0 ) + 0 0 0 5 5 6 1 4'}"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "think = tokenizer.bos_token_id\n",
    "ans = tokenizer.bos_token_id\n",
    "eos = tokenizer.eos_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "args.num_mem_tokens = 10\n",
    "args.use_cot = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "think = tokenizer.bos_token_id\n",
    "ans = tokenizer.bos_token_id\n",
    "eos = tokenizer.eos_token_id\n",
    "\n",
    "def collate_fn(batch):\n",
    "    input_ids, labels, labels_mask, attention_mask = [], [], [], []\n",
    "    for sample in batch:\n",
    "        task, lab, cot = sample['task'], sample['labels'], sample['cot']\n",
    "        task_tokens = tokenizer.encode(task, add_special_tokens=False)\n",
    "        labels_tokens = tokenizer.encode(lab, add_special_tokens=False)\n",
    "        cot_tokens = tokenizer.encode(cot, add_special_tokens=False)\n",
    "\n",
    "        if args.use_cot:\n",
    "            full_input = task_tokens + [think] + cot_tokens + [ans] + labels_tokens + [eos]\n",
    "        else:\n",
    "            full_input = task_tokens + [ans] + labels_tokens + [eos]\n",
    "        inp_ids = torch.tensor(full_input)\n",
    "        input_ids.append(inp_ids)\n",
    "\n",
    "        lab = torch.tensor(full_input)\n",
    "        lab[:len(task_tokens)] = -100\n",
    "        labels.append(lab)\n",
    "\n",
    "        lab_mask = torch.ones_like(inp_ids)\n",
    "        lab_mask[:len(task_tokens)] = 0\n",
    "        labels_mask.append(lab_mask)\n",
    "        attention_mask.append(torch.ones_like(inp_ids))\n",
    "        \n",
    "    input_ids = pad_sequence(input_ids, padding_value=id_pad_value, batch_first=True)\n",
    "    attention_mask = pad_sequence(attention_mask, padding_value=0, batch_first=True)\n",
    "    labels = pad_sequence(labels, padding_value=id_pad_value, batch_first=True)\n",
    "    labels_mask = pad_sequence(labels_mask, padding_value=0, batch_first=True)\n",
    "\n",
    "    collated = {'input_ids': input_ids,\n",
    "                'labels': labels, \n",
    "                'attention_mask': attention_mask,\n",
    "                }\n",
    "    if args.num_mem_tokens is not None:\n",
    "        # add labels mask only for RMT, ARMT\n",
    "        collated['labels_mask'] = labels_mask.bool()\n",
    "    return collated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "collated = collate_fn(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1 3 3 8 * 5 1 0 5<|endoftext|>5 5 6 1 4 + 0 1 3 3 8 0 ( 5 6 9 4 2 1 ) + 0 0 0 0 0 0 0 ( 5 6 9 4 2 1 0 ) + 0 0 0 5 5 6 1 4<|endoftext|>5 6 9 9 7 7 1 4<|endoftext|>'"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(collated['input_ids'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|endoftext|>5 5 6 1 4 + 0 1 3 3 8 0 ( 5 6 9 4 2 1 ) + 0 0 0 0 0 0 0 ( 5 6 9 4 2 1 0 ) + 0 0 0 5 5 6 1 4<|endoftext|>5 6 9 9 7 7 1 4<|endoftext|>'"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(collated['input_ids'][0][collated['labels_mask'][0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|endoftext|>5 5 6 1 4 + 0 1 3 3 8 0 ( 5 6 9 4 2 1 ) + 0 0 0 0 0 0 0 ( 5 6 9 4 2 1 0 ) + 0 0 0 5 5 6 1 4<|endoftext|>5 6 9 9 7 7 1 4<|endoftext|>'"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(collated['labels'][0][collated['labels_mask'][0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "think_text = tokenizer.decode(think)\n",
    "ans_text = tokenizer.decode(ans)\n",
    "\n",
    "def extract_cot(text):\n",
    "    try:\n",
    "        start_index = text.index(think_text)\n",
    "        end_index = text.index(ans_text, start_index + len(think_text))\n",
    "        return text[start_index + len(think_text):end_index]\n",
    "    except ValueError as e:\n",
    "        return ''\n",
    "\n",
    "def extract_answer(text):\n",
    "    return text.split(ans_text)[-2]\n",
    "        \n",
    "def compute_accuracy(eval_pred):\n",
    "    preds = eval_pred.predictions.argmax(axis=-1)[:, :-1]\n",
    "    labels = eval_pred.label_ids[:, 1:]\n",
    "    print(\"preds.shape, labels.shape\")\n",
    "    print(preds.shape, labels.shape)\n",
    "\n",
    "    labels_masks = labels > 0\n",
    "    preds_full = [p[m] for p, m in zip(preds, labels_masks)]\n",
    "    labels_full = [l[m] for l, m in zip(labels, labels_masks)]\n",
    "\n",
    "    print(len(preds_full), len(labels_full))\n",
    "    # print(preds_full, labels_full)\n",
    "\n",
    "    preds_full_text = tokenizer.batch_decode(preds_full, add_special_tokens=True)\n",
    "    labels_full_text = tokenizer.batch_decode(labels_full, add_special_tokens=True)\n",
    "\n",
    "    preds_cot = [extract_cot(p) for p in preds_full_text]\n",
    "    preds_ans = [extract_answer(p) for p in preds_full_text]\n",
    "\n",
    "    labels_cot = [extract_cot(l) for l in labels_full_text]\n",
    "    labels_ans = [extract_answer(l) for l in labels_full_text]\n",
    "    \n",
    "    acc_cot = np.mean([c == l for c, l in zip(preds_cot, labels_cot)])\n",
    "    acc_ans = np.mean([c == l for c, l in zip(preds_ans, labels_ans)])\n",
    "\n",
    "    return {'accuracy_cot': acc_cot, 'accuracy_ans': acc_ans}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = collated['labels']\n",
    "preds = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preds.shape, labels.shape\n",
      "torch.Size([10, 66]) torch.Size([10, 66])\n",
      "10 10\n"
     ]
    }
   ],
   "source": [
    "# preds = eval_pred.predictions.argmax(axis=-1)[:, :-1]\n",
    "# labels = eval_pred.label_ids[:, 1:]\n",
    "print(\"preds.shape, labels.shape\")\n",
    "print(preds.shape, labels.shape)\n",
    "\n",
    "labels_masks = labels > 0\n",
    "preds_full = [p[m] for p, m in zip(preds, labels_masks)]\n",
    "labels_full = [l[m] for l, m in zip(labels, labels_masks)]\n",
    "\n",
    "print(len(preds_full), len(labels_full))\n",
    "# print(preds_full, labels_full)\n",
    "\n",
    "preds_full_text = tokenizer.batch_decode(preds_full, add_special_tokens=True)\n",
    "labels_full_text = tokenizer.batch_decode(labels_full, add_special_tokens=True)\n",
    "\n",
    "preds_cot = [extract_cot(p) for p in preds_full_text]\n",
    "preds_ans = [extract_answer(p) for p in preds_full_text]\n",
    "\n",
    "labels_cot = [extract_cot(l) for l in labels_full_text]\n",
    "labels_ans = [extract_answer(l) for l in labels_full_text]\n",
    "\n",
    "acc_cot = np.mean([c == l for c, l in zip(preds_cot, labels_cot)])\n",
    "acc_ans = np.mean([c == l for c, l in zip(preds_ans, labels_ans)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['5 6 9 9 7 7 1 4',\n",
       " '0 4 1 8 0 0 7 7',\n",
       " '6 7 4 8 1 3 4 5',\n",
       " '2 1 7 5 3 3 8 0',\n",
       " '2 1 9 4 0 4 0 1',\n",
       " '0 1 3 0 3 7 5 1',\n",
       " '8 6 7 8 0 7 9 0',\n",
       " '0 2 5 4 2 2 5 1',\n",
       " '0 0 6 2 1 6 6 0',\n",
       " '6 1 3 9 0 3 2 3']"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['|endoftext|>5 5 6 1 4 + 0 1 3 3 8 0 ( 5 6 9 4 2 1 ) + 0 0 0 0 0 0 0 ( 5 6 9 4 2 1 0 ) + 0 0 0 5 5 6 1 4',\n",
       " '|endoftext|>0 0 0 0 0 + 0 4 4 2 5 3 ( 0 4 4 2 5 3 ) + 0 0 7 7 6 1 6 ( 0 4 1 0 2 5 6 ) + 0 0 0 8 8 4 0 7',\n",
       " '|endoftext|>6 9 9 3 1 + 0 8 8 9 1 4 ( 6 7 8 3 3 4 ) + 0 0 6 8 9 8 4 ( 6 7 4 2 3 3 5 ) + 0 0 0 6 8 9 8 4',\n",
       " '|endoftext|>2 3 4 3 3 + 0 8 4 1 0 5 ( 2 1 9 4 3 5 ) + 0 0 8 8 2 2 2 ( 2 1 7 3 6 7 2 ) + 0 0 0 2 7 5 5 0',\n",
       " '|endoftext|>2 1 9 4 2 + 0 0 0 0 0 0 ( 2 1 9 4 2 0 ) + 0 0 0 6 7 0 2 ( 2 1 9 0 0 1 2 ) + 0 0 0 4 0 3 8 0',\n",
       " '|endoftext|>0 6 3 0 4 + 0 5 4 0 5 0 ( 0 1 8 0 9 0 ) + 0 0 5 4 0 5 0 ( 0 1 3 5 9 5 0 ) + 0 0 0 5 3 1 5 1',\n",
       " '|endoftext|>8 9 8 1 1 + 0 7 4 8 7 1 ( 8 6 3 0 9 1 ) + 0 0 4 6 8 5 1 ( 8 6 7 6 7 7 1 ) + 0 0 0 2 3 9 7 0',\n",
       " '|endoftext|>0 0 0 0 0 + 0 2 7 8 3 1 ( 0 2 7 8 3 1 ) + 0 0 8 3 1 2 1 ( 0 2 5 2 5 3 1 ) + 0 0 0 2 7 8 3 1',\n",
       " '|endoftext|>0 4 8 2 1 + 0 6 7 9 7 1 ( 0 0 6 2 9 1 ) + 0 0 0 4 8 2 1 ( 0 0 6 6 7 4 1 ) + 0 0 0 6 3 1 5 0',\n",
       " '|endoftext|>6 8 0 0 4 + 0 3 4 0 0 2 ( 6 1 5 0 4 2 ) + 0 0 8 4 4 3 5 ( 6 1 3 5 8 5 5 ) + 0 0 0 4 2 7 6 2']"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_cot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### recurrence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "think = tokenizer.bos_token_id\n",
    "ans = tokenizer.bos_token_id\n",
    "eos = tokenizer.eos_token_id\n",
    "\n",
    "def collate_fn(batch):\n",
    "    input_ids, labels, labels_mask, attention_mask = [], [], [], []\n",
    "    for sample in batch:\n",
    "        task, lab, cot = sample['task'], sample['labels'], sample['cot']\n",
    "        task_tokens = tokenizer.encode(task, add_special_tokens=False)\n",
    "        labels_tokens = tokenizer.encode(lab, add_special_tokens=False)\n",
    "        cot_tokens = tokenizer.encode(cot, add_special_tokens=False)\n",
    "\n",
    "        if args.use_cot:\n",
    "            full_input = task_tokens + [think] + cot_tokens + [ans] + labels_tokens + [eos]\n",
    "        else:\n",
    "            full_input = task_tokens + [ans] + labels_tokens + [eos]\n",
    "        inp_ids = torch.tensor(full_input)\n",
    "        input_ids.append(inp_ids)\n",
    "\n",
    "        lab = torch.tensor(full_input)\n",
    "        lab[:len(task_tokens)] = -100\n",
    "        labels.append(lab)\n",
    "\n",
    "        lab_mask = torch.ones_like(inp_ids)\n",
    "        lab_mask[:len(task_tokens)] = 0\n",
    "        labels_mask.append(lab_mask)\n",
    "        attention_mask.append(torch.ones_like(inp_ids))\n",
    "        \n",
    "    input_ids = pad_sequence(input_ids, padding_value=id_pad_value, batch_first=True)\n",
    "    attention_mask = pad_sequence(attention_mask, padding_value=0, batch_first=True)\n",
    "    labels = pad_sequence(labels, padding_value=id_pad_value, batch_first=True)\n",
    "    labels_mask = pad_sequence(labels_mask, padding_value=0, batch_first=True)\n",
    "\n",
    "    collated = {'input_ids': input_ids,\n",
    "                'labels': labels, \n",
    "                'attention_mask': attention_mask,\n",
    "                }\n",
    "    if args.num_mem_tokens is not None:\n",
    "        # add labels mask only for RMT, ARMT\n",
    "        collated['labels_mask'] = labels_mask.bool()\n",
    "    return collated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = [hf_dataset['valid'][i] for i in range(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'task': '5 6 3 2 * 7 4 3 4',\n",
       "  'labels': '5 5 6 0 8 2 0 1',\n",
       "  'cot': '5 5 5 6 1 + 0 0 6 4 9 0 ( 5 5 1 1 1 1 ) + 0 0 5 9 0 7 0 ( 5 5 6 0 2 8 0 ) + 0 0 0 0 6 4 9 0'},\n",
       " {'task': '6 9 1 5 * 6 4 4 7',\n",
       "  'labels': '6 1 4 9 8 6 8 3',\n",
       "  'cot': '6 7 1 1 3 + 0 4 8 7 0 2 ( 6 1 0 9 3 2 ) + 0 0 4 8 7 0 2 ( 6 1 4 7 1 3 2 ) + 0 0 0 2 7 3 6 3'},\n",
       " {'task': '6 7 3 9 * 8 9 1 7',\n",
       "  'labels': '8 4 4 8 8 4 7 6',\n",
       "  'cot': '8 0 0 5 7 + 0 4 8 3 4 8 ( 8 4 8 8 1 9 ) + 0 0 6 7 3 9 0 ( 8 4 4 6 5 8 1 ) + 0 0 0 2 3 6 5 6'},\n",
       " {'task': '3 0 3 4 * 3 4 6 5',\n",
       "  'labels': '9 2 8 1 8 2 4 2',\n",
       "  'cot': '9 0 9 2 1 + 0 2 1 2 7 1 ( 9 2 0 5 8 1 ) + 0 0 8 1 8 5 2 ( 9 2 8 6 6 7 2 ) + 0 0 0 5 1 5 1 2'},\n",
       " {'task': '0 3 3 7 * 8 5 6 5',\n",
       "  'labels': '0 4 1 3 7 4 1 4',\n",
       "  'cot': '0 4 6 8 5 + 0 0 5 6 6 3 ( 0 4 1 5 2 4 ) + 0 0 0 8 9 3 4 ( 0 4 1 3 2 8 4 ) + 0 0 0 0 5 6 6 3'},\n",
       " {'task': '3 6 0 6 * 4 3 8 7',\n",
       "  'labels': '2 4 5 7 9 4 7 4',\n",
       "  'cot': '2 5 2 4 2 + 0 9 8 1 8 1 ( 2 4 1 6 0 2 ) + 0 0 4 0 5 8 4 ( 2 4 5 6 5 0 5 ) + 0 0 0 1 4 4 2 4'},\n",
       " {'task': '4 7 8 4 * 2 9 1 6',\n",
       "  'labels': '8 0 8 9 7 1 0 3',\n",
       "  'cot': '8 4 7 9 0 + 0 6 6 8 3 4 ( 8 0 4 8 4 4 ) + 0 0 4 7 8 4 0 ( 8 0 8 5 3 9 0 ) + 0 0 0 4 4 2 9 2'},\n",
       " {'task': '2 9 6 1 * 0 5 1 9',\n",
       "  'labels': '0 0 8 1 8 4 5 1',\n",
       "  'cot': '0 0 0 0 0 + 0 0 6 4 8 0 ( 0 0 6 4 8 0 ) + 0 0 2 9 6 1 0 ( 0 0 8 3 5 2 0 ) + 0 0 0 8 2 2 5 1'},\n",
       " {'task': '1 1 5 4 * 5 6 0 5',\n",
       "  'labels': '5 1 2 8 4 8 2 2',\n",
       "  'cot': '5 5 5 2 2 + 0 6 6 0 7 2 ( 5 1 2 3 9 2 ) + 0 0 0 0 0 0 0 ( 5 1 2 3 9 2 0 ) + 0 0 0 5 5 5 2 2'},\n",
       " {'task': '3 9 9 3 * 0 9 3 3',\n",
       "  'labels': '0 7 2 6 3 5 3 1',\n",
       "  'cot': '0 0 0 0 0 + 0 7 3 9 5 3 ( 0 7 3 9 5 3 ) + 0 0 9 7 9 1 1 ( 0 7 2 7 5 5 1 ) + 0 0 0 9 7 9 1 1'}]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collate_fn(batch)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
