{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "import os\n",
    "import datasets\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"gpt2\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cpt_path = \"/workspace-SR006.nfs2/Bulatov_A/rmt/runs/test/4_by_4_mult/Llama-3.2-1B-Instruct/smol:qa1-5-1:9/SEGM_1x1024_1024_64_LR3e-04-lora-mnc-distill__short/checkpoint-5000/pytorch_model.bin\"\n",
    "\n",
    "model.load_state_dict(torch.load(cpt_path), strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir = \"/workspace-SR006.nfs2/Bulatov_A/rmt/data/implicit_chain_of_thought/4_by_4_mult\"\n",
    "\n",
    "train_path = os.path.join(dataset_dir, \"train\")\n",
    "valid_path = os.path.join(dataset_dir, \"valid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = datasets.load_from_disk(train_path)\n",
    "valid_dataset = datasets.load_from_disk(valid_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "id_pad_value = tokenizer.pad_token_id if tokenizer.pad_token_id is not None else tokenizer.eos_token_id\n",
    "def collate_fn(batch):\n",
    "    input_ids = [torch.tensor(b['examples_all']) for b in batch]\n",
    "    labels = [torch.tensor(b['labels_all']) for b in batch]\n",
    "    attention_mask = [torch.ones_like(b, dtype=int) for b in input_ids]\n",
    "    labels_mask = [torch.sign(torch.tensor(b['labels_all'])) for b in batch]\n",
    "\n",
    "\n",
    "    input_ids = pad_sequence(input_ids, padding_value=id_pad_value, batch_first=True)\n",
    "    labels = pad_sequence(labels, padding_value=id_pad_value, batch_first=True)\n",
    "    attention_mask = pad_sequence(attention_mask, padding_value=0, batch_first=True)\n",
    "    labels_mask = pad_sequence(labels_mask, padding_value=0, batch_first=True)\n",
    "\n",
    "    collated = {'input_ids': input_ids,\n",
    "                'labels': labels,\n",
    "                'attention_mask': attention_mask,\n",
    "                }\n",
    "    # if args.num_mem_tokens is not None:\n",
    "    #     # add labels mask only for RMT, ARMT\n",
    "    #     collated['labels_mask'] = labels_mask.bool()\n",
    "    return collated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_cot(text):\n",
    "    if '<|endoftext|>' not in text:\n",
    "        return ''\n",
    "    else:\n",
    "        return text.split('<|endoftext|>')[0].strip()\n",
    "\n",
    "def extract_answer(text):\n",
    "    if '####' not in text:\n",
    "        return ''\n",
    "    else:\n",
    "        ans = text.split('####')[-1]\n",
    "        ans = ans.split('<|endoftext|>')[0]\n",
    "        return ans.strip()\n",
    "        \n",
    "def compute_accuracy(eval_pred):\n",
    "    preds = eval_pred.predictions[:, :-1]\n",
    "    labels = eval_pred.label_ids[:, 1:]\n",
    "    # inputs = eval_pred.inputs\n",
    "    # losses = eval_pred.losses\n",
    "\n",
    "    # labels = collated['labels'][:, 1:]\n",
    "\n",
    "    labels_masks = labels > 0\n",
    "    preds_full = [p[m] for p, m in zip(preds, labels_masks)]\n",
    "    labels_full = [l[m] for l, m in zip(labels, labels_masks)]\n",
    "\n",
    "    preds_full_text = tokenizer.batch_decode(preds_full, add_special_tokens=True)\n",
    "    labels_full_text = tokenizer.batch_decode(labels_full, add_special_tokens=True)\n",
    "\n",
    "    preds_cot = [extract_cot(p) for p in preds_full_text]\n",
    "    preds_ans = [extract_answer(p) for p in preds_full_text]\n",
    "\n",
    "    labels_cot = [extract_cot(l) for l in labels_full_text]\n",
    "    labels_ans = [extract_answer(l) for l in labels_full_text]\n",
    "    \n",
    "    # Calculate accuracy only on the unignored tokens\n",
    "    acc_cot = np.mean([c == l for c, l in zip(preds_cot, labels_cot)])\n",
    "    acc_ans = np.mean([c == l for c, l in zip(preds_ans, labels_ans)])\n",
    "\n",
    "    return {'accuracy_cot': acc_cot, 'accuracy_ans': acc_ans}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'eval_pred' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[43]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m predictions = \u001b[43meval_pred\u001b[49m.predictions\n\u001b[32m      2\u001b[39m label_ids = eval_pred.label_ids\n\u001b[32m      3\u001b[39m inputs = eval_pred.inputs\n",
      "\u001b[31mNameError\u001b[39m: name 'eval_pred' is not defined"
     ]
    }
   ],
   "source": [
    "predictions = eval_pred.predictions\n",
    "label_ids = eval_pred.label_ids\n",
    "inputs = eval_pred.inputs\n",
    "losses = eval_pred.losses\n",
    "# elements = (self.predictions, self.label_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`loss_type=None` was set in the config but it is unrecognised.Using the default loss: `ForCausalLMLoss`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "odict_keys(['loss', 'logits', 'past_key_values'])\n"
     ]
    }
   ],
   "source": [
    "batch = [valid_dataset[i] for i in range(10)]\n",
    "collated = collate_fn(batch)\n",
    "\n",
    "out = model(**collated)\n",
    "print(out.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.3672e-06, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 71)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = out.logits.argmax(dim=-1).cpu().numpy()\n",
    "preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_text = tokenizer.batch_decode(preds, add_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[', 9 9 4 * 0 0 7 0 5 5 5 5 6 1 + 0 0 6 4 9 0 ( 5 5 1 1 1 1 ) + 0 0 5 9 0 7 0 ( 5 5 6 0 2 8 0 ) + 0 0 0 0 6 4 9 0 ',\n",
       " ' #### 5 5 6 0 8 2 0 1 ',\n",
       " ' #']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_text[0].split('<|endoftext|>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mIndexError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[105]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[33;43m'\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m<|endoftext|>\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "\u001b[31mIndexError\u001b[39m: list index out of range"
     ]
    }
   ],
   "source": [
    "''.split('<|endoftext|>')[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = collated['labels'][:, 1:]\n",
    "\n",
    "labels_masks = labels > 0\n",
    "preds_full = [p[m] for p, m in zip(preds[:, :-1], labels_masks)]\n",
    "labels_full = [l[m] for l, m in zip(labels, labels_masks)]\n",
    "\n",
    "preds_full_text = tokenizer.batch_decode(preds_full, add_special_tokens=True)\n",
    "labels_full_text = tokenizer.batch_decode(labels_full, add_special_tokens=True)\n",
    "\n",
    "preds_cot = [extract_cot(p) for p in preds_full_text]\n",
    "preds_ans = [extract_answer(p) for p in preds_full_text]\n",
    "\n",
    "labels_cot = [extract_cot(l) for l in labels_full_text]\n",
    "labels_ans = [extract_answer(l) for l in labels_full_text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels = collated['labels'][:, 1:]\n",
    "\n",
    "# labels_masks = labels > 0\n",
    "# preds_full = [p[m] for p, m in zip(preds[:, :-1], labels_masks)]\n",
    "# labels_full = [l[m] for l, m in zip(labels, labels_masks)]\n",
    "\n",
    "# preds_full_text = tokenizer.batch_decode(preds_full, add_special_tokens=True)\n",
    "# labels_full_text = tokenizer.batch_decode(labels_full, add_special_tokens=True)\n",
    "\n",
    "# preds_cot = [p.split('<|endoftext|>')[0].strip() for p in preds_full_text]\n",
    "# labels_cot = [l.split('<|endoftext|>')[0].strip() for l in labels_full_text]\n",
    "\n",
    "# # preds_ans = [p.split('<|endoftext|>')[1].strip()[4:] for p in preds_full_text]\n",
    "# # labels_ans = [l.split('<|endoftext|>')[1].strip()[4:] for l in labels_full_text]\n",
    "\n",
    "# preds_ans = [p.split('####')[1].strip()[4:] for p in preds_full_text]\n",
    "# labels_ans = [l.split('####')[1].split('astrip()[4:] for l in labels_full_text]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' 5 6 3 2 * 7 4 3 4 <|endoftext|> 5 5 5 6 1 + 0 0 6 4 9 0 ( 5 5 1 1 1 1 ) + 0 0 5 9 0 7 0 ( 5 5 6 0 2 8 0 ) + 0 0 0 0 6 4 9 0 <|endoftext|> #### 5 5 6 0 8 2 0 1 <|endoftext|>',\n",
       " ' 6 9 1 5 * 6 4 4 7 <|endoftext|> 6 7 1 1 3 + 0 4 8 7 0 2 ( 6 1 0 9 3 2 ) + 0 0 4 8 7 0 2 ( 6 1 4 7 1 3 2 ) + 0 0 0 2 7 3 6 3 <|endoftext|> #### 6 1 4 9 8 6 8 3 <|endoftext|>',\n",
       " ' 6 7 3 9 * 8 9 1 7 <|endoftext|> 8 0 0 5 7 + 0 4 8 3 4 8 ( 8 4 8 8 1 9 ) + 0 0 6 7 3 9 0 ( 8 4 4 6 5 8 1 ) + 0 0 0 2 3 6 5 6 <|endoftext|> #### 8 4 4 8 8 4 7 6 <|endoftext|>',\n",
       " ' 3 0 3 4 * 3 4 6 5 <|endoftext|> 9 0 9 2 1 + 0 2 1 2 7 1 ( 9 2 0 5 8 1 ) + 0 0 8 1 8 5 2 ( 9 2 8 6 6 7 2 ) + 0 0 0 5 1 5 1 2 <|endoftext|> #### 9 2 8 1 8 2 4 2 <|endoftext|>',\n",
       " ' 0 3 3 7 * 8 5 6 5 <|endoftext|> 0 4 6 8 5 + 0 0 5 6 6 3 ( 0 4 1 5 2 4 ) + 0 0 0 8 9 3 4 ( 0 4 1 3 2 8 4 ) + 0 0 0 0 5 6 6 3 <|endoftext|> #### 0 4 1 3 7 4 1 4 <|endoftext|>',\n",
       " ' 3 6 0 6 * 4 3 8 7 <|endoftext|> 2 5 2 4 2 + 0 9 8 1 8 1 ( 2 4 1 6 0 2 ) + 0 0 4 0 5 8 4 ( 2 4 5 6 5 0 5 ) + 0 0 0 1 4 4 2 4 <|endoftext|> #### 2 4 5 7 9 4 7 4 <|endoftext|>',\n",
       " ' 4 7 8 4 * 2 9 1 6 <|endoftext|> 8 4 7 9 0 + 0 6 6 8 3 4 ( 8 0 4 8 4 4 ) + 0 0 4 7 8 4 0 ( 8 0 8 5 3 9 0 ) + 0 0 0 4 4 2 9 2 <|endoftext|> #### 8 0 8 9 7 1 0 3 <|endoftext|>',\n",
       " ' 2 9 6 1 * 0 5 1 9 <|endoftext|> 0 0 0 0 0 + 0 0 6 4 8 0 ( 0 0 6 4 8 0 ) + 0 0 2 9 6 1 0 ( 0 0 8 3 5 2 0 ) + 0 0 0 8 2 2 5 1 <|endoftext|> #### 0 0 8 1 8 4 5 1 <|endoftext|>',\n",
       " ' 1 1 5 4 * 5 6 0 5 <|endoftext|> 5 5 5 2 2 + 0 6 6 0 7 2 ( 5 1 2 3 9 2 ) + 0 0 0 0 0 0 0 ( 5 1 2 3 9 2 0 ) + 0 0 0 5 5 5 2 2 <|endoftext|> #### 5 1 2 8 4 8 2 2 <|endoftext|>',\n",
       " ' 3 9 9 3 * 0 9 3 3 <|endoftext|> 0 0 0 0 0 + 0 7 3 9 5 3 ( 0 7 3 9 5 3 ) + 0 0 9 7 9 1 1 ( 0 7 2 7 5 5 1 ) + 0 0 0 9 7 9 1 1 <|endoftext|> #### 0 7 2 6 3 5 3 1 <|endoftext|>']"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.batch_decode(collated['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' 5 5 5 6 1 + 0 0 6 4 9 0 ( 5 5 1 1 1 1 ) + 0 0 5 9 0 7 0 ( 5 5 6 0 2 8 0 ) + 0 0 0 0 6 4 9 0 <|endoftext|> #### 5 5 6 0 8 2 0 1 <|endoftext|>',\n",
       " ' 6 7 1 1 3 + 0 4 8 7 0 2 ( 6 1 0 9 3 2 ) + 0 0 4 8 7 0 2 ( 6 1 4 7 1 3 2 ) + 0 0 0 2 7 3 6 3 <|endoftext|> #### 6 1 4 9 8 6 8 3 <|endoftext|>',\n",
       " ' 8 0 0 5 7 + 0 4 8 3 4 8 ( 8 4 8 8 1 9 ) + 0 0 6 7 3 9 0 ( 8 4 4 6 5 8 1 ) + 0 0 0 2 3 6 5 6 <|endoftext|> #### 8 4 4 8 8 4 7 6 <|endoftext|>',\n",
       " ' 9 0 9 2 1 + 0 2 1 2 7 1 ( 9 2 0 5 8 1 ) + 0 0 8 1 8 5 2 ( 9 2 8 6 6 7 2 ) + 0 0 0 5 1 5 1 2 <|endoftext|> #### 9 2 8 1 8 2 4 2 <|endoftext|>',\n",
       " ' 0 4 6 8 5 + 0 0 5 6 6 3 ( 0 4 1 5 2 4 ) + 0 0 0 8 9 3 4 ( 0 4 1 3 2 8 4 ) + 0 0 0 0 5 6 6 3 <|endoftext|> #### 0 4 1 3 7 4 1 4 <|endoftext|>',\n",
       " ' 2 5 2 4 2 + 0 9 8 1 8 1 ( 2 4 1 6 0 2 ) + 0 0 4 0 5 8 4 ( 2 4 5 6 5 0 5 ) + 0 0 0 1 4 4 2 4 <|endoftext|> #### 2 4 5 7 9 4 7 4 <|endoftext|>',\n",
       " ' 8 4 7 9 0 + 0 6 6 8 3 4 ( 8 0 4 8 4 4 ) + 0 0 4 7 8 4 0 ( 8 0 8 5 3 9 0 ) + 0 0 0 4 4 2 9 2 <|endoftext|> #### 8 0 8 9 7 1 0 3 <|endoftext|>',\n",
       " ' 0 0 0 0 0 + 0 0 6 4 8 0 ( 0 0 6 4 8 0 ) + 0 0 2 9 6 1 0 ( 0 0 8 3 5 2 0 ) + 0 0 0 8 2 2 5 1 <|endoftext|> #### 0 0 8 1 8 4 5 1 <|endoftext|>',\n",
       " ' 5 5 5 2 2 + 0 6 6 0 7 2 ( 5 1 2 3 9 2 ) + 0 0 0 0 0 0 0 ( 5 1 2 3 9 2 0 ) + 0 0 0 5 5 5 2 2 <|endoftext|> #### 5 1 2 8 4 8 2 2 <|endoftext|>',\n",
       " ' 0 0 0 0 0 + 0 7 3 9 5 3 ( 0 7 3 9 5 3 ) + 0 0 9 7 9 1 1 ( 0 7 2 7 5 5 1 ) + 0 0 0 9 7 9 1 1 <|endoftext|> #### 0 7 2 6 3 5 3 1 <|endoftext|>']"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_full_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['5 5 5 6 1 + 0 0 6 4 9 0 ( 5 5 1 1 1 1 ) + 0 0 5 9 0 7 0 ( 5 5 6 0 2 8 0 ) + 0 0 0 0 6 4 9 0',\n",
       " '6 7 1 1 3 + 0 4 8 7 0 2 ( 6 1 0 9 3 2 ) + 0 0 4 8 7 0 2 ( 6 1 4 7 1 3 2 ) + 0 0 0 2 7 3 6 3',\n",
       " '8 0 0 5 7 + 0 4 8 3 4 8 ( 8 4 8 8 1 9 ) + 0 0 6 7 3 9 0 ( 8 4 4 6 5 8 1 ) + 0 0 0 2 3 6 5 6',\n",
       " '9 0 9 2 1 + 0 2 1 2 7 1 ( 9 2 0 5 8 1 ) + 0 0 8 1 8 5 2 ( 9 2 8 6 6 7 2 ) + 0 0 0 5 1 5 1 2',\n",
       " '0 4 6 8 5 + 0 0 5 6 6 3 ( 0 4 1 5 2 4 ) + 0 0 0 8 9 3 4 ( 0 4 1 3 2 8 4 ) + 0 0 0 0 5 6 6 3',\n",
       " '2 5 2 4 2 + 0 9 8 1 8 1 ( 2 4 1 6 0 2 ) + 0 0 4 0 5 8 4 ( 2 4 5 6 5 0 5 ) + 0 0 0 1 4 4 2 4',\n",
       " '8 4 7 9 0 + 0 6 6 8 3 4 ( 8 0 4 8 4 4 ) + 0 0 4 7 8 4 0 ( 8 0 8 5 3 9 0 ) + 0 0 0 4 4 2 9 2',\n",
       " '0 0 0 0 0 + 0 0 6 4 8 0 ( 0 0 6 4 8 0 ) + 0 0 2 9 6 1 0 ( 0 0 8 3 5 2 0 ) + 0 0 0 8 2 2 5 1',\n",
       " '5 5 5 2 2 + 0 6 6 0 7 2 ( 5 1 2 3 9 2 ) + 0 0 0 0 0 0 0 ( 5 1 2 3 9 2 0 ) + 0 0 0 5 5 5 2 2',\n",
       " '0 0 0 0 0 + 0 7 3 9 5 3 ( 0 7 3 9 5 3 ) + 0 0 9 7 9 1 1 ( 0 7 2 7 5 5 1 ) + 0 0 0 9 7 9 1 1']"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_cot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['5 5 5 6 1 + 0 0 6 4 9 0 ( 5 5 1 1 1 1 ) + 0 0 5 9 0 7 0 ( 5 5 6 0 2 8 0 ) + 0 0 0 0 6 4 9 0',\n",
       " '6 7 1 1 3 + 0 4 8 7 0 2 ( 6 1 0 9 3 2 ) + 0 0 4 8 7 0 2 ( 6 1 4 7 1 3 2 ) + 0 0 0 2 7 3 6 3',\n",
       " '8 0 0 5 7 + 0 4 8 3 4 8 ( 8 4 8 8 1 9 ) + 0 0 6 7 3 9 0 ( 8 4 4 6 5 8 1 ) + 0 0 0 2 3 6 5 6',\n",
       " '9 0 9 2 1 + 0 2 1 2 7 1 ( 9 2 0 5 8 1 ) + 0 0 8 1 8 5 2 ( 9 2 8 6 6 7 2 ) + 0 0 0 5 1 5 1 2',\n",
       " '0 4 6 8 5 + 0 0 5 6 6 3 ( 0 4 1 5 2 4 ) + 0 0 0 8 9 3 4 ( 0 4 1 3 2 8 4 ) + 0 0 0 0 5 6 6 3',\n",
       " '2 5 2 4 2 + 0 9 8 1 8 1 ( 2 4 1 6 0 2 ) + 0 0 4 0 5 8 4 ( 2 4 5 6 5 0 5 ) + 0 0 0 1 4 4 2 4',\n",
       " '8 4 7 9 0 + 0 6 6 8 3 4 ( 8 0 4 8 4 4 ) + 0 0 4 7 8 4 0 ( 8 0 8 5 3 9 0 ) + 0 0 0 4 4 2 9 2',\n",
       " '0 0 0 0 0 + 0 0 6 4 8 0 ( 0 0 6 4 8 0 ) + 0 0 2 9 6 1 0 ( 0 0 8 3 5 2 0 ) + 0 0 0 8 2 2 5 1',\n",
       " '5 5 5 2 2 + 0 6 6 0 7 2 ( 5 1 2 3 9 2 ) + 0 0 0 0 0 0 0 ( 5 1 2 3 9 2 0 ) + 0 0 0 5 5 5 2 2',\n",
       " '0 0 0 0 0 + 0 7 3 9 5 3 ( 0 7 3 9 5 3 ) + 0 0 9 7 9 1 1 ( 0 7 2 7 5 5 1 ) + 0 0 0 9 7 9 1 1']"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_cot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['5 5 6 0 8 2 0 1',\n",
       " '6 1 4 9 8 6 8 3',\n",
       " '8 4 4 8 8 4 7 6',\n",
       " '9 2 8 1 8 2 4 2',\n",
       " '0 4 1 3 7 4 1 4',\n",
       " '2 4 5 7 9 4 7 4',\n",
       " '8 0 8 9 7 1 0 3',\n",
       " '0 0 8 1 8 4 5 1',\n",
       " '5 1 2 8 4 8 2 2',\n",
       " '0 7 2 6 3 5 3 1']"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['5 5 6 0 8 2 0 1',\n",
       " '6 1 4 9 8 6 8 3',\n",
       " '8 4 4 8 8 4 7 6',\n",
       " '9 2 8 1 8 2 4 2',\n",
       " '0 4 1 3 7 4 1 4',\n",
       " '2 4 5 7 9 4 7 4',\n",
       " '8 0 8 9 7 1 0 3',\n",
       " '0 0 8 1 8 4 5 1',\n",
       " '5 1 2 8 4 8 2 2',\n",
       " '0 7 2 6 3 5 3 1']"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'labels_texta' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[60]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mlabels_texta\u001b[49m\n\u001b[32m      2\u001b[39m [\u001b[32m0\u001b[39m].split(\u001b[33m'\u001b[39m\u001b[33m<|endoftext|>\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'labels_texta' is not defined"
     ]
    }
   ],
   "source": [
    "labels_text\n",
    "[0].split('<|endoftext|>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'labels_mask'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[41]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m p, l, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(preds, collated[\u001b[33m'\u001b[39m\u001b[33mlabels\u001b[39m\u001b[33m'\u001b[39m], \u001b[43mcollated\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mlabels_mask\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m):\n\u001b[32m      2\u001b[39m     \u001b[38;5;28mprint\u001b[39m(p[m], l[m])\n",
      "\u001b[31mKeyError\u001b[39m: 'labels_mask'"
     ]
    }
   ],
   "source": [
    "for p, l, m in zip(preds, collated['labels'], collated['labels_mask']):\n",
    "    print(p[m], l[m])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   11,   860,   860,   604,  1635,   657,   657,   767,   657,\n",
       "         642,   642,   642,   642,   718,   352,  1343,   657,   657,\n",
       "         718,   604,   860,   657,   357,   642,   642,   352,   352,\n",
       "         352,   352,  1267,  1343,   657,   657,   642,   860,   657,\n",
       "         767,   657,   357,   642,   642,   718,   657,   362,   807,\n",
       "         657,  1267,  1343,   657,   657,   657,   657,   718,   604,\n",
       "         860,   657,   220, 50256,  1303, 21017,   642,   642,   718,\n",
       "         657,   807,   362,   657,   352,   220, 50256,  1303])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[', 9 9 4 * 0 0 7 0 5 5 5 5 6 1 + 0 0 6 4 9 0 ( 5 5 1 1 1 1 ) + 0 0 5 9 0 7 0 ( 5 5 6 0 2 8 0 ) + 0 0 0 0 6 4 9 0 <|endoftext|> #### 5 5 6 0 8 2 0 1 <|endoftext|> #', ' the 0 1 6 0 1 0 8 3 6 6 7 1 1 3 + 0 4 8 7 0 2 ( 6 1 0 9 3 2 ) + 0 0 4 8 7 0 2 ( 6 1 4 7 1 3 2 ) + 0 0 0 2 7 3 6 3 <|endoftext|> #### 6 1 4 9 8 6 8 3 <|endoftext|> #', ' the 0 8 4 + 2 8 3 0 8 8 0 0 5 7 + 0 4 8 3 4 8 ( 8 4 8 8 1 9 ) + 0 0 6 7 3 9 0 ( 8 4 4 6 5 8 1 ) + 0 0 0 2 3 6 5 6 <|endoftext|> #### 8 4 4 8 8 4 7 6 <|endoftext|> #', ', 2 3 2\\n 0 0 0 1 9 9 0 9 2 1 + 0 2 1 2 7 1 ( 9 2 0 5 8 1 ) + 0 0 8 1 8 5 2 ( 9 2 8 6 6 7 2 ) + 0 0 0 5 1 5 1 2 <|endoftext|> #### 9 2 8 1 8 2 4 2 <|endoftext|> #', ' the 1 - 0 0 0 1 3 2 0 0 4 6 8 5 + 0 0 5 6 6 3 ( 0 4 1 5 2 4 ) + 0 0 0 8 9 3 4 ( 0 4 1 3 2 8 4 ) + 0 0 0 0 5 6 6 3 <|endoftext|> #### 0 4 1 3 7 4 1 4 <|endoftext|> #', ', 4 5 1 0 8 2 8 1 2 2 5 2 4 2 + 0 9 8 1 8 1 ( 2 4 1 6 0 2 ) + 0 0 4 0 5 8 4 ( 2 4 5 6 5 0 5 ) + 0 0 0 1 4 4 2 4 <|endoftext|> #### 2 4 5 7 9 4 7 4 <|endoftext|> #', ' the 7 0 9\\n 0 8 3 0 0 8 4 7 9 0 + 0 6 6 8 3 4 ( 8 0 4 8 4 4 ) + 0 0 4 7 8 4 0 ( 8 0 8 5 3 9 0 ) + 0 0 0 4 4 2 9 2 <|endoftext|> #### 8 0 8 9 7 1 0 3 <|endoftext|> #', ', 3 9 2 0 0 0 3 0 0 0 0 0 0 0 + 0 0 6 4 8 0 ( 0 0 6 4 8 0 ) + 0 0 2 9 6 1 0 ( 0 0 8 3 5 2 0 ) + 0 0 0 8 2 2 5 1 <|endoftext|> #### 0 0 8 1 8 4 5 1 <|endoftext|> #', ', 7 7 3average 1 0 0 2 5 5 5 5 2 2 + 0 6 6 0 7 2 ( 5 1 2 3 9 2 ) + 0 0 0 0 0 0 0 ( 5 1 2 3 9 2 0 ) + 0 0 0 5 5 5 2 2 <|endoftext|> #### 5 1 2 8 4 8 2 2 <|endoftext|> #', ', 5 9 1ACH 0 3 7 0 0 0 0 0 0 0 + 0 7 3 9 5 3 ( 0 7 3 9 5 3 ) + 0 0 9 7 9 1 1 ( 0 7 2 7 5 5 1 ) + 0 0 0 9 7 9 1 1 <|endoftext|> #### 0 7 2 6 3 5 3 1 <|endoftext|> #']\n"
     ]
    }
   ],
   "source": [
    "pred_texts = tokenizer.batch_decode(preds, skip_special_tokens=False)\n",
    "print(pred_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' 5 6 3 2 * 7 4 3 4 <|endoftext|> 5 5 5 6 1 + 0 0 6 4 9 0 ( 5 5 1 1 1 1 ) + 0 0 5 9 0 7 0 ( 5 5 6 0 2 8 0 ) + 0 0 0 0 6 4 9 0 <|endoftext|> #### 5 5 6 0 8 2 0 1 <|endoftext|>', ' 6 9 1 5 * 6 4 4 7 <|endoftext|> 6 7 1 1 3 + 0 4 8 7 0 2 ( 6 1 0 9 3 2 ) + 0 0 4 8 7 0 2 ( 6 1 4 7 1 3 2 ) + 0 0 0 2 7 3 6 3 <|endoftext|> #### 6 1 4 9 8 6 8 3 <|endoftext|>', ' 6 7 3 9 * 8 9 1 7 <|endoftext|> 8 0 0 5 7 + 0 4 8 3 4 8 ( 8 4 8 8 1 9 ) + 0 0 6 7 3 9 0 ( 8 4 4 6 5 8 1 ) + 0 0 0 2 3 6 5 6 <|endoftext|> #### 8 4 4 8 8 4 7 6 <|endoftext|>', ' 3 0 3 4 * 3 4 6 5 <|endoftext|> 9 0 9 2 1 + 0 2 1 2 7 1 ( 9 2 0 5 8 1 ) + 0 0 8 1 8 5 2 ( 9 2 8 6 6 7 2 ) + 0 0 0 5 1 5 1 2 <|endoftext|> #### 9 2 8 1 8 2 4 2 <|endoftext|>', ' 0 3 3 7 * 8 5 6 5 <|endoftext|> 0 4 6 8 5 + 0 0 5 6 6 3 ( 0 4 1 5 2 4 ) + 0 0 0 8 9 3 4 ( 0 4 1 3 2 8 4 ) + 0 0 0 0 5 6 6 3 <|endoftext|> #### 0 4 1 3 7 4 1 4 <|endoftext|>', ' 3 6 0 6 * 4 3 8 7 <|endoftext|> 2 5 2 4 2 + 0 9 8 1 8 1 ( 2 4 1 6 0 2 ) + 0 0 4 0 5 8 4 ( 2 4 5 6 5 0 5 ) + 0 0 0 1 4 4 2 4 <|endoftext|> #### 2 4 5 7 9 4 7 4 <|endoftext|>', ' 4 7 8 4 * 2 9 1 6 <|endoftext|> 8 4 7 9 0 + 0 6 6 8 3 4 ( 8 0 4 8 4 4 ) + 0 0 4 7 8 4 0 ( 8 0 8 5 3 9 0 ) + 0 0 0 4 4 2 9 2 <|endoftext|> #### 8 0 8 9 7 1 0 3 <|endoftext|>', ' 2 9 6 1 * 0 5 1 9 <|endoftext|> 0 0 0 0 0 + 0 0 6 4 8 0 ( 0 0 6 4 8 0 ) + 0 0 2 9 6 1 0 ( 0 0 8 3 5 2 0 ) + 0 0 0 8 2 2 5 1 <|endoftext|> #### 0 0 8 1 8 4 5 1 <|endoftext|>', ' 1 1 5 4 * 5 6 0 5 <|endoftext|> 5 5 5 2 2 + 0 6 6 0 7 2 ( 5 1 2 3 9 2 ) + 0 0 0 0 0 0 0 ( 5 1 2 3 9 2 0 ) + 0 0 0 5 5 5 2 2 <|endoftext|> #### 5 1 2 8 4 8 2 2 <|endoftext|>', ' 3 9 9 3 * 0 9 3 3 <|endoftext|> 0 0 0 0 0 + 0 7 3 9 5 3 ( 0 7 3 9 5 3 ) + 0 0 9 7 9 1 1 ( 0 7 2 7 5 5 1 ) + 0 0 0 9 7 9 1 1 <|endoftext|> #### 0 7 2 6 3 5 3 1 <|endoftext|>']\n"
     ]
    }
   ],
   "source": [
    "labels_texts = tokenizer.batch_decode(collated['input_ids'], skip_special_tokens=False)\n",
    "print(labels_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 71])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collated['input_ids'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "', 9 9 4 * 0 0 7 0 5 5 5 5 6 1 + 0 0 6 4 9 0 ( 5 5 1 1 1 1 ) + 0 0 5 9 0 7 0 ( 5 5 6 0 2 8 0 ) + 0 0 0 0 6 4 9 0 <|endoftext|> #### 5 5 6 0 8 2 0 1 <|endoftext|> #'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_texts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   11,   860,   860,   604,  1635,   657,   657,   767,   657,\n",
       "         642,   642,   642,   642,   718,   352,  1343,   657,   657,\n",
       "         718,   604,   860,   657,   357,   642,   642,   352,   352,\n",
       "         352,   352,  1267,  1343,   657,   657,   642,   860,   657,\n",
       "         767,   657,   357,   642,   642,   718,   657,   362,   807,\n",
       "         657,  1267,  1343,   657,   657,   657,   657,   718,   604,\n",
       "         860,   657,   220, 50256,  1303, 21017,   642,   642,   718,\n",
       "         657,   807,   362,   657,   352,   220, 50256,  1303])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([71])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collated['input_ids'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ",  6\n",
      " 9  3\n",
      " 9  2\n",
      " 4  *\n",
      " *  7\n",
      " 0  4\n",
      " 0  3\n",
      " 7  4\n",
      " 0  \n",
      " 5 <|endoftext|>\n",
      " 5  5\n",
      " 5  5\n",
      " 5  5\n",
      " 6  6\n",
      " 1  1\n",
      " +  +\n",
      " 0  0\n",
      " 0  0\n",
      " 6  6\n",
      " 4  4\n",
      " 9  9\n",
      " 0  0\n",
      " (  (\n",
      " 5  5\n",
      " 5  5\n",
      " 1  1\n",
      " 1  1\n",
      " 1  1\n",
      " 1  1\n",
      " )  )\n",
      " +  +\n",
      " 0  0\n",
      " 0  0\n",
      " 5  5\n",
      " 9  9\n",
      " 0  0\n",
      " 7  7\n",
      " 0  0\n",
      " (  (\n",
      " 5  5\n",
      " 5  5\n",
      " 6  6\n",
      " 0  0\n",
      " 2  2\n",
      " 8  8\n",
      " 0  0\n",
      " )  )\n",
      " +  +\n",
      " 0  0\n",
      " 0  0\n",
      " 0  0\n",
      " 0  0\n",
      " 6  6\n",
      " 4  4\n",
      " 9  9\n",
      " 0  0\n",
      "   \n",
      "<|endoftext|> <|endoftext|>\n",
      " #  #\n",
      "### ###\n",
      " 5  5\n",
      " 5  5\n",
      " 6  6\n",
      " 0  0\n",
      " 8  8\n",
      " 2  2\n",
      " 0  0\n",
      " 1  1\n",
      "   \n",
      "<|endoftext|> <|endoftext|>\n"
     ]
    }
   ],
   "source": [
    "for p, t in zip(preds[0], collated['input_ids'][0][1:]):\n",
    "    # print(p, tokenizer.decode([p]), t, tokenizer.decode([t]))\n",
    "    print(tokenizer.decode([p]), tokenizer.decode([t]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
