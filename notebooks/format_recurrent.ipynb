{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import AdamW\n",
    "import argparse\n",
    "import os\n",
    "import tqdm\n",
    "import inspect\n",
    "import logging\n",
    "\n",
    "import datasets\n",
    "\n",
    "# from models.teacher import Teacher\n",
    "# from models.configuration_teacher import TeacherConfig\n",
    "# from data import CoTDataset, CoTDataCollator, extract_answer\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from modeling_rmt.language_modeling import MemoryCell, RecurrentWrapper\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from transformers import AutoModelForCausalLM\n",
    "from transformers.modeling_outputs import CausalLMOutputWithCrossAttentions\n",
    "from torch.nn import CrossEntropyLoss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained('gpt2')\n",
    "tokenizer = AutoTokenizer.from_pretrained('gpt2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecurrentWrapperNoSegmentation(RecurrentWrapper):\n",
    "    def forward(self, segments, labels, output_attentions=None, output_hidden_states=None):\n",
    "        # segments = segments['segments']\n",
    "        # for seg in segments:\n",
    "        #     print(tokenizer.batch_decode(seg['input_ids'], skip_special_tokens=True))\n",
    "        memory_state = None\n",
    "\n",
    "        cell_outputs = []\n",
    "        for seg_num, segment in enumerate(segments):\n",
    "            cell_out, memory_state = self.memory_cell(input_ids=segment['input_ids'],\n",
    "                                                      attention_mask=segment['attention_mask'],\n",
    "                                                      memory_state=memory_state, output_hidden_states=True)\n",
    "            cell_outputs.append(cell_out)\n",
    "            self.manage_gradients(memory_state, seg_num)\n",
    "\n",
    "        out = self.process_outputs(cell_outputs, segments,\n",
    "                                   output_attentions=output_attentions,\n",
    "                                   output_hidden_states=output_hidden_states)\n",
    "        return out\n",
    "\n",
    "    def generate(self, segments, **generate_kwargs):\n",
    "        raise NotImplementedError(\"Generation not implemented for this wrapper.\")\n",
    "        memory_state = None\n",
    "        for seg_num, segment in enumerate(segments[:-1]):\n",
    "            cell_out, memory_state = self.memory_cell(**segment, memory_state=memory_state, output_hidden_states=True)\n",
    "\n",
    "        final_segment = segments[-1]\n",
    "        out = self.memory_cell.generate(**final_segment, memory_state=memory_state, **generate_kwargs)\n",
    "\n",
    "        return out\n",
    "\n",
    "    def process_outputs(self, cell_outputs, segments, **kwargs):\n",
    "        out = CausalLMOutputWithCrossAttentions()\n",
    "        proxy_out = {}\n",
    "        for seg_num, segment in enumerate(segments):\n",
    "            cell_out = cell_outputs[seg_num]\n",
    "\n",
    "            full_logits = cell_out.logits\n",
    "\n",
    "            labels = segment.get('labels')\n",
    "            if labels is not None:\n",
    "                shift_labels = labels[..., 1:].contiguous()\n",
    "                shift_logits = full_logits[..., :-1, :].contiguous()\n",
    "                flat_labels = shift_labels.view(-1)\n",
    "                flat_logits = shift_logits.view(-1, shift_logits.size(-1))\n",
    "\n",
    "                loss_fct = CrossEntropyLoss()\n",
    "                labels_mask = segment.get('labels_mask')\n",
    "                if labels_mask is not None:\n",
    "                    shift_mask = labels_mask[..., :-1].contiguous()\n",
    "\n",
    "                    flat_labels = flat_labels[shift_mask.view(-1)]\n",
    "                    flat_logits = flat_logits[shift_mask.view(-1)]\n",
    "\n",
    "                    if labels_mask.sum() == 0:\n",
    "                        loss_value = 0\n",
    "                    else:\n",
    "                        loss_value = loss_fct(flat_logits, flat_labels)\n",
    "\n",
    "                proxy_out[f'loss_{seg_num}'] = loss_value\n",
    "            else:\n",
    "                proxy_out[f'loss_{seg_num}'] = 0\n",
    "\n",
    "            segment_keys = ['loss']\n",
    "            if kwargs.get('output_attentions'):\n",
    "                segment_keys.append('attentions')\n",
    "            if kwargs.get('output_hidden_states'):\n",
    "                segment_keys.append('hidden_states')\n",
    "\n",
    "            for key, value in cell_out.items():\n",
    "                if any([sk in key for sk in segment_keys]):\n",
    "                    proxy_out[f'{key}_{seg_num}'] = value\n",
    "\n",
    "        num_segments = len(segments)\n",
    "        out['loss'] = sum([proxy_out[f'loss_{seg_num}'] for seg_num in range(num_segments)]) / num_segments\n",
    "        out['logits'] = torch.cat([cell_out.logits for cell_out in cell_outputs], dim=1)\n",
    "        # print(out.keys(), out.loss)\n",
    "\n",
    "        return out\n",
    "\n",
    "    def gradient_checkpointing_enable(self, *args, **kwargs):\n",
    "        if hasattr(self.memory_cell.model, \"gradient_checkpointing_enable\"):\n",
    "            return self.memory_cell.model.gradient_checkpointing_enable(*args, **kwargs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory_cell = MemoryCell(model, num_mem_tokens=16)\n",
    "# recurrent_wrapper = RecurrentWrapper(memory_cell, segment_size=512)\n",
    "rmt = RecurrentWrapperNoSegmentation(memory_cell, segment_size=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = rmt(**collated)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(10.4265, grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "self = rmt\n",
    "output_attentions = False\n",
    "output_hidden_states = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.4557, grad_fn=<MeanBackward0>) tensor(9.1104, grad_fn=<StdBackward0>)\n",
      "tensor(0.4604, grad_fn=<MeanBackward0>) tensor(10.1487, grad_fn=<StdBackward0>)\n",
      "tensor(0.4524, grad_fn=<MeanBackward0>) tensor(10.0450, grad_fn=<StdBackward0>)\n",
      "tensor(0.3894, grad_fn=<MeanBackward0>) tensor(9.3270, grad_fn=<StdBackward0>)\n",
      "tensor(0.3663, grad_fn=<MeanBackward0>) tensor(8.9285, grad_fn=<StdBackward0>)\n",
      "tensor(0.3589, grad_fn=<MeanBackward0>) tensor(8.8887, grad_fn=<StdBackward0>)\n",
      "tensor(0.3725, grad_fn=<MeanBackward0>) tensor(9.0271, grad_fn=<StdBackward0>)\n",
      "tensor(0.3775, grad_fn=<MeanBackward0>) tensor(9.1252, grad_fn=<StdBackward0>)\n"
     ]
    }
   ],
   "source": [
    "memory_state = None\n",
    "\n",
    "cell_outputs = []\n",
    "for seg_num, segment in enumerate(segments):\n",
    "    # cell_out, memory_state = self.memory_cell(**segment, memory_state=memory_state, output_hidden_states=True)\n",
    "    cell_out, memory_state = self.memory_cell(input_ids=segment['input_ids'],\n",
    "                                                attention_mask=segment['attention_mask'],\n",
    "                                                memory_state=memory_state, output_hidden_states=True)\n",
    "    cell_outputs.append(cell_out)\n",
    "    self.manage_gradients(memory_state, seg_num)\n",
    "    print(memory_state.mean(), memory_state.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "out.loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rmt.memory_cell.memory.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "seg_num = 1\n",
    "cell_out = cell_outputs[seg_num]\n",
    "segment = segments[seg_num]\n",
    "\n",
    "\n",
    "# out = self.process_outputs(cell_out, labels=segment['labels'],\n",
    "#                             labels_mask=segment['labels_mask'],\n",
    "#                             output_attentions=output_attentions,\n",
    "#                             output_hidden_states=output_hidden_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 11, 50257])"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cell_out.logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "kwargs = {\n",
    "    'output_attentions': False,\n",
    "    'output_hidden_states': True\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'segments' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m out = CausalLMOutputWithCrossAttentions()\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m seg_num, segment \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[43msegments\u001b[49m):\n\u001b[32m      3\u001b[39m     cell_out = cell_outputs[seg_num]\n\u001b[32m      5\u001b[39m     full_logits = cell_out.logits\n",
      "\u001b[31mNameError\u001b[39m: name 'segments' is not defined"
     ]
    }
   ],
   "source": [
    "out = CausalLMOutputWithCrossAttentions()\n",
    "for seg_num, segment in enumerate(segments):\n",
    "    cell_out = cell_outputs[seg_num]\n",
    "\n",
    "    full_logits = cell_out.logits\n",
    "    full_hidden_states = cell_out.hidden_states\n",
    "\n",
    "    labels = segment.get('labels')\n",
    "    if labels is not None:\n",
    "        shift_labels = labels[..., 1:].contiguous()\n",
    "        shift_logits = full_logits[..., :-1, :].contiguous()\n",
    "        flat_labels = shift_labels.view(-1)\n",
    "        flat_logits = shift_logits.view(-1, shift_logits.size(-1))\n",
    "\n",
    "        loss_fct = CrossEntropyLoss()\n",
    "        labels_mask = segment.get('labels_mask')\n",
    "        if labels_mask is not None:\n",
    "            shift_mask = labels_mask[..., :-1].contiguous()\n",
    "\n",
    "            flat_labels = flat_labels[shift_mask.view(-1)]\n",
    "            flat_logits = flat_logits[shift_mask.view(-1)]\n",
    "\n",
    "            if labels_mask.sum() == 0:\n",
    "                loss_value = 0\n",
    "            else:\n",
    "                loss_value = loss_fct(flat_logits, flat_labels)\n",
    "\n",
    "        out[f'loss_{seg_num}'] = loss_value\n",
    "    else:\n",
    "        out[f'loss_{seg_num}'] = 0\n",
    "\n",
    "    out[f'logits_{seg_num}'] = full_logits\n",
    "    segment_keys = ['loss', 'logits']\n",
    "    if kwargs.get('output_attentions'):\n",
    "        segment_keys.append('attentions')\n",
    "    if kwargs.get('output_hidden_states'):\n",
    "        segment_keys.append('hidden_states')\n",
    "\n",
    "    for key, value in cell_out.items():\n",
    "        if any([sk in key for sk in segment_keys]):\n",
    "            out[f'{key}_{seg_num}'] = value\n",
    "\n",
    "num_segments = len(segments)\n",
    "out['loss'] = sum([out[f'loss_{seg_num}'] for seg_num in range(num_segments)]) / num_segments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_0 0\n",
      "loss_1 tensor(12.6786, grad_fn=<NllLossBackward0>)\n",
      "loss_2 tensor(14.0413, grad_fn=<NllLossBackward0>)\n",
      "loss_3 tensor(13.6104, grad_fn=<NllLossBackward0>)\n",
      "loss_4 tensor(14.0162, grad_fn=<NllLossBackward0>)\n",
      "loss_5 tensor(11.6516, grad_fn=<NllLossBackward0>)\n",
      "loss_6 tensor(16.1613, grad_fn=<NllLossBackward0>)\n",
      "loss_7 tensor(12.0924, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(11.7815, grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "for k, v in out.items():\n",
    "    if 'loss' in k:\n",
    "        print(k, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(nan, grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "out = self.process_outputs(cell_outputs, labels=labels,\n",
    "                            labels_mask=labels_mask,\n",
    "                            output_attentions=output_attentions,\n",
    "                            output_hidden_states=output_hidden_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Holder:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "args = Holder()\n",
    "args.use_cot = True\n",
    "args.num_mem_tokens = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# id_pad_value = tokenizer.pad_token_id if tokenizer.pad_token_id is not None else tokenizer.eos_token_id\n",
    "# think = ans = tokenizer.bos_token_id\n",
    "# eos = tokenizer.eos_token_id\n",
    "\n",
    "# from torch.nn.utils.rnn import pad_sequence\n",
    "# def collate_fn(batch):\n",
    "#     input_ids, input_ids_generate, labels, labels_mask, attention_mask = [], [], [], [], []\n",
    "#     for sample in batch:\n",
    "#         task, lab, cot = sample['task'], sample['labels'], sample['cot']\n",
    "#         task_tokens = tokenizer.encode(task, add_special_tokens=False)\n",
    "#         labels_tokens = tokenizer.encode(lab, add_special_tokens=False)\n",
    "#         cot_tokens = tokenizer.encode(cot, add_special_tokens=False)\n",
    "\n",
    "#         if args.use_cot:\n",
    "#             full_input = task_tokens + [think] + cot_tokens + [ans] + labels_tokens + [eos]\n",
    "#             gen_input = task_tokens + [think]\n",
    "#         else:\n",
    "#             full_input = task_tokens + [ans] + labels_tokens + [eos]\n",
    "#             gen_input = task_tokens + [ans]\n",
    "        \n",
    "#         inp_ids = torch.tensor(full_input)\n",
    "#         input_ids.append(inp_ids)\n",
    "#         input_ids_generate.append(torch.tensor(gen_input))\n",
    "\n",
    "\n",
    "#         lab = torch.tensor(full_input)\n",
    "#         lab[:len(task_tokens)] = -100\n",
    "#         labels.append(lab)\n",
    "\n",
    "#         lab_mask = torch.ones_like(inp_ids)\n",
    "#         lab_mask[:len(task_tokens)] = 0\n",
    "#         labels_mask.append(lab_mask)\n",
    "#         attention_mask.append(torch.ones_like(inp_ids))\n",
    "\n",
    "#     input_ids = pad_sequence(input_ids, padding_value=id_pad_value, batch_first=True)\n",
    "#     # input_ids_generate = pad_sequence(input_ids_generate, padding_value=id_pad_value, batch_first=True)\n",
    "#     attention_mask = pad_sequence(attention_mask, padding_value=0, batch_first=True)\n",
    "#     labels = pad_sequence(labels, padding_value=id_pad_value, batch_first=True)\n",
    "#     labels_mask = pad_sequence(labels_mask, padding_value=0, batch_first=True)\n",
    "\n",
    "#     collated = {'input_ids': input_ids,\n",
    "#                 'input_ids_generate': input_ids_generate,\n",
    "#                 'labels': labels,\n",
    "#                 'attention_mask': attention_mask,\n",
    "#                 }\n",
    "#     if args.num_mem_tokens is not None:\n",
    "#         # add labels mask only for RMT, ARMT\n",
    "#         collated['labels_mask'] = labels_mask.bool()\n",
    "#     return collated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_path = \"/workspace-SR006.nfs2/Bulatov_A/rmt/data/implicit_chain_of_thought/4_by_4_mult\"\n",
    "# train_dataset = datasets.load_from_disk(os.path.join(dataset_path, \"train\"))\n",
    "# valid_dataset = datasets.load_from_disk(os.path.join(dataset_path, \"valid\"))\n",
    "# if os.path.exists(os.path.join(dataset_path, \"test\")):\n",
    "#     test_dataset = datasets.load_from_disk(os.path.join(dataset_path, \"test\"))\n",
    "# else:\n",
    "#     test_dataset = datasets.load_from_disk(os.path.join(dataset_path, \"valid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'booydar/gsm8k'\n",
    "# dataset_name = 'booydar/multiplication_4x4'\n",
    "valid_dataset = datasets.load_dataset(dataset_name, split='valid')\n",
    "train_dataset = datasets.load_dataset(dataset_name, split='train')\n",
    "\n",
    "args.task_name = dataset_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[9705]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode('////')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_cot(text, by=\">> <<\"):\n",
    "    if text.startswith('<<'):\n",
    "        text = text[2:]\n",
    "    if text.endswith('>>'):\n",
    "        text = text[:-2]\n",
    "    \n",
    "    return text.split(by)\n",
    "\n",
    "def make_segment(input_tokens, loss=False):\n",
    "    input_ids = torch.tensor(input_tokens)\n",
    "    attention_mask = torch.ones_like(input_ids)\n",
    "    labels = torch.tensor(input_tokens) if loss else torch.tensor([-100] * len(input_ids))\n",
    "    # labels = torch.tensor(input_tokens)\n",
    "    labels_mask = torch.ones_like(input_ids) if loss else torch.zeros_like(input_ids)\n",
    "\n",
    "    return {'input_ids': input_ids,\n",
    "            'attention_mask': attention_mask,\n",
    "            'labels': labels,\n",
    "            'labels_mask': labels_mask.bool()\n",
    "            }\n",
    "\n",
    "id_pad_value = tokenizer.pad_token_id if tokenizer.pad_token_id is not None else tokenizer.eos_token_id\n",
    "think = tokenizer.encode('????')\n",
    "bos = tokenizer.encode('////')\n",
    "ans = tokenizer.encode('!!!!')\n",
    "eos = [tokenizer.eos_token_id]\n",
    "if 'gsm8k' in args.task_name:\n",
    "    delim = \">> <<\"\n",
    "elif 'multiplication' in args.task_name:\n",
    "    delim = ' + '\n",
    "else:\n",
    "    raise NotImplementedError(f\"Unknown task name {args.task_name}\")\n",
    "\n",
    "def collate_fn(batch):\n",
    "    # first, we segment each sample into task, cot steps and labels\n",
    "    segments_batch = []\n",
    "    for sample in batch:\n",
    "        task, lab, cot = sample['task'], sample['labels'], sample['cot']\n",
    "        task_tokens = tokenizer.encode(task, add_special_tokens=False)\n",
    "        labels_tokens = tokenizer.encode(lab, add_special_tokens=False)\n",
    "        if getattr(args, 'use_cot', False):\n",
    "            cot_segments = split_cot(cot, by=delim)\n",
    "        else:\n",
    "            cot_segments = [cot]\n",
    "        cot_segment_tokens = tokenizer.batch_encode_plus(cot_segments, add_special_tokens=False)['input_ids']\n",
    "\n",
    "        segments = []\n",
    "        segments.append(make_segment(bos + task_tokens + think, loss=False))\n",
    "        for segment in cot_segment_tokens[:-1]:\n",
    "            segments.append(make_segment(bos + segment + think, loss=True))\n",
    "        segments.append(make_segment(bos + cot_segment_tokens[-1] + ans, loss=True))\n",
    "\n",
    "        segments.append(make_segment(bos + labels_tokens + eos, loss=True))\n",
    "        segments_batch.append(segments)\n",
    "\n",
    "    # if some samples have less segments than others, we pad them with empty segments\n",
    "    num_segments = max(len(segments) for segments in segments_batch)\n",
    "    for segments in segments_batch:\n",
    "        if len(segments) < num_segments:\n",
    "            segments.extend([make_segment(eos, loss=False)] * (num_segments - len(segments)))\n",
    "\n",
    "    # prepare segments for the whole batch\n",
    "    batch_segments = []\n",
    "    for i in range(num_segments):\n",
    "        input_ids = [s[i]['input_ids'] for s in segments_batch]\n",
    "        attention_mask = [s[i]['attention_mask'] for s in segments_batch]\n",
    "        labels = [s[i]['labels'] for s in segments_batch]\n",
    "        labels_mask = [s[i]['labels_mask'] for s in segments_batch]\n",
    "\n",
    "        input_ids = pad_sequence(input_ids, batch_first=True, padding_value=id_pad_value)\n",
    "        attention_mask = pad_sequence(attention_mask, batch_first=True, padding_value=0)\n",
    "        labels = pad_sequence(labels, batch_first=True, padding_value=-100)\n",
    "        labels_mask = pad_sequence(labels_mask, batch_first=True, padding_value=False)\n",
    "\n",
    "        batch_segment = {'input_ids': input_ids,\n",
    "                         'attention_mask': attention_mask,\n",
    "                         'labels_mask': labels_mask,\n",
    "                         'labels': labels\n",
    "                         }\n",
    "        batch_segments.append(batch_segment)\n",
    "    full_labels = torch.cat([s['labels'] for s in batch_segments], dim=1)\n",
    "    return {\"segments\": batch_segments, 'labels': full_labels}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "args.use_cot = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = [valid_dataset[i] for i in range(10)]\n",
    "collated = collate_fn(batch)\n",
    "segments = collated['segments']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(segments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids torch.Size([10, 115])\n",
      "attention_mask torch.Size([10, 115])\n",
      "labels_mask torch.Size([10, 115])\n",
      "labels torch.Size([10, 115])\n"
     ]
    }
   ],
   "source": [
    "for k, v in segments[0].items():\n",
    "    print(k, v.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = rmt(**collated)\n",
    "# out.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "collated = segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['////John cuts his grass to 2 inches.  It grows .5 inches per month.  When it gets to 4 inches he cuts it back down to 2 inches.  It cost $100 to get his grass cut.  How much does he pay per year?????<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>',\n",
       " '////Hannah has three dogs. The first dog eats 1.5 cups of dog food a day. The second dog eats twice as much while the third dog eats 2.5 cups more than the second dog. How many cups of dog food should Hannah prepare in a day for her three dogs?????<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>',\n",
       " '////Travis wants to fly to Australia. The regular tickets cost about $2000. As Travis is a student, he will get a 30% discount on this price. How much does he need to pay for his ticket?????<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>',\n",
       " '////A set of 7 spoons costs $21. If each spoon would be sold separately, how much would 5 spoons cost?????<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>',\n",
       " '////Tom bought his games for $200.  They tripled in value and he then sold 40% of them.  How much did he sell the games for?????<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>',\n",
       " \"////Maggie went to Lou's aquarium and saw 100 goldfish in the aquarium. She asked if she could take some home to care for, and she was allowed to catch half of them. While using a catching net, she caught 3/5 of the total number of goldfish she was allowed to take home. How many goldfish does Maggie remain with to catch to get the total number she was allowed to take home?????<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>\",\n",
       " '////Kenny played basketball last week. He ran for twice as long as he played basketball, and he practiced on the trumpet for twice as long as he ran. If he practiced on the trumpet for 40 hours, how many hours did Kenny play basketball last week?????<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>',\n",
       " '////Marcia wants to buy some fruit. Apples cost $2, bananas cost $1, and oranges cost $3. If Marcia buys 12 apples, 4 bananas and 4 oranges, what is the average cost of each piece of fruit in dollars?????<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>',\n",
       " \"////It’s Meghan’s turn to pick up her team's coffee order.  She needs 2 drip coffees that are $2.25 each and one double shot espresso that’s $3.50.  She needs 2 lattes that are $4.00 and needs to add vanilla syrup to one of those for an additional $0.50.  She also needs 2 cold brew coffees that are $2.50 each and 1 cappuccino for $3.50.  How much is the coffee order?????\",\n",
       " '////Roman and Remy took separate showers. Remy used 1 more gallon than 3 times the number of gallons that Roman used for his shower. Together the boys used 33 gallons of water.  How many gallons did Remy use?????<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seg = collated[0]\n",
    "tokenizer.batch_decode(seg['input_ids'], skip_special_tokens=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['////<<4-2=2>> <<2/.5=4>> <<12/4=3>> <<100*3=300>>!!!!<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>',\n",
       " '////<<1.5*2=3>> <<3+2.5=5.5>> <<1.5+3+5.5=10>>!!!!<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>',\n",
       " '////<<30/100*2000=600>> <<2000-600=1400>>!!!!<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>',\n",
       " '////<<21/7=3>> <<5*3=15>>!!!!<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>',\n",
       " '////<<200*3=600>> <<600*.4=240>>!!!!<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>',\n",
       " '////<<1/2*100=50>> <<3/5*50=30>> <<50-30=20>>!!!!<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>',\n",
       " '////<<40/2=20>> <<20/2=10>>!!!!<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>',\n",
       " '////<<12*2=24>> <<4*1=4>> <<3*4=12>> <<24+4+12=40>> <<12+4+4=20>> <<40/20=2>>!!!!<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>',\n",
       " '////<<2*2.25=4.50>> <<2*4=8.00>> <<2*2.50=5.00>> <<4.50+8.00+.50+5.00+3.50+3.50=25.00>>!!!!',\n",
       " '////<<32=32>> <<8=8>>!!!!<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seg = collated[1]\n",
    "tokenizer.batch_decode(seg['input_ids'], skip_special_tokens=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['////300<|endoftext|><|endoftext|>',\n",
       " '////10<|endoftext|><|endoftext|>',\n",
       " '////1400<|endoftext|>',\n",
       " '////15<|endoftext|><|endoftext|>',\n",
       " '////240<|endoftext|><|endoftext|>',\n",
       " '////20<|endoftext|><|endoftext|>',\n",
       " '////10<|endoftext|><|endoftext|>',\n",
       " '////2<|endoftext|><|endoftext|>',\n",
       " '////25<|endoftext|><|endoftext|>',\n",
       " '////25<|endoftext|><|endoftext|>']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seg = collated[2]\n",
    "tokenizer.batch_decode(seg['input_ids'], skip_special_tokens=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['----12/4=3????<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>',\n",
       " '----1.5+3+5.5=10!!!!',\n",
       " '----1400<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>',\n",
       " '----15<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>',\n",
       " '----240<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>',\n",
       " '----50-30=20!!!!<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>',\n",
       " '----10<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>',\n",
       " '----3*4=12????<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>',\n",
       " '----2*2.50=5.00????<|endoftext|><|endoftext|>',\n",
       " '----25<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>']"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seg = collated[3]\n",
    "tokenizer.batch_decode(seg['input_ids'], skip_special_tokens=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['----100*3=300!!!!<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>',\n",
       " '----10<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>',\n",
       " '<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>',\n",
       " '<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>',\n",
       " '<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>',\n",
       " '----20<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>',\n",
       " '<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>',\n",
       " '----24+4+12=40????<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>',\n",
       " '----4.50+8.00+.50+5.00+3.50+3.50=25.00!!!!',\n",
       " '<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>']"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seg = collated[4]\n",
    "tokenizer.batch_decode(seg['input_ids'], skip_special_tokens=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['----300<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>',\n",
       " '<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>',\n",
       " '<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>',\n",
       " '<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>',\n",
       " '<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>',\n",
       " '<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>',\n",
       " '<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>',\n",
       " '----12+4+4=20????',\n",
       " '----25<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>',\n",
       " '<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>']"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seg = collated[5]\n",
    "tokenizer.batch_decode(seg['input_ids'], skip_special_tokens=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>',\n",
       " '<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>',\n",
       " '<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>',\n",
       " '<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>',\n",
       " '<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>',\n",
       " '<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>',\n",
       " '<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>',\n",
       " '----40/20=2!!!!',\n",
       " '<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>',\n",
       " '<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>']"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seg = collated[6]\n",
    "tokenizer.batch_decode(seg['input_ids'], skip_special_tokens=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<|endoftext|><|endoftext|><|endoftext|>',\n",
       " '<|endoftext|><|endoftext|><|endoftext|>',\n",
       " '<|endoftext|><|endoftext|><|endoftext|>',\n",
       " '<|endoftext|><|endoftext|><|endoftext|>',\n",
       " '<|endoftext|><|endoftext|><|endoftext|>',\n",
       " '<|endoftext|><|endoftext|><|endoftext|>',\n",
       " '<|endoftext|><|endoftext|><|endoftext|>',\n",
       " '----2<|endoftext|>',\n",
       " '<|endoftext|><|endoftext|><|endoftext|>',\n",
       " '<|endoftext|><|endoftext|><|endoftext|>']"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seg = collated[7]\n",
    "tokenizer.batch_decode(seg['input_ids'], skip_special_tokens=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_cot(text, by=\">> <<\"):\n",
    "    return text.split(by)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch = [train_dataset[i] for i in range(10)]\n",
    "batch = [valid_dataset[i] for i in range(10)]\n",
    "collated = collate_fn(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "think = tokenizer.encode('????')\n",
    "ans = tokenizer.encode('!!!!')\n",
    "eos = [tokenizer.eos_token_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_segment(input_tokens, loss=False):\n",
    "    input_ids = torch.tensor(input_tokens)\n",
    "    attention_mask = torch.ones_like(input_ids)\n",
    "    labels = torch.tensor(input_tokens) if loss else torch.tensor([-100] * len(input_ids))\n",
    "    labels_mask = torch.ones_like(input_ids) if loss else torch.zeros_like(input_ids)\n",
    "\n",
    "    return {'input_ids': input_ids,\n",
    "            'attention_mask': attention_mask,\n",
    "            'labels': labels,\n",
    "            'labels_mask': labels_mask.bool()\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "segments_batch = []\n",
    "for sample in batch:\n",
    "    task, lab, cot = sample['task'], sample['labels'], sample['cot']\n",
    "    task_tokens = tokenizer.encode(task, add_special_tokens=False)\n",
    "    labels_tokens = tokenizer.encode(lab, add_special_tokens=False)\n",
    "    cot_segments = split_cot(cot, by=' + ')\n",
    "    cot_segment_tokens = tokenizer.batch_encode_plus(cot_segments, add_special_tokens=False)['input_ids']\n",
    "    \n",
    "    segments = []\n",
    "    segments.append(make_segment(task_tokens + think, loss=False))\n",
    "    for segment in cot_segment_tokens[:-1]:\n",
    "        segments.append(make_segment(segment + think, loss=True))\n",
    "    segments.append(make_segment(cot_segment_tokens[-1] + ans, loss=True))\n",
    "\n",
    "    segments.append(make_segment(labels_tokens + eos, loss=True))\n",
    "    segments_batch.append(segments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_segments = max(len(segments) for segments in segments_batch)\n",
    "for segments in segments_batch:\n",
    "    if len(segments) < num_segments:\n",
    "        segments.extend([make_segment(eos, loss=False)] * (num_segments - len(segments)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_segments = []\n",
    "for i in range(num_segments):\n",
    "    input_ids = [s[i]['input_ids'] for s in segments_batch]\n",
    "    attention_mask = [s[i]['attention_mask'] for s in segments_batch]\n",
    "    labels = [s[i]['labels'] for s in segments_batch]\n",
    "    labels_mask = [s[i]['labels_mask'] for s in segments_batch]\n",
    "\n",
    "    input_ids = pad_sequence(input_ids, batch_first=True, padding_value=id_pad_value)\n",
    "    attention_mask = pad_sequence(attention_mask, batch_first=True, padding_value=0)\n",
    "    labels = pad_sequence(labels, batch_first=True, padding_value=-100)\n",
    "    labels_mask = pad_sequence(labels_mask, batch_first=True, padding_value=False)\n",
    "\n",
    "    batch_segment = {'input_ids': input_ids,\n",
    "                     'attention_mask': attention_mask,\n",
    "                     'labels_mask': labels_mask,\n",
    "                     'labels': labels\n",
    "                    }\n",
    "    batch_segments.append(batch_segment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['5 6 3 2 * 7 4 3 4????',\n",
       " '6 9 1 5 * 6 4 4 7????',\n",
       " '6 7 3 9 * 8 9 1 7????',\n",
       " '3 0 3 4 * 3 4 6 5????',\n",
       " '0 3 3 7 * 8 5 6 5????',\n",
       " '3 6 0 6 * 4 3 8 7????',\n",
       " '4 7 8 4 * 2 9 1 6????',\n",
       " '2 9 6 1 * 0 5 1 9????',\n",
       " '1 1 5 4 * 5 6 0 5????',\n",
       " '3 9 9 3 * 0 9 3 3????']"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seg = batch_segments[0]\n",
    "tokenizer.batch_decode(seg['input_ids'], skip_special_tokens=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['5 5 5 6 1????',\n",
       " '6 7 1 1 3????',\n",
       " '8 0 0 5 7????',\n",
       " '9 0 9 2 1????',\n",
       " '0 4 6 8 5????',\n",
       " '2 5 2 4 2????',\n",
       " '8 4 7 9 0????',\n",
       " '0 0 0 0 0????',\n",
       " '5 5 5 2 2????',\n",
       " '0 0 0 0 0????']"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seg = batch_segments[1]\n",
    "tokenizer.batch_decode(seg['input_ids'], skip_special_tokens=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "expected sequence of length 2 at dim 1 (got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[145]\u001b[39m\u001b[32m, line 39\u001b[39m\n\u001b[32m     36\u001b[39m data_loader = DataLoader(dataset, batch_size=\u001b[32m3\u001b[39m, collate_fn=\u001b[38;5;28;01mlambda\u001b[39;00m batch: segment_collate_fn(batch, segment_size=\u001b[32m2\u001b[39m))\n\u001b[32m     38\u001b[39m \u001b[38;5;66;03m# Fetch a batch\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m39\u001b[39m \u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msegmented_batch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdata_loader\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     40\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mprint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msegmented_batch\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace-SR006.nfs2/Bulatov_A/env_main/lib/python3.11/site-packages/torch/utils/data/dataloader.py:708\u001b[39m, in \u001b[36m_BaseDataLoaderIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    705\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    706\u001b[39m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[32m    707\u001b[39m     \u001b[38;5;28mself\u001b[39m._reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m708\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    709\u001b[39m \u001b[38;5;28mself\u001b[39m._num_yielded += \u001b[32m1\u001b[39m\n\u001b[32m    710\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    711\u001b[39m     \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable\n\u001b[32m    712\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    713\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._num_yielded > \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called\n\u001b[32m    714\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace-SR006.nfs2/Bulatov_A/env_main/lib/python3.11/site-packages/torch/utils/data/dataloader.py:764\u001b[39m, in \u001b[36m_SingleProcessDataLoaderIter._next_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    762\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    763\u001b[39m     index = \u001b[38;5;28mself\u001b[39m._next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m764\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m    765\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pin_memory:\n\u001b[32m    766\u001b[39m         data = _utils.pin_memory.pin_memory(data, \u001b[38;5;28mself\u001b[39m._pin_memory_device)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace-SR006.nfs2/Bulatov_A/env_main/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:55\u001b[39m, in \u001b[36m_MapDatasetFetcher.fetch\u001b[39m\u001b[34m(self, possibly_batched_index)\u001b[39m\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     54\u001b[39m     data = \u001b[38;5;28mself\u001b[39m.dataset[possibly_batched_index]\n\u001b[32m---> \u001b[39m\u001b[32m55\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcollate_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[145]\u001b[39m\u001b[32m, line 36\u001b[39m, in \u001b[36m<lambda>\u001b[39m\u001b[34m(batch)\u001b[39m\n\u001b[32m     29\u001b[39m dataset = [\n\u001b[32m     30\u001b[39m     [\u001b[32m1\u001b[39m, \u001b[32m2\u001b[39m, \u001b[32m3\u001b[39m, \u001b[32m4\u001b[39m],             \u001b[38;5;66;03m# 2 segments\u001b[39;00m\n\u001b[32m     31\u001b[39m     [\u001b[32m5\u001b[39m, \u001b[32m6\u001b[39m, \u001b[32m7\u001b[39m, \u001b[32m8\u001b[39m, \u001b[32m9\u001b[39m, \u001b[32m10\u001b[39m],      \u001b[38;5;66;03m# 3 segments\u001b[39;00m\n\u001b[32m     32\u001b[39m     [\u001b[32m11\u001b[39m, \u001b[32m12\u001b[39m, \u001b[32m13\u001b[39m]             \u001b[38;5;66;03m# 2 segments (last one short)\u001b[39;00m\n\u001b[32m     33\u001b[39m ]\n\u001b[32m     35\u001b[39m \u001b[38;5;66;03m# Create DataLoader\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m36\u001b[39m data_loader = DataLoader(dataset, batch_size=\u001b[32m3\u001b[39m, collate_fn=\u001b[38;5;28;01mlambda\u001b[39;00m batch: \u001b[43msegment_collate_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msegment_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[32m     38\u001b[39m \u001b[38;5;66;03m# Fetch a batch\u001b[39;00m\n\u001b[32m     39\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m segmented_batch \u001b[38;5;129;01min\u001b[39;00m data_loader:\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[145]\u001b[39m\u001b[32m, line 26\u001b[39m, in \u001b[36msegment_collate_fn\u001b[39m\u001b[34m(batch, segment_size, pad_value)\u001b[39m\n\u001b[32m     23\u001b[39m grouped_segments = [[seg[i] \u001b[38;5;28;01mfor\u001b[39;00m seg \u001b[38;5;129;01min\u001b[39;00m padded_segments] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(max_segments)]\n\u001b[32m     25\u001b[39m \u001b[38;5;66;03m# Convert to tensors\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m26\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m[\u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43msegment\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msegment\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mgrouped_segments\u001b[49m\u001b[43m]\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[145]\u001b[39m\u001b[32m, line 26\u001b[39m, in \u001b[36m<listcomp>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m     23\u001b[39m grouped_segments = [[seg[i] \u001b[38;5;28;01mfor\u001b[39;00m seg \u001b[38;5;129;01min\u001b[39;00m padded_segments] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(max_segments)]\n\u001b[32m     25\u001b[39m \u001b[38;5;66;03m# Convert to tensors\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m26\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43msegment\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m segment \u001b[38;5;129;01min\u001b[39;00m grouped_segments]\n",
      "\u001b[31mValueError\u001b[39m: expected sequence of length 2 at dim 1 (got 1)"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def segment_collate_fn(batch, segment_size=2, pad_value=0):\n",
    "    \"\"\"Segments samples, then groups corresponding segments, handling variable segment counts.\"\"\"\n",
    "    \n",
    "    # Step 1: Segment each sample\n",
    "    segmented_samples = [\n",
    "        [sample[i:i + segment_size] for i in range(0, len(sample), segment_size)]\n",
    "        for sample in batch\n",
    "    ]\n",
    "    \n",
    "    # Step 2: Find the max number of segments\n",
    "    max_segments = max(len(segments) for segments in segmented_samples)\n",
    "    \n",
    "    # Step 3: Pad samples to have the same number of segments\n",
    "    padded_segments = [\n",
    "        segments + [[pad_value] * segment_size] * (max_segments - len(segments))\n",
    "        for segments in segmented_samples\n",
    "    ]\n",
    "    \n",
    "    # Step 4: Transpose to group corresponding segments\n",
    "    grouped_segments = [[seg[i] for seg in padded_segments] for i in range(max_segments)]\n",
    "    \n",
    "    # Convert to tensors\n",
    "    return [torch.tensor(segment) for segment in grouped_segments]\n",
    "\n",
    "# Example dataset (list of lists with varying lengths)\n",
    "dataset = [\n",
    "    [1, 2, 3, 4],             # 2 segments\n",
    "    [5, 6, 7, 8, 9, 10],      # 3 segments\n",
    "    [11, 12, 13]             # 2 segments (last one short)\n",
    "]\n",
    "\n",
    "# Create DataLoader\n",
    "data_loader = DataLoader(dataset, batch_size=3, collate_fn=lambda batch: segment_collate_fn(batch, segment_size=2))\n",
    "\n",
    "# Fetch a batch\n",
    "for segmented_batch in data_loader:\n",
    "    print(segmented_batch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'input_ids': tensor([  20,  718,  513,  362, 1635,  767,  604,  513,  604, 9805]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  'labels': tensor([-100, -100, -100, -100, -100, -100, -100, -100, -100, -100]),\n",
       "  'labels_mask': tensor([False, False, False, False, False, False, False, False, False, False])},\n",
       " {'input_ids': tensor([  20,  642,  642,  718,  352, 9805]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1]),\n",
       "  'labels': tensor([  20,  642,  642,  718,  352, 9805]),\n",
       "  'labels_mask': tensor([True, True, True, True, True, True])},\n",
       " {'input_ids': tensor([  15,  657,  718,  604,  860,  657,  357,  642,  642,  352,  352,  352,\n",
       "           352, 1267, 9805]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  'labels': tensor([  15,  657,  718,  604,  860,  657,  357,  642,  642,  352,  352,  352,\n",
       "           352, 1267, 9805]),\n",
       "  'labels_mask': tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "          True, True, True])},\n",
       " {'input_ids': tensor([  15,  657,  642,  860,  657,  767,  657,  357,  642,  642,  718,  657,\n",
       "           362,  807,  657, 1267, 9805]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  'labels': tensor([  15,  657,  642,  860,  657,  767,  657,  357,  642,  642,  718,  657,\n",
       "           362,  807,  657, 1267, 9805]),\n",
       "  'labels_mask': tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "          True, True, True, True, True])},\n",
       " {'input_ids': tensor([   15,   657,   657,   657,   718,   604,   860,   657, 13896]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  'labels': tensor([   15,   657,   657,   657,   718,   604,   860,   657, 13896]),\n",
       "  'labels_mask': tensor([True, True, True, True, True, True, True, True, True])},\n",
       " {'input_ids': tensor([   20,   642,   718,   657,   807,   362,   657,   352, 50256]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  'labels': tensor([   20,   642,   718,   657,   807,   362,   657,   352, 50256]),\n",
       "  'labels_mask': tensor([True, True, True, True, True, True, True, True, True])}]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.use_cot:\n",
    "    segments = []\n",
    "    segments.append({'input_ids': task_tokens + [think]})\n",
    "    for segment in cot_segment_tokens[:-1]:\n",
    "        segments.append({'input_ids': segment + [think]})\n",
    "    segments.append({'input_ids': cot_segment_tokens[-1] + [ans]})\n",
    "    \n",
    "    segments.append({'input_ids': labels_tokens + [eos]})\n",
    "\n",
    "    for segment in segments\n",
    "    \n",
    "else:\n",
    "    full_input = task_tokens + [ans] + labels_tokens + [eos]\n",
    "    gen_input = task_tokens + [ans]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids, input_ids_generate, labels, labels_mask, attention_mask = [], [], [], [], []\n",
    "for sample in batch:\n",
    "    task, lab, cot = sample['task'], sample['labels'], sample['cot']\n",
    "    task_tokens = tokenizer.encode(task, add_special_tokens=False)\n",
    "    labels_tokens = tokenizer.encode(lab, add_special_tokens=False)\n",
    "    cot_tokens = tokenizer.encode(cot, add_special_tokens=False)\n",
    "\n",
    "    if args.use_cot:\n",
    "        full_input = task_tokens + [think] + cot_tokens + [ans] + labels_tokens + [eos]\n",
    "        gen_input = task_tokens + [think]\n",
    "    else:\n",
    "        full_input = task_tokens + [ans] + labels_tokens + [eos]\n",
    "        gen_input = task_tokens + [ans]\n",
    "    \n",
    "    inp_ids = torch.tensor(full_input)\n",
    "    input_ids.append(inp_ids)\n",
    "    input_ids_generate.append(torch.tensor(gen_input))\n",
    "\n",
    "\n",
    "    lab = torch.tensor(full_input)\n",
    "    lab[:len(task_tokens)] = -100\n",
    "    labels.append(lab)\n",
    "\n",
    "    lab_mask = torch.ones_like(inp_ids)\n",
    "    lab_mask[:len(task_tokens)] = 0\n",
    "    labels_mask.append(lab_mask)\n",
    "    attention_mask.append(torch.ones_like(inp_ids))\n",
    "\n",
    "input_ids = pad_sequence(input_ids, padding_value=id_pad_value, batch_first=True)\n",
    "# input_ids_generate = pad_sequence(input_ids_generate, padding_value=id_pad_value, batch_first=True)\n",
    "attention_mask = pad_sequence(attention_mask, padding_value=0, batch_first=True)\n",
    "labels = pad_sequence(labels, padding_value=id_pad_value, batch_first=True)\n",
    "labels_mask = pad_sequence(labels_mask, padding_value=0, batch_first=True)\n",
    "\n",
    "collated = {'input_ids': input_ids,\n",
    "            'input_ids_generate': input_ids_generate,\n",
    "            'labels': labels,\n",
    "            'attention_mask': attention_mask,\n",
    "            }\n",
    "if args.num_mem_tokens is not None:\n",
    "    # add labels mask only for RMT, ARMT\n",
    "    collated['labels_mask'] = labels_mask.bool()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[   20,   718,   513,   362,  1635,   767,   604,   513,   604, 50256,\n",
       "             20,   642,   642,   718,   352,  1343,   657,   657,   718,   604,\n",
       "            860,   657,   357,   642,   642,   352,   352,   352,   352,  1267,\n",
       "           1343,   657,   657,   642,   860,   657,   767,   657,   357,   642,\n",
       "            642,   718,   657,   362,   807,   657,  1267,  1343,   657,   657,\n",
       "            657,   657,   718,   604,   860,   657, 50256,    20,   642,   718,\n",
       "            657,   807,   362,   657,   352, 50256],\n",
       "         [   21,   860,   352,   642,  1635,   718,   604,   604,   767, 50256,\n",
       "             21,   767,   352,   352,   513,  1343,   657,   604,   807,   767,\n",
       "            657,   362,   357,   718,   352,   657,   860,   513,   362,  1267,\n",
       "           1343,   657,   657,   604,   807,   767,   657,   362,   357,   718,\n",
       "            352,   604,   767,   352,   513,   362,  1267,  1343,   657,   657,\n",
       "            657,   362,   767,   513,   718,   513, 50256,    21,   352,   604,\n",
       "            860,   807,   718,   807,   513, 50256],\n",
       "         [   21,   767,   513,   860,  1635,   807,   860,   352,   767, 50256,\n",
       "             23,   657,   657,   642,   767,  1343,   657,   604,   807,   513,\n",
       "            604,   807,   357,   807,   604,   807,   807,   352,   860,  1267,\n",
       "           1343,   657,   657,   718,   767,   513,   860,   657,   357,   807,\n",
       "            604,   604,   718,   642,   807,   352,  1267,  1343,   657,   657,\n",
       "            657,   362,   513,   718,   642,   718, 50256,    23,   604,   604,\n",
       "            807,   807,   604,   767,   718, 50256],\n",
       "         [   18,   657,   513,   604,  1635,   513,   604,   718,   642, 50256,\n",
       "             24,   657,   860,   362,   352,  1343,   657,   362,   352,   362,\n",
       "            767,   352,   357,   860,   362,   657,   642,   807,   352,  1267,\n",
       "           1343,   657,   657,   807,   352,   807,   642,   362,   357,   860,\n",
       "            362,   807,   718,   718,   767,   362,  1267,  1343,   657,   657,\n",
       "            657,   642,   352,   642,   352,   362, 50256,    24,   362,   807,\n",
       "            352,   807,   362,   604,   362, 50256],\n",
       "         [   15,   513,   513,   767,  1635,   807,   642,   718,   642, 50256,\n",
       "             15,   604,   718,   807,   642,  1343,   657,   657,   642,   718,\n",
       "            718,   513,   357,   657,   604,   352,   642,   362,   604,  1267,\n",
       "           1343,   657,   657,   657,   807,   860,   513,   604,   357,   657,\n",
       "            604,   352,   513,   362,   807,   604,  1267,  1343,   657,   657,\n",
       "            657,   657,   642,   718,   718,   513, 50256,    15,   604,   352,\n",
       "            513,   767,   604,   352,   604, 50256],\n",
       "         [   18,   718,   657,   718,  1635,   604,   513,   807,   767, 50256,\n",
       "             17,   642,   362,   604,   362,  1343,   657,   860,   807,   352,\n",
       "            807,   352,   357,   362,   604,   352,   718,   657,   362,  1267,\n",
       "           1343,   657,   657,   604,   657,   642,   807,   604,   357,   362,\n",
       "            604,   642,   718,   642,   657,   642,  1267,  1343,   657,   657,\n",
       "            657,   352,   604,   604,   362,   604, 50256,    17,   604,   642,\n",
       "            767,   860,   604,   767,   604, 50256],\n",
       "         [   19,   767,   807,   604,  1635,   362,   860,   352,   718, 50256,\n",
       "             23,   604,   767,   860,   657,  1343,   657,   718,   718,   807,\n",
       "            513,   604,   357,   807,   657,   604,   807,   604,   604,  1267,\n",
       "           1343,   657,   657,   604,   767,   807,   604,   657,   357,   807,\n",
       "            657,   807,   642,   513,   860,   657,  1267,  1343,   657,   657,\n",
       "            657,   604,   604,   362,   860,   362, 50256,    23,   657,   807,\n",
       "            860,   767,   352,   657,   513, 50256],\n",
       "         [   17,   860,   718,   352,  1635,   657,   642,   352,   860, 50256,\n",
       "             15,   657,   657,   657,   657,  1343,   657,   657,   718,   604,\n",
       "            807,   657,   357,   657,   657,   718,   604,   807,   657,  1267,\n",
       "           1343,   657,   657,   362,   860,   718,   352,   657,   357,   657,\n",
       "            657,   807,   513,   642,   362,   657,  1267,  1343,   657,   657,\n",
       "            657,   807,   362,   362,   642,   352, 50256,    15,   657,   807,\n",
       "            352,   807,   604,   642,   352, 50256],\n",
       "         [   16,   352,   642,   604,  1635,   642,   718,   657,   642, 50256,\n",
       "             20,   642,   642,   362,   362,  1343,   657,   718,   718,   657,\n",
       "            767,   362,   357,   642,   352,   362,   513,   860,   362,  1267,\n",
       "           1343,   657,   657,   657,   657,   657,   657,   657,   357,   642,\n",
       "            352,   362,   513,   860,   362,   657,  1267,  1343,   657,   657,\n",
       "            657,   642,   642,   642,   362,   362, 50256,    20,   352,   362,\n",
       "            807,   604,   807,   362,   362, 50256],\n",
       "         [   18,   860,   860,   513,  1635,   657,   860,   513,   513, 50256,\n",
       "             15,   657,   657,   657,   657,  1343,   657,   767,   513,   860,\n",
       "            642,   513,   357,   657,   767,   513,   860,   642,   513,  1267,\n",
       "           1343,   657,   657,   860,   767,   860,   352,   352,   357,   657,\n",
       "            767,   362,   767,   642,   642,   352,  1267,  1343,   657,   657,\n",
       "            657,   860,   767,   860,   352,   352, 50256,    15,   767,   362,\n",
       "            718,   513,   642,   513,   352, 50256]]),\n",
       " 'input_ids_generate': [tensor([   20,   718,   513,   362,  1635,   767,   604,   513,   604, 50256]),\n",
       "  tensor([   21,   860,   352,   642,  1635,   718,   604,   604,   767, 50256]),\n",
       "  tensor([   21,   767,   513,   860,  1635,   807,   860,   352,   767, 50256]),\n",
       "  tensor([   18,   657,   513,   604,  1635,   513,   604,   718,   642, 50256]),\n",
       "  tensor([   15,   513,   513,   767,  1635,   807,   642,   718,   642, 50256]),\n",
       "  tensor([   18,   718,   657,   718,  1635,   604,   513,   807,   767, 50256]),\n",
       "  tensor([   19,   767,   807,   604,  1635,   362,   860,   352,   718, 50256]),\n",
       "  tensor([   17,   860,   718,   352,  1635,   657,   642,   352,   860, 50256]),\n",
       "  tensor([   16,   352,   642,   604,  1635,   642,   718,   657,   642, 50256]),\n",
       "  tensor([   18,   860,   860,   513,  1635,   657,   860,   513,   513, 50256])],\n",
       " 'labels': tensor([[ -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100, 50256,\n",
       "             20,   642,   642,   718,   352,  1343,   657,   657,   718,   604,\n",
       "            860,   657,   357,   642,   642,   352,   352,   352,   352,  1267,\n",
       "           1343,   657,   657,   642,   860,   657,   767,   657,   357,   642,\n",
       "            642,   718,   657,   362,   807,   657,  1267,  1343,   657,   657,\n",
       "            657,   657,   718,   604,   860,   657, 50256,    20,   642,   718,\n",
       "            657,   807,   362,   657,   352, 50256],\n",
       "         [ -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100, 50256,\n",
       "             21,   767,   352,   352,   513,  1343,   657,   604,   807,   767,\n",
       "            657,   362,   357,   718,   352,   657,   860,   513,   362,  1267,\n",
       "           1343,   657,   657,   604,   807,   767,   657,   362,   357,   718,\n",
       "            352,   604,   767,   352,   513,   362,  1267,  1343,   657,   657,\n",
       "            657,   362,   767,   513,   718,   513, 50256,    21,   352,   604,\n",
       "            860,   807,   718,   807,   513, 50256],\n",
       "         [ -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100, 50256,\n",
       "             23,   657,   657,   642,   767,  1343,   657,   604,   807,   513,\n",
       "            604,   807,   357,   807,   604,   807,   807,   352,   860,  1267,\n",
       "           1343,   657,   657,   718,   767,   513,   860,   657,   357,   807,\n",
       "            604,   604,   718,   642,   807,   352,  1267,  1343,   657,   657,\n",
       "            657,   362,   513,   718,   642,   718, 50256,    23,   604,   604,\n",
       "            807,   807,   604,   767,   718, 50256],\n",
       "         [ -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100, 50256,\n",
       "             24,   657,   860,   362,   352,  1343,   657,   362,   352,   362,\n",
       "            767,   352,   357,   860,   362,   657,   642,   807,   352,  1267,\n",
       "           1343,   657,   657,   807,   352,   807,   642,   362,   357,   860,\n",
       "            362,   807,   718,   718,   767,   362,  1267,  1343,   657,   657,\n",
       "            657,   642,   352,   642,   352,   362, 50256,    24,   362,   807,\n",
       "            352,   807,   362,   604,   362, 50256],\n",
       "         [ -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100, 50256,\n",
       "             15,   604,   718,   807,   642,  1343,   657,   657,   642,   718,\n",
       "            718,   513,   357,   657,   604,   352,   642,   362,   604,  1267,\n",
       "           1343,   657,   657,   657,   807,   860,   513,   604,   357,   657,\n",
       "            604,   352,   513,   362,   807,   604,  1267,  1343,   657,   657,\n",
       "            657,   657,   642,   718,   718,   513, 50256,    15,   604,   352,\n",
       "            513,   767,   604,   352,   604, 50256],\n",
       "         [ -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100, 50256,\n",
       "             17,   642,   362,   604,   362,  1343,   657,   860,   807,   352,\n",
       "            807,   352,   357,   362,   604,   352,   718,   657,   362,  1267,\n",
       "           1343,   657,   657,   604,   657,   642,   807,   604,   357,   362,\n",
       "            604,   642,   718,   642,   657,   642,  1267,  1343,   657,   657,\n",
       "            657,   352,   604,   604,   362,   604, 50256,    17,   604,   642,\n",
       "            767,   860,   604,   767,   604, 50256],\n",
       "         [ -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100, 50256,\n",
       "             23,   604,   767,   860,   657,  1343,   657,   718,   718,   807,\n",
       "            513,   604,   357,   807,   657,   604,   807,   604,   604,  1267,\n",
       "           1343,   657,   657,   604,   767,   807,   604,   657,   357,   807,\n",
       "            657,   807,   642,   513,   860,   657,  1267,  1343,   657,   657,\n",
       "            657,   604,   604,   362,   860,   362, 50256,    23,   657,   807,\n",
       "            860,   767,   352,   657,   513, 50256],\n",
       "         [ -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100, 50256,\n",
       "             15,   657,   657,   657,   657,  1343,   657,   657,   718,   604,\n",
       "            807,   657,   357,   657,   657,   718,   604,   807,   657,  1267,\n",
       "           1343,   657,   657,   362,   860,   718,   352,   657,   357,   657,\n",
       "            657,   807,   513,   642,   362,   657,  1267,  1343,   657,   657,\n",
       "            657,   807,   362,   362,   642,   352, 50256,    15,   657,   807,\n",
       "            352,   807,   604,   642,   352, 50256],\n",
       "         [ -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100, 50256,\n",
       "             20,   642,   642,   362,   362,  1343,   657,   718,   718,   657,\n",
       "            767,   362,   357,   642,   352,   362,   513,   860,   362,  1267,\n",
       "           1343,   657,   657,   657,   657,   657,   657,   657,   357,   642,\n",
       "            352,   362,   513,   860,   362,   657,  1267,  1343,   657,   657,\n",
       "            657,   642,   642,   642,   362,   362, 50256,    20,   352,   362,\n",
       "            807,   604,   807,   362,   362, 50256],\n",
       "         [ -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100, 50256,\n",
       "             15,   657,   657,   657,   657,  1343,   657,   767,   513,   860,\n",
       "            642,   513,   357,   657,   767,   513,   860,   642,   513,  1267,\n",
       "           1343,   657,   657,   860,   767,   860,   352,   352,   357,   657,\n",
       "            767,   362,   767,   642,   642,   352,  1267,  1343,   657,   657,\n",
       "            657,   860,   767,   860,   352,   352, 50256,    15,   767,   362,\n",
       "            718,   513,   642,   513,   352, 50256]]),\n",
       " 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print out first all features of sample\n",
    "\n",
    "for k, v in valid_dataset[0].items():\n",
    "    tokens = [i if i > 0 else 0 for i in v]\n",
    "    print(k, tokenizer.decode(tokens))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_pad_value = tokenizer.pad_token_id if tokenizer.pad_token_id is not None else tokenizer.eos_token_id\n",
    "# id_pad_value = -100\n",
    "\n",
    "\n",
    "if args.use_cot in (False, None):\n",
    "    inputs_key = 'examples_nocot'\n",
    "    labels_key = 'labels_nocot'\n",
    "else:\n",
    "    inputs_key = 'examples_all'\n",
    "    labels_key = 'labels_all'\n",
    "    \n",
    "split_cot_by = \">> <<\"\n",
    "# def collate_fn(batch):\n",
    "input_ids = [torch.tensor(b[inputs_key]) for b in batch]\n",
    "labels = [torch.tensor(b[labels_key]) for b in batch]\n",
    "attention_mask = [torch.ones_like(b, dtype=int) for b in input_ids]\n",
    "# labels_mask defines which input_ids participate in loss calculation\n",
    "labels_mask = [torch.sign(torch.tensor(b[labels_key])) for b in batch]\n",
    "\n",
    "\n",
    "input_ids = pad_sequence(input_ids, padding_value=id_pad_value, batch_first=True)\n",
    "labels = pad_sequence(labels, padding_value=id_pad_value, batch_first=True)\n",
    "attention_mask = pad_sequence(attention_mask, padding_value=0, batch_first=True)\n",
    "labels_mask = pad_sequence(labels_mask, padding_value=0, batch_first=True)\n",
    "\n",
    "collated = {'input_ids': input_ids,\n",
    "            'labels': labels, \n",
    "            'attention_mask': attention_mask,\n",
    "            }\n",
    "if args.num_mem_tokens is not None:\n",
    "    # add labels mask only for RMT, ARMT\n",
    "    collated['labels_mask'] = labels_mask.bool()\n",
    "# return collated"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
