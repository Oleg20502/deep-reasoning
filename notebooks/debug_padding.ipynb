{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa0c8414-6cd2-41d6-a5e9-056e4b3a5198",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user33/.conda/envs/rmt/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "import datasets\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7585560c-02a2-44ff-9c33-35e08af77437",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "from utils.reasoning import make_segment, split_cot\n",
    "from torch.nn.utils.rnn import pad_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "8913518e-cf99-4eb2-8a16-89f2c600faa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from transformers.modeling_outputs import CausalLMOutputWithCrossAttentions\n",
    "\n",
    "class MemoryCellSmart(torch.nn.Module):\n",
    "    def __init__(self, base_model, num_mem_tokens):\n",
    "        super().__init__()\n",
    "        self.model = base_model\n",
    "        self.num_mem_tokens = num_mem_tokens\n",
    "        embeddings = self.model.get_input_embeddings()\n",
    "        memory_dim = getattr(self.model.config, 'n_embd', self.model.config.hidden_size)\n",
    "        memory_weights = torch.randn((num_mem_tokens, memory_dim)) * embeddings.weight.data.std()\n",
    "        self.register_parameter('memory', torch.nn.Parameter(memory_weights, requires_grad=True))\n",
    "\n",
    "    def set_memory(self, input_shape):\n",
    "        return self.memory.repeat(input_shape[0], 1, 1)\n",
    "    \n",
    "    def put_tensor_by_mask(self, inputs_embeds, memory_state, mem_mask):\n",
    "        bs, N, H = inputs_embeds.shape\n",
    "\n",
    "        for i in range(bs):\n",
    "            inputs_embeds[i, mem_mask[i]] = memory_state[i]\n",
    "        \n",
    "        return inputs_embeds\n",
    "    \n",
    "    def extract_tensor_by_mask(self, outputs, mask):\n",
    "        bs, N, H = outputs.shape\n",
    "        M = mask.sum(dim=1)[0].item()\n",
    "\n",
    "        extracted = outputs[mask]\n",
    "        return extracted.view(bs, M, H)\n",
    "\n",
    "    def process_input(\n",
    "            self,\n",
    "            input_ids,\n",
    "            memory_state,\n",
    "            write_mem,\n",
    "            read_mem_mask=None,\n",
    "            write_mem_mask=None,\n",
    "            **kwargs\n",
    "        ):\n",
    "        seg_kwargs = dict(**kwargs)\n",
    "\n",
    "        inputs_embeds = kwargs.get('inputs_embeds')\n",
    "        if inputs_embeds is None:\n",
    "            inputs_embeds = self.model.get_input_embeddings()(input_ids)\n",
    "        else:\n",
    "            raise ValueError(\"inputs_embeds is not supported for memory cells\") # test \"if\"\n",
    "\n",
    "        inputs_embeds = self.put_tensor_by_mask(inputs_embeds, memory_state, read_mem_mask)\n",
    "        if write_mem:\n",
    "            inputs_embeds = self.put_tensor_by_mask(inputs_embeds, memory_state, write_mem_mask)\n",
    "        \n",
    "        seg_kwargs['input_ids'] = None\n",
    "        seg_kwargs['inputs_embeds'] = inputs_embeds\n",
    "        seg_kwargs['attention_mask'] = kwargs['attention_mask']\n",
    "        seg_kwargs['output_hidden_states'] = True\n",
    "        return seg_kwargs\n",
    "\n",
    "    def forward(\n",
    "            self,\n",
    "            input_ids,\n",
    "            memory_state=None,\n",
    "            text_mask=None,\n",
    "            read_mem_mask=None,\n",
    "            write_mem_mask=None,\n",
    "            **kwargs\n",
    "        ):\n",
    "        if memory_state is None:\n",
    "            memory_state = self.set_memory(input_ids.shape)\n",
    "\n",
    "        seg_kwargs = self.process_input(\n",
    "            input_ids,\n",
    "            memory_state,\n",
    "            write_mem=True,\n",
    "            read_mem_mask=read_mem_mask,\n",
    "            write_mem_mask=write_mem_mask,\n",
    "            **kwargs\n",
    "        )\n",
    "        out = self.model(**seg_kwargs)\n",
    "        out, new_memory_state = self.process_output(\n",
    "            out,\n",
    "            text_mask=text_mask,\n",
    "            write_mem_mask=write_mem_mask,\n",
    "            **kwargs\n",
    "        )\n",
    "\n",
    "        return out, new_memory_state\n",
    "\n",
    "    def generate(\n",
    "        self,\n",
    "        input_ids,\n",
    "        memory_state,\n",
    "        attention_mask=None,\n",
    "        read_mem_mask=None,\n",
    "        write_mem_mask=None,\n",
    "        **generate_kwargs):\n",
    "        if memory_state is None:\n",
    "            memory_state = self.set_memory(input_ids.shape)\n",
    "\n",
    "        seg_kwargs = self.process_input(\n",
    "            input_ids,\n",
    "            memory_state,\n",
    "            attention_mask=attention_mask,\n",
    "            write_mem=False,\n",
    "            read_mem_mask=read_mem_mask,\n",
    "            write_mem_mask=write_mem_mask,\n",
    "        )\n",
    "        out = self.model.generate(inputs_embeds=seg_kwargs['inputs_embeds'], attention_mask=seg_kwargs['attention_mask'], **generate_kwargs)\n",
    "        return out\n",
    "\n",
    "\n",
    "    def process_output(self, model_outputs, text_mask, write_mem_mask, **kwargs):\n",
    "        if self.num_mem_tokens not in {0, None}:\n",
    "            out = CausalLMOutputWithCrossAttentions()\n",
    "            memory_state = self.extract_tensor_by_mask(model_outputs.hidden_states[-1], write_mem_mask)\n",
    "            out['logits'] = self.extract_tensor_by_mask(model_outputs.logits, text_mask)\n",
    "\n",
    "            if kwargs.get('output_hidden_states'):\n",
    "                out['hidden_states'] = [self.extract_tensor_by_mask(lh, text_mask)\n",
    "                                        for lh in model_outputs.hidden_states]\n",
    "\n",
    "            if kwargs.get('output_attentions'):\n",
    "                print(model_outputs['attentions'].shape)\n",
    "                out['attentions'] = model_outputs['attentions']\n",
    "        else:\n",
    "            memory_state = None\n",
    "            out = model_outputs\n",
    "\n",
    "        return out, memory_state\n",
    "\n",
    "\n",
    "class RecurrentWrapper(torch.nn.Module):\n",
    "    def __init__(self, memory_cell, **rmt_kwargs):\n",
    "        super().__init__()\n",
    "        self.memory_cell = memory_cell\n",
    "        self.rmt_config = rmt_kwargs\n",
    "\n",
    "    def process_outputs(self, cell_outputs, segments, **kwargs):\n",
    "        out = CausalLMOutputWithCrossAttentions()\n",
    "        proxy_out = {}\n",
    "        for seg_num, segment in enumerate(segments):\n",
    "            cell_out = cell_outputs[seg_num]\n",
    "\n",
    "            full_logits = cell_out.logits\n",
    "\n",
    "            labels = segment.get('labels')\n",
    "            if labels is not None:\n",
    "                shift_labels = labels[..., 1:].contiguous()\n",
    "                shift_logits = full_logits[..., :-1, :].contiguous()\n",
    "                flat_labels = shift_labels.view(-1)\n",
    "                flat_logits = shift_logits.view(-1, shift_logits.size(-1))\n",
    "\n",
    "                loss_fct = CrossEntropyLoss()\n",
    "                labels_mask = segment.get('labels_mask')\n",
    "                if labels_mask is not None:\n",
    "                    shift_mask = labels_mask[..., :-1].contiguous()\n",
    "\n",
    "                    flat_labels = flat_labels[shift_mask.view(-1)]\n",
    "                    flat_logits = flat_logits[shift_mask.view(-1)]\n",
    "\n",
    "                    if labels_mask.sum() == 0:\n",
    "                        loss_value = 0\n",
    "                    else:\n",
    "                        loss_value = loss_fct(flat_logits, flat_labels)\n",
    "\n",
    "                proxy_out[f'loss_{seg_num}'] = loss_value\n",
    "            else:\n",
    "                proxy_out[f'loss_{seg_num}'] = 0\n",
    "\n",
    "            segment_keys = ['loss']\n",
    "            if kwargs.get('output_attentions'):\n",
    "                segment_keys.append('attentions')\n",
    "            if kwargs.get('output_hidden_states'):\n",
    "                segment_keys.append('hidden_states')\n",
    "\n",
    "            for key, value in cell_out.items():\n",
    "                if any([sk in key for sk in segment_keys]):\n",
    "                    proxy_out[f'{key}_{seg_num}'] = value\n",
    "\n",
    "        num_segments = len(segments)\n",
    "        out['loss'] = sum([proxy_out[f'loss_{seg_num}'] for seg_num in range(num_segments)]) / num_segments\n",
    "        out['logits'] = torch.cat([cell_out.logits for cell_out in cell_outputs], dim=1)\n",
    "\n",
    "        return out\n",
    "    \n",
    "    def forward(self, segments, labels, output_attentions=None, output_hidden_states=None):\n",
    "        memory_state = None\n",
    "\n",
    "        cell_outputs = []\n",
    "        for seg_num, segment in enumerate(segments):\n",
    "            cell_out, memory_state = self.memory_cell(\n",
    "                input_ids=segment['input_ids'],\n",
    "                attention_mask=segment['attention_mask'],\n",
    "                text_mask=segment['text_mask'],\n",
    "                read_mem_mask=segment['read_mem_mask'],\n",
    "                write_mem_mask=segment['write_mem_mask'],\n",
    "                memory_state=memory_state,\n",
    "                output_hidden_states=True,\n",
    "                )\n",
    "            cell_outputs.append(cell_out)\n",
    "            self.manage_gradients(memory_state, seg_num)\n",
    "\n",
    "        out = self.process_outputs(\n",
    "            cell_outputs,\n",
    "            segments,\n",
    "            output_attentions=output_attentions,\n",
    "            output_hidden_states=output_hidden_states\n",
    "        )\n",
    "        return out\n",
    "\n",
    "    def generate(self, segments, **kwargs):\n",
    "        memory_state = None\n",
    "\n",
    "        for seg_num, segment in enumerate(segments):\n",
    "            cell_out, memory_state = self.memory_cell(\n",
    "                input_ids=segment['input_ids'],\n",
    "                attention_mask=segment['attention_mask'],\n",
    "                text_mask=segment['text_mask'],\n",
    "                memory_state=memory_state, output_hidden_states=True\n",
    "            )\n",
    "\n",
    "        generated_segments = []\n",
    "        for seg_num in range(len(segments), self.rmt_config.get(\"max_n_segments\", 32)):\n",
    "            output_ids, memory_state = self.generate_segment(memory_state=memory_state, **kwargs)\n",
    "            generated_segments.append(output_ids)\n",
    "\n",
    "            if self.all_done(generated_segments):\n",
    "                break\n",
    "\n",
    "        return generated_segments\n",
    "\n",
    "    def generate_segment(self, memory_state, **kwargs):\n",
    "        input_ids = self.get_bos_tensor(memory_state)\n",
    "        attention_mask = torch.ones_like(input_ids).bool()\n",
    "\n",
    "        generated = self.memory_cell.generate(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            memory_state=memory_state,\n",
    "            eos_token_id=[\n",
    "                self.rmt_config['eos_token_id'],\n",
    "                self.rmt_config['think_token_id'],\n",
    "                self.rmt_config['answer_token_id']\n",
    "            ],\n",
    "            **kwargs\n",
    "        )\n",
    "\n",
    "        # Update memory state from generation\n",
    "        fwd_inputs = torch.cat((input_ids, generated), dim=1)[:, :-1]\n",
    "        _, memory_state = self.memory_cell(input_ids=fwd_inputs, memory_state=memory_state)\n",
    "\n",
    "        return generated, memory_state\n",
    "\n",
    "    def get_bos_tensor(self, memory_state):\n",
    "        bos = self.rmt_config[\"bos_token_id\"]\n",
    "        bos_tensor = torch.tensor([bos] * memory_state.shape[0]).reshape(-1, 1)\n",
    "        return bos_tensor.to(memory_state.device)\n",
    "\n",
    "    def all_done(self, generated_segments):\n",
    "        eos = self.rmt_config['eos_token_id']\n",
    "        bs = generated_segments[0].shape[0]\n",
    "        have_eos = [any([eos in seg[i] for seg in generated_segments]) for i in range(bs)]\n",
    "        all_done = all(have_eos)\n",
    "        return all_done\n",
    "\n",
    "    def manage_gradients(self, memory_state, seg_num):\n",
    "        k2, max_n_segments = self.rmt_config.get('k2'), self.rmt_config.get('max_n_segments')\n",
    "        if seg_num == 0 \\\n",
    "            or k2 in {-1, None} \\\n",
    "                or seg_num + k2 > max_n_segments:\n",
    "            return memory_state\n",
    "\n",
    "        memory_state = memory_state.detach()\n",
    "        return memory_state\n",
    "\n",
    "    def gradient_checkpointing_enable(self, *args, **kwargs):\n",
    "        if hasattr(self.memory_cell.model, \"gradient_checkpointing_enable\"):\n",
    "            return self.memory_cell.model.gradient_checkpointing_enable(*args, **kwargs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "1a0f6a52-0bc0-4c94-9666-26e673e06f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Holder:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "args = Holder()\n",
    "args.use_cot = True\n",
    "args.num_mem_tokens = 16\n",
    "args.segment_size = 64\n",
    "args.max_n_segments = 10\n",
    "args.max_cot_steps = 8\n",
    "args.task_name = 'gsm8k'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "d36c61f1-5dc8-4ce0-970c-c23eb1601672",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"HuggingFaceTB/SmolLM2-135M\"\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "pad = [tokenizer.pad_token_id] if tokenizer.pad_token_id is not None else [tokenizer.eos_token_id]\n",
    "bos = [tokenizer.bos_token_id]\n",
    "eos = [tokenizer.eos_token_id]\n",
    "think = tokenizer.encode(\"<issue_start>\")\n",
    "ans = tokenizer.encode(\"<issue_closed>\")\n",
    "mem_token = tokenizer.encode(\"<empty_output>\")\n",
    "\n",
    "if 'gsm8k' in args.task_name:\n",
    "    delim = \">> <<\"\n",
    "elif 'multiplication' in args.task_name:\n",
    "    delim = ' + '\n",
    "else:\n",
    "    raise NotImplementedError(f\"Unknown task name {args.task_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "63ffb47a-9076-4d99-b0ae-ba0c83ce301e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":)\n"
     ]
    }
   ],
   "source": [
    "memory_cell = MemoryCellSmart(\n",
    "    model,\n",
    "    num_mem_tokens=16\n",
    ")\n",
    "\n",
    "rmt = RecurrentWrapper(\n",
    "    memory_cell, \n",
    "    max_n_segments=8,\n",
    "    think_token_id=think[0],\n",
    "    answer_token_id=ans[0],\n",
    "    bos_token_id=bos[0],\n",
    "    eos_token_id=eos[0]\n",
    ")\n",
    "\n",
    "# checkpoint_path = \"/home/user33/kashurin/RMT_SmolLM2-135M/pt/checkpoint-29500/pytorch_model.bin\"\n",
    "# checkpoint_path = \"/home/user33/kashurin/RMT_SmolLM2-135M/cot/checkpoint-2200/pytorch_model.bin\"\n",
    "device = 'cuda'\n",
    "\n",
    "# rmt.load_state_dict(torch.load(checkpoint_path), strict=False)\n",
    "rmt.to(device)\n",
    "print(':)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "0df1f99a-f051-4895-9a06-346011c220d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_segment_with_mem(input_tokens, loss=False, mem_token=None, num_mem_tokens=0):\n",
    "    input_tokens_with_mem = [mem_token]*num_mem_tokens + input_tokens + [mem_token]*num_mem_tokens\n",
    "    if loss:\n",
    "        labels = torch.tensor(input_tokens)\n",
    "    else:\n",
    "        labels = torch.tensor([-100] * len(input_tokens))\n",
    "    \n",
    "    input_ids = torch.tensor(input_tokens_with_mem)\n",
    "    \n",
    "    read_mem_mask = torch.zeros(input_ids.shape, dtype=torch.long)\n",
    "    read_mem_mask[:num_mem_tokens] = 1\n",
    "\n",
    "    write_mem_mask = torch.zeros(input_ids.shape, dtype=torch.long)\n",
    "    write_mem_mask[-num_mem_tokens:] = 1\n",
    "\n",
    "    text_mask = torch.ones(input_ids.shape, dtype=torch.long) - read_mem_mask - write_mem_mask\n",
    "\n",
    "    attention_mask = torch.ones_like(input_ids)\n",
    "\n",
    "    if loss:\n",
    "        labels_mask = torch.ones(len(input_tokens))\n",
    "    else:\n",
    "        labels_mask = torch.zeros(len(input_tokens))\n",
    "\n",
    "    return {'input_ids': input_ids,\n",
    "            'attention_mask': attention_mask,\n",
    "            'labels': labels,\n",
    "            'labels_mask': labels_mask.bool(),\n",
    "            'text_mask': text_mask.bool(),\n",
    "            'read_mem_mask': read_mem_mask.bool(),\n",
    "            'write_mem_mask': write_mem_mask.bool()\n",
    "            }\n",
    "\n",
    "\n",
    "def collate_fn(batch):\n",
    "    # first, we segment each sample into task, cot steps and labels\n",
    "    segments_batch = []\n",
    "    for sample in batch:\n",
    "        task, lab, cot = sample['task'], sample['labels'], sample['cot']\n",
    "        task_tokens = tokenizer.encode(task, add_special_tokens=False)\n",
    "        labels_tokens = tokenizer.encode(lab, add_special_tokens=False)\n",
    "        if getattr(args, 'use_cot', False):\n",
    "            cot_segments = split_cot(cot, by=delim)\n",
    "        else:\n",
    "            cot_segments = [cot]\n",
    "        cot_segment_tokens = tokenizer.batch_encode_plus(cot_segments, add_special_tokens=False)['input_ids']\n",
    "\n",
    "        segments = []\n",
    "        segments.append(make_segment_with_mem(\n",
    "            bos + task_tokens + think,\n",
    "            loss=False,\n",
    "            mem_token=mem_token[0],\n",
    "            num_mem_tokens=args.num_mem_tokens,\n",
    "        ))\n",
    "        for segment in cot_segment_tokens[:-1]:\n",
    "            segments.append(make_segment_with_mem(\n",
    "                bos + segment + think,\n",
    "                loss=True,\n",
    "                mem_token=mem_token[0],\n",
    "                num_mem_tokens=args.num_mem_tokens,\n",
    "            ))\n",
    "        segments.append(make_segment_with_mem(\n",
    "            bos + cot_segment_tokens[-1] + ans,\n",
    "            loss=True,\n",
    "            mem_token=mem_token[0],\n",
    "            num_mem_tokens=args.num_mem_tokens,\n",
    "        ))\n",
    "\n",
    "        segments.append(make_segment_with_mem(\n",
    "            bos + labels_tokens + eos,\n",
    "            loss=True,\n",
    "            mem_token=mem_token[0],\n",
    "            num_mem_tokens=args.num_mem_tokens,\n",
    "        ))\n",
    "        segments_batch.append(segments)\n",
    "\n",
    "    # if some samples have less segments than others, we pad them with empty segments\n",
    "    num_segments = max(len(segments) for segments in segments_batch)\n",
    "    for segments in segments_batch:\n",
    "        if len(segments) < num_segments:\n",
    "            segments.extend([\n",
    "                make_segment_with_mem(\n",
    "                    eos,\n",
    "                    loss=False,\n",
    "                    mem_token=mem_token[0],\n",
    "                    num_mem_tokens=args.num_mem_tokens,\n",
    "                )] * (num_segments - len(segments)))\n",
    "\n",
    "    # prepare segments for the whole batch\n",
    "    batch_segments = []\n",
    "    for i in range(num_segments):\n",
    "        input_ids = [s[i]['input_ids'] for s in segments_batch]\n",
    "        attention_mask = [s[i]['attention_mask'] for s in segments_batch]\n",
    "        labels = [s[i]['labels'] for s in segments_batch]\n",
    "        labels_mask = [s[i]['labels_mask'] for s in segments_batch]\n",
    "        text_mask = [s[i]['text_mask'] for s in segments_batch]\n",
    "        read_mem_mask = [s[i]['read_mem_mask'] for s in segments_batch]\n",
    "        write_mem_mask = [s[i]['write_mem_mask'] for s in segments_batch]\n",
    "\n",
    "        input_ids = pad_sequence(input_ids, batch_first=True, padding_value=id_pad_value)\n",
    "        attention_mask = pad_sequence(attention_mask, batch_first=True, padding_value=0)\n",
    "        labels = pad_sequence(labels, batch_first=True, padding_value=-100)\n",
    "        labels_mask = pad_sequence(labels_mask, batch_first=True, padding_value=False)\n",
    "        text_mask = pad_sequence(text_mask, batch_first=True, padding_value=True)\n",
    "        read_mem_mask = pad_sequence(read_mem_mask, batch_first=True, padding_value=False)\n",
    "        write_mem_mask = pad_sequence(write_mem_mask, batch_first=True, padding_value=False)\n",
    "\n",
    "        batch_segment = {'input_ids': input_ids,\n",
    "                         'attention_mask': attention_mask,\n",
    "                         'labels_mask': labels_mask,\n",
    "                         'labels': labels,\n",
    "                         'text_mask': text_mask,\n",
    "                         'read_mem_mask': read_mem_mask,\n",
    "                         'write_mem_mask': write_mem_mask\n",
    "                         }\n",
    "        batch_segments.append(batch_segment)\n",
    "    full_labels = torch.cat([s['labels'] for s in batch_segments], dim=1)\n",
    "    return {\"segments\": batch_segments, 'labels': full_labels}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dc72f342-dba0-4b71-b39b-700aed8e0900",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'booydar/gsm8k'\n",
    "train_dataset = datasets.load_dataset(dataset, split='train')\n",
    "valid_dataset = datasets.load_dataset(dataset, split='valid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "41eb4f59-5aa7-40cc-bfa2-e21946e3f148",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collated_batch_to_device(collated):\n",
    "    new_segments = []\n",
    "    for segment in collated[\"segments\"]:\n",
    "        segment = {k: v.to(device) for k, v in segment.items()}\n",
    "        new_segments.append(segment)\n",
    "\n",
    "    collated[\"segments\"] = new_segments\n",
    "    \n",
    "    collated[\"labels\"] = collated[\"labels\"].to(device)\n",
    "\n",
    "    return collated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "4c4dc5bb-e977-4869-9e10-1702c89bfb2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(63, device='cuda:0')"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collated[\"segments\"][0][\"text_mask\"][0].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "9333060a-9373-4e75-b61d-3ae56cda0bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = [\n",
    "    valid_dataset[0],\n",
    "    valid_dataset[1]\n",
    "]\n",
    "\n",
    "collated = collate_fn(batch)\n",
    "collated = collated_batch_to_device(collated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "3dfdb537-9007-4e30-916d-43168ef8bb4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = rmt(collated[\"segments\"], collated[\"labels\"], output_attentions=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a4692a0-fa47-4340-9df4-0f4f473d3eee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
